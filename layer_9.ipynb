{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Layer 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lb_YDijM8zS",
        "outputId": "9ee8d167-935e-47ec-d96f-8cd65af24715"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# DATASET_PATH = \"/content/drive/MyDrive/ML Project/layer 9\"\n",
        "DATASET_PATH = \"layer 9\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-fmzxIArNja4"
      },
      "outputs": [],
      "source": [
        "# CSV files into Pandas DataFrames\n",
        "train_df = pd.read_csv(f\"{DATASET_PATH}/train.csv\")\n",
        "valid_df = pd.read_csv(f\"{DATASET_PATH}/valid.csv\")\n",
        "test_df = pd.read_csv(f\"{DATASET_PATH}/test.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VUVoO3KlOQ3T"
      },
      "outputs": [],
      "source": [
        "temp = list(train_df.columns)\n",
        "\n",
        "FEATURES = temp[:-4]\n",
        "LABELS = temp[-4:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "k9RXSp5jQ9HL",
        "outputId": "9cb6f512-eb01-43a1-9a98-9de7a26c1e89"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>feature_10</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_759</th>\n",
              "      <th>feature_760</th>\n",
              "      <th>feature_761</th>\n",
              "      <th>feature_762</th>\n",
              "      <th>feature_763</th>\n",
              "      <th>feature_764</th>\n",
              "      <th>feature_765</th>\n",
              "      <th>feature_766</th>\n",
              "      <th>feature_767</th>\n",
              "      <th>feature_768</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.013112</td>\n",
              "      <td>0.130904</td>\n",
              "      <td>0.020284</td>\n",
              "      <td>0.063018</td>\n",
              "      <td>-0.034321</td>\n",
              "      <td>-0.073516</td>\n",
              "      <td>-0.030659</td>\n",
              "      <td>-0.064994</td>\n",
              "      <td>0.024153</td>\n",
              "      <td>0.082765</td>\n",
              "      <td>...</td>\n",
              "      <td>0.037803</td>\n",
              "      <td>0.241121</td>\n",
              "      <td>0.079949</td>\n",
              "      <td>-0.186099</td>\n",
              "      <td>-0.096718</td>\n",
              "      <td>0.126006</td>\n",
              "      <td>-0.023069</td>\n",
              "      <td>0.190374</td>\n",
              "      <td>0.146516</td>\n",
              "      <td>0.038047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.005934</td>\n",
              "      <td>0.138592</td>\n",
              "      <td>-0.007000</td>\n",
              "      <td>0.055925</td>\n",
              "      <td>-0.021927</td>\n",
              "      <td>-0.084788</td>\n",
              "      <td>0.013339</td>\n",
              "      <td>0.060811</td>\n",
              "      <td>-0.011344</td>\n",
              "      <td>0.039792</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.098701</td>\n",
              "      <td>0.042921</td>\n",
              "      <td>0.018571</td>\n",
              "      <td>-0.114785</td>\n",
              "      <td>-0.105186</td>\n",
              "      <td>0.059050</td>\n",
              "      <td>0.021443</td>\n",
              "      <td>0.013027</td>\n",
              "      <td>0.046826</td>\n",
              "      <td>-0.026682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.067210</td>\n",
              "      <td>0.078710</td>\n",
              "      <td>-0.044344</td>\n",
              "      <td>0.101248</td>\n",
              "      <td>-0.074331</td>\n",
              "      <td>-0.088951</td>\n",
              "      <td>0.074616</td>\n",
              "      <td>0.007231</td>\n",
              "      <td>0.021091</td>\n",
              "      <td>0.080092</td>\n",
              "      <td>...</td>\n",
              "      <td>0.029569</td>\n",
              "      <td>0.053370</td>\n",
              "      <td>0.096232</td>\n",
              "      <td>-0.369018</td>\n",
              "      <td>-0.066708</td>\n",
              "      <td>-0.003730</td>\n",
              "      <td>-0.063339</td>\n",
              "      <td>-0.044497</td>\n",
              "      <td>-0.024363</td>\n",
              "      <td>-0.042594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.005678</td>\n",
              "      <td>0.060703</td>\n",
              "      <td>0.033954</td>\n",
              "      <td>0.068771</td>\n",
              "      <td>-0.039923</td>\n",
              "      <td>-0.186583</td>\n",
              "      <td>0.014921</td>\n",
              "      <td>0.020791</td>\n",
              "      <td>0.017441</td>\n",
              "      <td>0.016184</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.095406</td>\n",
              "      <td>0.018405</td>\n",
              "      <td>-0.018047</td>\n",
              "      <td>-0.080393</td>\n",
              "      <td>-0.114030</td>\n",
              "      <td>0.048255</td>\n",
              "      <td>0.033839</td>\n",
              "      <td>0.035026</td>\n",
              "      <td>-0.047988</td>\n",
              "      <td>-0.038252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.076360</td>\n",
              "      <td>0.061095</td>\n",
              "      <td>-0.004938</td>\n",
              "      <td>0.066692</td>\n",
              "      <td>-0.040454</td>\n",
              "      <td>-0.005141</td>\n",
              "      <td>-0.003213</td>\n",
              "      <td>0.025721</td>\n",
              "      <td>0.083558</td>\n",
              "      <td>0.005890</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003129</td>\n",
              "      <td>0.045479</td>\n",
              "      <td>0.057146</td>\n",
              "      <td>-0.194466</td>\n",
              "      <td>0.000739</td>\n",
              "      <td>0.018702</td>\n",
              "      <td>0.013192</td>\n",
              "      <td>-0.038486</td>\n",
              "      <td>0.033358</td>\n",
              "      <td>-0.038452</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 768 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
              "0   0.013112   0.130904   0.020284   0.063018  -0.034321  -0.073516   \n",
              "1   0.005934   0.138592  -0.007000   0.055925  -0.021927  -0.084788   \n",
              "2  -0.067210   0.078710  -0.044344   0.101248  -0.074331  -0.088951   \n",
              "3  -0.005678   0.060703   0.033954   0.068771  -0.039923  -0.186583   \n",
              "4  -0.076360   0.061095  -0.004938   0.066692  -0.040454  -0.005141   \n",
              "\n",
              "   feature_7  feature_8  feature_9  feature_10  ...  feature_759  feature_760  \\\n",
              "0  -0.030659  -0.064994   0.024153    0.082765  ...     0.037803     0.241121   \n",
              "1   0.013339   0.060811  -0.011344    0.039792  ...    -0.098701     0.042921   \n",
              "2   0.074616   0.007231   0.021091    0.080092  ...     0.029569     0.053370   \n",
              "3   0.014921   0.020791   0.017441    0.016184  ...    -0.095406     0.018405   \n",
              "4  -0.003213   0.025721   0.083558    0.005890  ...    -0.003129     0.045479   \n",
              "\n",
              "   feature_761  feature_762  feature_763  feature_764  feature_765  \\\n",
              "0     0.079949    -0.186099    -0.096718     0.126006    -0.023069   \n",
              "1     0.018571    -0.114785    -0.105186     0.059050     0.021443   \n",
              "2     0.096232    -0.369018    -0.066708    -0.003730    -0.063339   \n",
              "3    -0.018047    -0.080393    -0.114030     0.048255     0.033839   \n",
              "4     0.057146    -0.194466     0.000739     0.018702     0.013192   \n",
              "\n",
              "   feature_766  feature_767  feature_768  \n",
              "0     0.190374     0.146516     0.038047  \n",
              "1     0.013027     0.046826    -0.026682  \n",
              "2    -0.044497    -0.024363    -0.042594  \n",
              "3     0.035026    -0.047988    -0.038252  \n",
              "4    -0.038486     0.033358    -0.038452  \n",
              "\n",
              "[5 rows x 768 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# drop ID column from the test dataset\n",
        "x_test = test_df.drop('ID', axis=1)\n",
        "\n",
        "x_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4xf-J1lmPIRn"
      },
      "outputs": [],
      "source": [
        "# dict to store train and valid dataset for each label\n",
        "x_train = {}\n",
        "y_train = {}\n",
        "x_valid = {}\n",
        "y_valid = {}\n",
        "\n",
        "# seperate the train and valid datasets into labels\n",
        "# remove the rows where label is NaN\n",
        "\n",
        "for label in LABELS:\n",
        "\n",
        "    train_df_temp = train_df[~np.isnan(train_df[label])]\n",
        "    valid_df_temp = valid_df[~np.isnan(valid_df[label])]\n",
        "\n",
        "    x_train[label] = train_df_temp.drop(LABELS, axis=1)\n",
        "    y_train[label] = train_df_temp[label]\n",
        "    x_valid[label] = valid_df_temp.drop(LABELS, axis=1)\n",
        "    y_valid[label] = valid_df_temp[label]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "wLKxs_WvRljJ",
        "outputId": "e96748ee-8d75-4126-eb26-c784c7d1d231"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>feature_10</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_759</th>\n",
              "      <th>feature_760</th>\n",
              "      <th>feature_761</th>\n",
              "      <th>feature_762</th>\n",
              "      <th>feature_763</th>\n",
              "      <th>feature_764</th>\n",
              "      <th>feature_765</th>\n",
              "      <th>feature_766</th>\n",
              "      <th>feature_767</th>\n",
              "      <th>feature_768</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>480</th>\n",
              "      <td>-0.037427</td>\n",
              "      <td>0.068284</td>\n",
              "      <td>-0.100538</td>\n",
              "      <td>0.076783</td>\n",
              "      <td>-0.113147</td>\n",
              "      <td>-0.079453</td>\n",
              "      <td>0.106947</td>\n",
              "      <td>0.011906</td>\n",
              "      <td>-0.047519</td>\n",
              "      <td>0.022915</td>\n",
              "      <td>...</td>\n",
              "      <td>0.061858</td>\n",
              "      <td>0.086089</td>\n",
              "      <td>0.004285</td>\n",
              "      <td>-0.325560</td>\n",
              "      <td>-0.035784</td>\n",
              "      <td>0.033521</td>\n",
              "      <td>-0.025551</td>\n",
              "      <td>0.083790</td>\n",
              "      <td>-0.027678</td>\n",
              "      <td>-0.008546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>481</th>\n",
              "      <td>0.024931</td>\n",
              "      <td>0.045966</td>\n",
              "      <td>0.016385</td>\n",
              "      <td>0.028214</td>\n",
              "      <td>-0.092396</td>\n",
              "      <td>-0.053490</td>\n",
              "      <td>-0.018101</td>\n",
              "      <td>0.053902</td>\n",
              "      <td>0.080196</td>\n",
              "      <td>0.010693</td>\n",
              "      <td>...</td>\n",
              "      <td>0.048435</td>\n",
              "      <td>0.127840</td>\n",
              "      <td>0.060487</td>\n",
              "      <td>-0.268356</td>\n",
              "      <td>-0.001359</td>\n",
              "      <td>0.019178</td>\n",
              "      <td>0.068597</td>\n",
              "      <td>0.066214</td>\n",
              "      <td>0.141953</td>\n",
              "      <td>0.075839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>482</th>\n",
              "      <td>0.025077</td>\n",
              "      <td>0.082511</td>\n",
              "      <td>0.074441</td>\n",
              "      <td>0.124308</td>\n",
              "      <td>-0.037937</td>\n",
              "      <td>-0.089271</td>\n",
              "      <td>0.012489</td>\n",
              "      <td>-0.036005</td>\n",
              "      <td>-0.023984</td>\n",
              "      <td>-0.010576</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.081554</td>\n",
              "      <td>0.121891</td>\n",
              "      <td>0.042131</td>\n",
              "      <td>-0.019572</td>\n",
              "      <td>-0.095350</td>\n",
              "      <td>0.087392</td>\n",
              "      <td>0.007523</td>\n",
              "      <td>0.030705</td>\n",
              "      <td>0.086901</td>\n",
              "      <td>0.031186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>483</th>\n",
              "      <td>0.030733</td>\n",
              "      <td>0.060249</td>\n",
              "      <td>0.099119</td>\n",
              "      <td>0.087801</td>\n",
              "      <td>-0.035729</td>\n",
              "      <td>-0.152115</td>\n",
              "      <td>0.032606</td>\n",
              "      <td>0.024821</td>\n",
              "      <td>0.032655</td>\n",
              "      <td>0.053826</td>\n",
              "      <td>...</td>\n",
              "      <td>0.039644</td>\n",
              "      <td>0.094773</td>\n",
              "      <td>-0.043471</td>\n",
              "      <td>-0.177032</td>\n",
              "      <td>-0.091252</td>\n",
              "      <td>0.031182</td>\n",
              "      <td>-0.034731</td>\n",
              "      <td>0.004988</td>\n",
              "      <td>0.143666</td>\n",
              "      <td>-0.012354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>484</th>\n",
              "      <td>0.012062</td>\n",
              "      <td>0.068691</td>\n",
              "      <td>0.051343</td>\n",
              "      <td>0.049753</td>\n",
              "      <td>0.006491</td>\n",
              "      <td>-0.107100</td>\n",
              "      <td>0.076212</td>\n",
              "      <td>0.004650</td>\n",
              "      <td>0.113739</td>\n",
              "      <td>0.004015</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.028502</td>\n",
              "      <td>0.123084</td>\n",
              "      <td>0.046536</td>\n",
              "      <td>-0.053508</td>\n",
              "      <td>-0.025445</td>\n",
              "      <td>0.062129</td>\n",
              "      <td>-0.034741</td>\n",
              "      <td>0.042223</td>\n",
              "      <td>-0.024982</td>\n",
              "      <td>0.132500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 768 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
              "480  -0.037427   0.068284  -0.100538   0.076783  -0.113147  -0.079453   \n",
              "481   0.024931   0.045966   0.016385   0.028214  -0.092396  -0.053490   \n",
              "482   0.025077   0.082511   0.074441   0.124308  -0.037937  -0.089271   \n",
              "483   0.030733   0.060249   0.099119   0.087801  -0.035729  -0.152115   \n",
              "484   0.012062   0.068691   0.051343   0.049753   0.006491  -0.107100   \n",
              "\n",
              "     feature_7  feature_8  feature_9  feature_10  ...  feature_759  \\\n",
              "480   0.106947   0.011906  -0.047519    0.022915  ...     0.061858   \n",
              "481  -0.018101   0.053902   0.080196    0.010693  ...     0.048435   \n",
              "482   0.012489  -0.036005  -0.023984   -0.010576  ...    -0.081554   \n",
              "483   0.032606   0.024821   0.032655    0.053826  ...     0.039644   \n",
              "484   0.076212   0.004650   0.113739    0.004015  ...    -0.028502   \n",
              "\n",
              "     feature_760  feature_761  feature_762  feature_763  feature_764  \\\n",
              "480     0.086089     0.004285    -0.325560    -0.035784     0.033521   \n",
              "481     0.127840     0.060487    -0.268356    -0.001359     0.019178   \n",
              "482     0.121891     0.042131    -0.019572    -0.095350     0.087392   \n",
              "483     0.094773    -0.043471    -0.177032    -0.091252     0.031182   \n",
              "484     0.123084     0.046536    -0.053508    -0.025445     0.062129   \n",
              "\n",
              "     feature_765  feature_766  feature_767  feature_768  \n",
              "480    -0.025551     0.083790    -0.027678    -0.008546  \n",
              "481     0.068597     0.066214     0.141953     0.075839  \n",
              "482     0.007523     0.030705     0.086901     0.031186  \n",
              "483    -0.034731     0.004988     0.143666    -0.012354  \n",
              "484    -0.034741     0.042223    -0.024982     0.132500  \n",
              "\n",
              "[5 rows x 768 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train['label_2'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9F-q9lf2yGK"
      },
      "source": [
        "### Classifires"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nbaLk6MO1K8L"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def svm_classifier(x_train, y_train, x_valid, y_valid):\n",
        "  model = SVC(kernel='linear')\n",
        "  model.fit(x_train, y_train)\n",
        "  y_predict = model.predict(x_valid)\n",
        "  accuracy = accuracy_score(y_valid, y_predict)\n",
        "  return accuracy\n",
        "\n",
        "def weighted_svm_classifier(x_train, y_train, x_valid, y_valid):\n",
        "  model = SVC(kernel='linear', class_weight='balanced')\n",
        "  model.fit(x_train, y_train)\n",
        "  y_predict = model.predict(x_valid)\n",
        "  accuracy = accuracy_score(y_valid, y_predict)\n",
        "  return accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9IRNfkhz3VSf"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "def xgb_classifier(x_train, y_train, x_valid, y_valid):\n",
        "  model = xgb.XGBClassifier()\n",
        "  model.fit(x_train, y_train)\n",
        "  y_predict = model.predict(x_valid)\n",
        "  accuracy = accuracy_score(y_valid, y_predict)\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LBz5GoTyumk"
      },
      "source": [
        "### Grid Search / Random Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "agXQQLdLy0rv"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "def random_grid_search(model, param_dist, cv, n_iter, x_train, y_train):\n",
        "\n",
        "  random_search = RandomizedSearchCV(\n",
        "      estimator=model,\n",
        "      param_distributions=param_dist,\n",
        "      scoring='accuracy',\n",
        "      cv=cv,\n",
        "      verbose=1,\n",
        "      n_jobs=-1,\n",
        "      n_iter=n_iter\n",
        "  )\n",
        "\n",
        "  random_search.fit(x_train, y_train)\n",
        "\n",
        "  return random_search\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def grid_search(model, param_dist, cv, x_train, y_train):\n",
        "\n",
        "  grid_search = GridSearchCV(\n",
        "      estimator=model,\n",
        "      param_grid=param_dist,\n",
        "      scoring='accuracy',\n",
        "      cv=cv,\n",
        "      verbose=1,\n",
        "      n_jobs=-1\n",
        "  )\n",
        "\n",
        "  grid_search.fit(x_train, y_train)\n",
        "\n",
        "  return grid_search\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def k_fold_cross_validation(model, k, x_train, y_train):\n",
        "\n",
        "    scores = cross_val_score(model, x_train, y_train, cv=k)\n",
        "    mean_score = np.mean(scores)\n",
        "    std_deviation = np.std(scores)\n",
        "    print(\"Cross-Validation Scores:\", scores)\n",
        "    print(\"Mean Score:\", mean_score)\n",
        "    print(\"Standard Deviation:\", std_deviation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLmbK_vUP8EV"
      },
      "source": [
        "## Label 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "Yq9CpFLiSRjj",
        "outputId": "3dbb3d8a-ffe4-4aa1-874c-b9e698ac05ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot: xlabel='label_1', ylabel='count'>"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "\n",
        "L1 = 'label_1'\n",
        "\n",
        "plt.figure(figsize=(18,6))\n",
        "sn.countplot(data=y_train, x=L1, color='blue')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Initial Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOHeNnVdZ34U",
        "outputId": "0a68dfb6-7226-4824-ade4-6a95c112f87e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy = 0.9693333333333334\n"
          ]
        }
      ],
      "source": [
        "accuracy = svm_classifier(x_train[L1], y_train[L1], x_valid[L1], y_valid[L1])\n",
        "print(f\"Accuracy = {accuracy}\")\n",
        "# accuracy = xgb_classifier(x_train[L1], y_train[L1]-1, x_valid[L1], y_valid[L1]-1)\n",
        "# print(f\"Accuracy = {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6JAQS1QXCpj"
      },
      "source": [
        "#### Correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aoLK40S_TMVV"
      },
      "outputs": [],
      "source": [
        "corr_matrix_l1 = x_train[L1].corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "kYtJbnyTTv_e",
        "outputId": "13748243-6ff7-4a79-b47e-a8d82e47ac28"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ca46b420-2a07-4348-9631-b4e6d9af244e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>feature_10</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_759</th>\n",
              "      <th>feature_760</th>\n",
              "      <th>feature_761</th>\n",
              "      <th>feature_762</th>\n",
              "      <th>feature_763</th>\n",
              "      <th>feature_764</th>\n",
              "      <th>feature_765</th>\n",
              "      <th>feature_766</th>\n",
              "      <th>feature_767</th>\n",
              "      <th>feature_768</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>feature_1</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.065348</td>\n",
              "      <td>-0.039416</td>\n",
              "      <td>0.116528</td>\n",
              "      <td>0.108225</td>\n",
              "      <td>-0.163679</td>\n",
              "      <td>0.131004</td>\n",
              "      <td>-0.073198</td>\n",
              "      <td>-0.045476</td>\n",
              "      <td>-0.120560</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225724</td>\n",
              "      <td>0.290177</td>\n",
              "      <td>0.015310</td>\n",
              "      <td>0.144664</td>\n",
              "      <td>-0.110313</td>\n",
              "      <td>-0.040330</td>\n",
              "      <td>0.132620</td>\n",
              "      <td>0.032706</td>\n",
              "      <td>0.035296</td>\n",
              "      <td>-0.039317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_2</th>\n",
              "      <td>0.065348</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.043611</td>\n",
              "      <td>0.068624</td>\n",
              "      <td>-0.278709</td>\n",
              "      <td>0.052155</td>\n",
              "      <td>-0.267946</td>\n",
              "      <td>-0.214403</td>\n",
              "      <td>-0.235840</td>\n",
              "      <td>-0.056829</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.150852</td>\n",
              "      <td>-0.096604</td>\n",
              "      <td>0.287950</td>\n",
              "      <td>-0.099087</td>\n",
              "      <td>0.269144</td>\n",
              "      <td>0.005612</td>\n",
              "      <td>-0.068710</td>\n",
              "      <td>-0.204834</td>\n",
              "      <td>-0.350866</td>\n",
              "      <td>0.162593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_3</th>\n",
              "      <td>-0.039416</td>\n",
              "      <td>0.043611</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.185437</td>\n",
              "      <td>-0.313107</td>\n",
              "      <td>-0.103496</td>\n",
              "      <td>-0.214606</td>\n",
              "      <td>-0.185952</td>\n",
              "      <td>0.155197</td>\n",
              "      <td>0.011407</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.248988</td>\n",
              "      <td>-0.162378</td>\n",
              "      <td>-0.024814</td>\n",
              "      <td>0.162806</td>\n",
              "      <td>0.231606</td>\n",
              "      <td>0.204807</td>\n",
              "      <td>0.133835</td>\n",
              "      <td>-0.063354</td>\n",
              "      <td>0.159975</td>\n",
              "      <td>0.217143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_4</th>\n",
              "      <td>0.116528</td>\n",
              "      <td>0.068624</td>\n",
              "      <td>-0.185437</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.096349</td>\n",
              "      <td>-0.220416</td>\n",
              "      <td>0.194002</td>\n",
              "      <td>0.027816</td>\n",
              "      <td>-0.144393</td>\n",
              "      <td>-0.148927</td>\n",
              "      <td>...</td>\n",
              "      <td>0.135598</td>\n",
              "      <td>0.071113</td>\n",
              "      <td>-0.084978</td>\n",
              "      <td>-0.166751</td>\n",
              "      <td>-0.220446</td>\n",
              "      <td>0.103712</td>\n",
              "      <td>0.100221</td>\n",
              "      <td>0.006758</td>\n",
              "      <td>0.034292</td>\n",
              "      <td>-0.128138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_5</th>\n",
              "      <td>0.108225</td>\n",
              "      <td>-0.278709</td>\n",
              "      <td>-0.313107</td>\n",
              "      <td>0.096349</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.021056</td>\n",
              "      <td>0.325761</td>\n",
              "      <td>-0.000900</td>\n",
              "      <td>0.038333</td>\n",
              "      <td>-0.116997</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.020572</td>\n",
              "      <td>0.024932</td>\n",
              "      <td>-0.202849</td>\n",
              "      <td>0.031865</td>\n",
              "      <td>-0.371326</td>\n",
              "      <td>-0.087327</td>\n",
              "      <td>-0.063512</td>\n",
              "      <td>0.016875</td>\n",
              "      <td>-0.031415</td>\n",
              "      <td>-0.203071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_764</th>\n",
              "      <td>-0.040330</td>\n",
              "      <td>0.005612</td>\n",
              "      <td>0.204807</td>\n",
              "      <td>0.103712</td>\n",
              "      <td>-0.087327</td>\n",
              "      <td>-0.174192</td>\n",
              "      <td>0.122454</td>\n",
              "      <td>0.012446</td>\n",
              "      <td>0.199985</td>\n",
              "      <td>0.171440</td>\n",
              "      <td>...</td>\n",
              "      <td>0.075743</td>\n",
              "      <td>0.065512</td>\n",
              "      <td>-0.313912</td>\n",
              "      <td>-0.196618</td>\n",
              "      <td>-0.114188</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.208730</td>\n",
              "      <td>0.181622</td>\n",
              "      <td>0.405485</td>\n",
              "      <td>-0.009266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_765</th>\n",
              "      <td>0.132620</td>\n",
              "      <td>-0.068710</td>\n",
              "      <td>0.133835</td>\n",
              "      <td>0.100221</td>\n",
              "      <td>-0.063512</td>\n",
              "      <td>-0.345465</td>\n",
              "      <td>-0.002038</td>\n",
              "      <td>0.005804</td>\n",
              "      <td>0.053829</td>\n",
              "      <td>-0.116723</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.103060</td>\n",
              "      <td>0.180543</td>\n",
              "      <td>-0.010908</td>\n",
              "      <td>-0.076788</td>\n",
              "      <td>0.228983</td>\n",
              "      <td>0.208730</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.204636</td>\n",
              "      <td>0.278358</td>\n",
              "      <td>-0.172730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_766</th>\n",
              "      <td>0.032706</td>\n",
              "      <td>-0.204834</td>\n",
              "      <td>-0.063354</td>\n",
              "      <td>0.006758</td>\n",
              "      <td>0.016875</td>\n",
              "      <td>-0.233690</td>\n",
              "      <td>0.282928</td>\n",
              "      <td>-0.105139</td>\n",
              "      <td>0.097498</td>\n",
              "      <td>0.391228</td>\n",
              "      <td>...</td>\n",
              "      <td>0.096985</td>\n",
              "      <td>0.293527</td>\n",
              "      <td>-0.266795</td>\n",
              "      <td>0.168379</td>\n",
              "      <td>-0.486373</td>\n",
              "      <td>0.181622</td>\n",
              "      <td>-0.204636</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.388446</td>\n",
              "      <td>-0.065182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_767</th>\n",
              "      <td>0.035296</td>\n",
              "      <td>-0.350866</td>\n",
              "      <td>0.159975</td>\n",
              "      <td>0.034292</td>\n",
              "      <td>-0.031415</td>\n",
              "      <td>-0.350340</td>\n",
              "      <td>0.185927</td>\n",
              "      <td>0.045446</td>\n",
              "      <td>0.113304</td>\n",
              "      <td>0.265687</td>\n",
              "      <td>...</td>\n",
              "      <td>0.115303</td>\n",
              "      <td>0.274362</td>\n",
              "      <td>-0.343106</td>\n",
              "      <td>0.081103</td>\n",
              "      <td>-0.327079</td>\n",
              "      <td>0.405485</td>\n",
              "      <td>0.278358</td>\n",
              "      <td>0.388446</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.132940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_768</th>\n",
              "      <td>-0.039317</td>\n",
              "      <td>0.162593</td>\n",
              "      <td>0.217143</td>\n",
              "      <td>-0.128138</td>\n",
              "      <td>-0.203071</td>\n",
              "      <td>0.242545</td>\n",
              "      <td>-0.390389</td>\n",
              "      <td>-0.033126</td>\n",
              "      <td>0.020400</td>\n",
              "      <td>-0.093904</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.012714</td>\n",
              "      <td>-0.117084</td>\n",
              "      <td>0.191413</td>\n",
              "      <td>0.091538</td>\n",
              "      <td>0.299900</td>\n",
              "      <td>-0.009266</td>\n",
              "      <td>-0.172730</td>\n",
              "      <td>-0.065182</td>\n",
              "      <td>-0.132940</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows Ã— 768 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca46b420-2a07-4348-9631-b4e6d9af244e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ca46b420-2a07-4348-9631-b4e6d9af244e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ca46b420-2a07-4348-9631-b4e6d9af244e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-abf0b056-bd94-4313-a042-232931212ad8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-abf0b056-bd94-4313-a042-232931212ad8')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-abf0b056-bd94-4313-a042-232931212ad8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "             feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
              "feature_1     1.000000   0.065348  -0.039416   0.116528   0.108225  -0.163679   \n",
              "feature_2     0.065348   1.000000   0.043611   0.068624  -0.278709   0.052155   \n",
              "feature_3    -0.039416   0.043611   1.000000  -0.185437  -0.313107  -0.103496   \n",
              "feature_4     0.116528   0.068624  -0.185437   1.000000   0.096349  -0.220416   \n",
              "feature_5     0.108225  -0.278709  -0.313107   0.096349   1.000000   0.021056   \n",
              "...                ...        ...        ...        ...        ...        ...   \n",
              "feature_764  -0.040330   0.005612   0.204807   0.103712  -0.087327  -0.174192   \n",
              "feature_765   0.132620  -0.068710   0.133835   0.100221  -0.063512  -0.345465   \n",
              "feature_766   0.032706  -0.204834  -0.063354   0.006758   0.016875  -0.233690   \n",
              "feature_767   0.035296  -0.350866   0.159975   0.034292  -0.031415  -0.350340   \n",
              "feature_768  -0.039317   0.162593   0.217143  -0.128138  -0.203071   0.242545   \n",
              "\n",
              "             feature_7  feature_8  feature_9  feature_10  ...  feature_759  \\\n",
              "feature_1     0.131004  -0.073198  -0.045476   -0.120560  ...    -0.225724   \n",
              "feature_2    -0.267946  -0.214403  -0.235840   -0.056829  ...    -0.150852   \n",
              "feature_3    -0.214606  -0.185952   0.155197    0.011407  ...    -0.248988   \n",
              "feature_4     0.194002   0.027816  -0.144393   -0.148927  ...     0.135598   \n",
              "feature_5     0.325761  -0.000900   0.038333   -0.116997  ...    -0.020572   \n",
              "...                ...        ...        ...         ...  ...          ...   \n",
              "feature_764   0.122454   0.012446   0.199985    0.171440  ...     0.075743   \n",
              "feature_765  -0.002038   0.005804   0.053829   -0.116723  ...    -0.103060   \n",
              "feature_766   0.282928  -0.105139   0.097498    0.391228  ...     0.096985   \n",
              "feature_767   0.185927   0.045446   0.113304    0.265687  ...     0.115303   \n",
              "feature_768  -0.390389  -0.033126   0.020400   -0.093904  ...    -0.012714   \n",
              "\n",
              "             feature_760  feature_761  feature_762  feature_763  feature_764  \\\n",
              "feature_1       0.290177     0.015310     0.144664    -0.110313    -0.040330   \n",
              "feature_2      -0.096604     0.287950    -0.099087     0.269144     0.005612   \n",
              "feature_3      -0.162378    -0.024814     0.162806     0.231606     0.204807   \n",
              "feature_4       0.071113    -0.084978    -0.166751    -0.220446     0.103712   \n",
              "feature_5       0.024932    -0.202849     0.031865    -0.371326    -0.087327   \n",
              "...                  ...          ...          ...          ...          ...   \n",
              "feature_764     0.065512    -0.313912    -0.196618    -0.114188     1.000000   \n",
              "feature_765     0.180543    -0.010908    -0.076788     0.228983     0.208730   \n",
              "feature_766     0.293527    -0.266795     0.168379    -0.486373     0.181622   \n",
              "feature_767     0.274362    -0.343106     0.081103    -0.327079     0.405485   \n",
              "feature_768    -0.117084     0.191413     0.091538     0.299900    -0.009266   \n",
              "\n",
              "             feature_765  feature_766  feature_767  feature_768  \n",
              "feature_1       0.132620     0.032706     0.035296    -0.039317  \n",
              "feature_2      -0.068710    -0.204834    -0.350866     0.162593  \n",
              "feature_3       0.133835    -0.063354     0.159975     0.217143  \n",
              "feature_4       0.100221     0.006758     0.034292    -0.128138  \n",
              "feature_5      -0.063512     0.016875    -0.031415    -0.203071  \n",
              "...                  ...          ...          ...          ...  \n",
              "feature_764     0.208730     0.181622     0.405485    -0.009266  \n",
              "feature_765     1.000000    -0.204636     0.278358    -0.172730  \n",
              "feature_766    -0.204636     1.000000     0.388446    -0.065182  \n",
              "feature_767     0.278358     0.388446     1.000000    -0.132940  \n",
              "feature_768    -0.172730    -0.065182    -0.132940     1.000000  \n",
              "\n",
              "[768 rows x 768 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corr_matrix_l1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CUISG7RyXf2u"
      },
      "outputs": [],
      "source": [
        "def get_corr_features(corr_matrix, threshold):\n",
        "\n",
        "  correlated_features = []\n",
        "\n",
        "  for i in range(len(corr_matrix.columns)):\n",
        "    for j in range(i+1, len(corr_matrix.columns)):\n",
        "      if (abs(corr_matrix.iloc[i, j]) > threshold):\n",
        "        col_name = corr_matrix.columns[j]\n",
        "        if col_name not in correlated_features:\n",
        "          correlated_features.append(col_name)\n",
        "\n",
        "  return correlated_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3D6Sbv9Ya39c",
        "outputId": "0649912e-2a7c-45ab-de9b-6e6adf24dd21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n"
          ]
        }
      ],
      "source": [
        "correlated_features_l1 = get_corr_features(corr_matrix_l1, 0.7)\n",
        "print(len(correlated_features_l1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQE4ZYMeKqj1"
      },
      "source": [
        "#### PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "l5k-Wm2DKulX"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "x_test_l1 = x_test.copy()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train[L1] = pd.DataFrame(scaler.fit_transform(x_train[L1]), columns=FEATURES)\n",
        "x_valid[L1] = pd.DataFrame(scaler.transform(x_valid[L1]), columns=FEATURES)\n",
        "x_test_l1 = pd.DataFrame(scaler.transform(x_test_l1), columns=FEATURES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN98_Gi5aU17",
        "outputId": "22fce5b6-c971-41f4-f57d-7e9374f9daea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of features: 350\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "threshold = 0.96\n",
        "\n",
        "pca = PCA(n_components=threshold, svd_solver='full')\n",
        "x_train_l1_pca = pd.DataFrame(pca.fit_transform(x_train[L1]))\n",
        "x_valid_l1_pca = pd.DataFrame(pca.transform(x_valid[L1]))\n",
        "x_test_l1_pca = pd.DataFrame(pca.transform(x_test_l1))\n",
        "\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "\n",
        "print(f\"Number of features: {len(explained_variance)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asP6QOkfacvy",
        "outputId": "aa4f73c8-1cea-4fab-ed50-c0379cc42b78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy = 0.9333333333333333\n"
          ]
        }
      ],
      "source": [
        "accuracy_1 = svm_classifier(x_train_l1_pca, y_train[L1], x_valid_l1_pca, y_valid[L1])\n",
        "print(f\"Accuracy = {accuracy_1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgSvtyBUdDxc"
      },
      "source": [
        "#### Hyperparameter Tuning - Random Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYIAt9GtdHIT",
        "outputId": "dfbd9633-0fd4-468f-e455-06c921afb4e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "{'kernel': 'rbf', 'gamma': 0.001, 'C': 1000.0}\n",
            "0.9417601683029453\n"
          ]
        }
      ],
      "source": [
        "param_dist = {\n",
        "    'C': np.logspace(-3, 3, 7),\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'gamma': np.logspace(-3, 3, 7)\n",
        "}\n",
        "cv = 2\n",
        "n_iter = 5\n",
        "svm = SVC()\n",
        "\n",
        "# random_search_l1 = grid_search(svm, param_dist, cv, x_train_l1_pca, y_train[L1])\n",
        "random_search_l1 = random_grid_search(svm, param_dist, cv, n_iter, x_train_l1_pca, y_train[L1])\n",
        "best_model_l1 = random_search_l1.best_estimator_\n",
        "best_accuracy_l1 = random_search_l1.best_score_\n",
        "best_param = random_search_l1.best_params_\n",
        "\n",
        "print(best_param)\n",
        "print(best_accuracy_l1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy after: 0.9613333333333334\n"
          ]
        }
      ],
      "source": [
        "y_pred_l1 = best_model_l1.predict(x_valid_l1_pca)\n",
        "accuracy = accuracy_score(y_valid[L1], y_pred_l1)\n",
        "print(f\"Accuracy after: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-Validation Scores: [0.95564516 0.95704769 0.95371669 0.95196353 0.95704769]\n",
            "Mean Score: 0.9550841514726507\n",
            "Standard Deviation: 0.001981608857074996\n"
          ]
        }
      ],
      "source": [
        "model = SVC(kernel= 'rbf', gamma= 0.001, C= 1000.0)\n",
        "\n",
        "k_fold_cross_validation(model, 5, x_train_l1_pca, y_train[L1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRH_NdswedzL"
      },
      "source": [
        "## Label 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "YAMMp3VJedzV",
        "outputId": "72155a8e-b778-4a0d-b404-628d7587a0c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot: xlabel='label_2', ylabel='count'>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "\n",
        "L2 = 'label_2'\n",
        "\n",
        "plt.figure(figsize=(18,6))\n",
        "sn.countplot(data=y_train, x=L2, color='blue')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Initial Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "-eUyfsE-edzV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy = 0.8233695652173914\n"
          ]
        }
      ],
      "source": [
        "accuracy = weighted_svm_classifier(x_train[L2], y_train[L2], x_valid[L2], y_valid[L2])\n",
        "print(f\"Accuracy = {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tmfnrgTedzV"
      },
      "source": [
        "#### Correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "TvfltvkmedzW"
      },
      "outputs": [],
      "source": [
        "corr_matrix_l2 = x_train[L2].corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "gsUZ9F4tedzW",
        "outputId": "13748243-6ff7-4a79-b47e-a8d82e47ac28"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>feature_10</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_759</th>\n",
              "      <th>feature_760</th>\n",
              "      <th>feature_761</th>\n",
              "      <th>feature_762</th>\n",
              "      <th>feature_763</th>\n",
              "      <th>feature_764</th>\n",
              "      <th>feature_765</th>\n",
              "      <th>feature_766</th>\n",
              "      <th>feature_767</th>\n",
              "      <th>feature_768</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>feature_1</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.056876</td>\n",
              "      <td>-0.039498</td>\n",
              "      <td>0.118076</td>\n",
              "      <td>0.112851</td>\n",
              "      <td>-0.166600</td>\n",
              "      <td>0.137696</td>\n",
              "      <td>-0.072975</td>\n",
              "      <td>-0.043850</td>\n",
              "      <td>-0.113356</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225903</td>\n",
              "      <td>0.293434</td>\n",
              "      <td>0.009847</td>\n",
              "      <td>0.145848</td>\n",
              "      <td>-0.115566</td>\n",
              "      <td>-0.034812</td>\n",
              "      <td>0.134990</td>\n",
              "      <td>0.038377</td>\n",
              "      <td>0.038189</td>\n",
              "      <td>-0.047894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_2</th>\n",
              "      <td>0.056876</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.047595</td>\n",
              "      <td>0.063880</td>\n",
              "      <td>-0.275346</td>\n",
              "      <td>0.051292</td>\n",
              "      <td>-0.265063</td>\n",
              "      <td>-0.212084</td>\n",
              "      <td>-0.233523</td>\n",
              "      <td>-0.044382</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.151111</td>\n",
              "      <td>-0.094786</td>\n",
              "      <td>0.281682</td>\n",
              "      <td>-0.099535</td>\n",
              "      <td>0.265121</td>\n",
              "      <td>0.015314</td>\n",
              "      <td>-0.066985</td>\n",
              "      <td>-0.197673</td>\n",
              "      <td>-0.344760</td>\n",
              "      <td>0.158917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_3</th>\n",
              "      <td>-0.039498</td>\n",
              "      <td>0.047595</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.180691</td>\n",
              "      <td>-0.317822</td>\n",
              "      <td>-0.105887</td>\n",
              "      <td>-0.218088</td>\n",
              "      <td>-0.187760</td>\n",
              "      <td>0.148033</td>\n",
              "      <td>0.008087</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.249580</td>\n",
              "      <td>-0.162531</td>\n",
              "      <td>-0.022784</td>\n",
              "      <td>0.165992</td>\n",
              "      <td>0.233145</td>\n",
              "      <td>0.205415</td>\n",
              "      <td>0.134334</td>\n",
              "      <td>-0.068711</td>\n",
              "      <td>0.158498</td>\n",
              "      <td>0.214362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_4</th>\n",
              "      <td>0.118076</td>\n",
              "      <td>0.063880</td>\n",
              "      <td>-0.180691</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.100580</td>\n",
              "      <td>-0.220944</td>\n",
              "      <td>0.196603</td>\n",
              "      <td>0.031122</td>\n",
              "      <td>-0.141089</td>\n",
              "      <td>-0.146779</td>\n",
              "      <td>...</td>\n",
              "      <td>0.135778</td>\n",
              "      <td>0.075056</td>\n",
              "      <td>-0.089173</td>\n",
              "      <td>-0.170199</td>\n",
              "      <td>-0.221257</td>\n",
              "      <td>0.106697</td>\n",
              "      <td>0.103314</td>\n",
              "      <td>0.013078</td>\n",
              "      <td>0.040056</td>\n",
              "      <td>-0.126484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_5</th>\n",
              "      <td>0.112851</td>\n",
              "      <td>-0.275346</td>\n",
              "      <td>-0.317822</td>\n",
              "      <td>0.100580</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.024638</td>\n",
              "      <td>0.323135</td>\n",
              "      <td>-0.001072</td>\n",
              "      <td>0.033806</td>\n",
              "      <td>-0.122683</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.017675</td>\n",
              "      <td>0.020871</td>\n",
              "      <td>-0.198018</td>\n",
              "      <td>0.029311</td>\n",
              "      <td>-0.369320</td>\n",
              "      <td>-0.092976</td>\n",
              "      <td>-0.067953</td>\n",
              "      <td>0.012496</td>\n",
              "      <td>-0.039707</td>\n",
              "      <td>-0.199933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_764</th>\n",
              "      <td>-0.034812</td>\n",
              "      <td>0.015314</td>\n",
              "      <td>0.205415</td>\n",
              "      <td>0.106697</td>\n",
              "      <td>-0.092976</td>\n",
              "      <td>-0.172826</td>\n",
              "      <td>0.116927</td>\n",
              "      <td>0.012693</td>\n",
              "      <td>0.201621</td>\n",
              "      <td>0.168050</td>\n",
              "      <td>...</td>\n",
              "      <td>0.069499</td>\n",
              "      <td>0.071036</td>\n",
              "      <td>-0.309803</td>\n",
              "      <td>-0.196119</td>\n",
              "      <td>-0.108149</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.207256</td>\n",
              "      <td>0.176582</td>\n",
              "      <td>0.402581</td>\n",
              "      <td>-0.006868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_765</th>\n",
              "      <td>0.134990</td>\n",
              "      <td>-0.066985</td>\n",
              "      <td>0.134334</td>\n",
              "      <td>0.103314</td>\n",
              "      <td>-0.067953</td>\n",
              "      <td>-0.344325</td>\n",
              "      <td>-0.006739</td>\n",
              "      <td>0.005132</td>\n",
              "      <td>0.054664</td>\n",
              "      <td>-0.120180</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.105545</td>\n",
              "      <td>0.182059</td>\n",
              "      <td>-0.009149</td>\n",
              "      <td>-0.075866</td>\n",
              "      <td>0.231146</td>\n",
              "      <td>0.207256</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.207324</td>\n",
              "      <td>0.276912</td>\n",
              "      <td>-0.173424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_766</th>\n",
              "      <td>0.038377</td>\n",
              "      <td>-0.197673</td>\n",
              "      <td>-0.068711</td>\n",
              "      <td>0.013078</td>\n",
              "      <td>0.012496</td>\n",
              "      <td>-0.237159</td>\n",
              "      <td>0.279386</td>\n",
              "      <td>-0.107323</td>\n",
              "      <td>0.094012</td>\n",
              "      <td>0.386221</td>\n",
              "      <td>...</td>\n",
              "      <td>0.101085</td>\n",
              "      <td>0.295610</td>\n",
              "      <td>-0.266255</td>\n",
              "      <td>0.167763</td>\n",
              "      <td>-0.485058</td>\n",
              "      <td>0.176582</td>\n",
              "      <td>-0.207324</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.385526</td>\n",
              "      <td>-0.064913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_767</th>\n",
              "      <td>0.038189</td>\n",
              "      <td>-0.344760</td>\n",
              "      <td>0.158498</td>\n",
              "      <td>0.040056</td>\n",
              "      <td>-0.039707</td>\n",
              "      <td>-0.347955</td>\n",
              "      <td>0.181550</td>\n",
              "      <td>0.041326</td>\n",
              "      <td>0.109208</td>\n",
              "      <td>0.260041</td>\n",
              "      <td>...</td>\n",
              "      <td>0.118570</td>\n",
              "      <td>0.277248</td>\n",
              "      <td>-0.337285</td>\n",
              "      <td>0.080803</td>\n",
              "      <td>-0.323770</td>\n",
              "      <td>0.402581</td>\n",
              "      <td>0.276912</td>\n",
              "      <td>0.385526</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.133094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_768</th>\n",
              "      <td>-0.047894</td>\n",
              "      <td>0.158917</td>\n",
              "      <td>0.214362</td>\n",
              "      <td>-0.126484</td>\n",
              "      <td>-0.199933</td>\n",
              "      <td>0.242825</td>\n",
              "      <td>-0.389481</td>\n",
              "      <td>-0.031580</td>\n",
              "      <td>0.022276</td>\n",
              "      <td>-0.086748</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.012334</td>\n",
              "      <td>-0.116659</td>\n",
              "      <td>0.186684</td>\n",
              "      <td>0.089587</td>\n",
              "      <td>0.296990</td>\n",
              "      <td>-0.006868</td>\n",
              "      <td>-0.173424</td>\n",
              "      <td>-0.064913</td>\n",
              "      <td>-0.133094</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows Ã— 768 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
              "feature_1     1.000000   0.056876  -0.039498   0.118076   0.112851  -0.166600   \n",
              "feature_2     0.056876   1.000000   0.047595   0.063880  -0.275346   0.051292   \n",
              "feature_3    -0.039498   0.047595   1.000000  -0.180691  -0.317822  -0.105887   \n",
              "feature_4     0.118076   0.063880  -0.180691   1.000000   0.100580  -0.220944   \n",
              "feature_5     0.112851  -0.275346  -0.317822   0.100580   1.000000   0.024638   \n",
              "...                ...        ...        ...        ...        ...        ...   \n",
              "feature_764  -0.034812   0.015314   0.205415   0.106697  -0.092976  -0.172826   \n",
              "feature_765   0.134990  -0.066985   0.134334   0.103314  -0.067953  -0.344325   \n",
              "feature_766   0.038377  -0.197673  -0.068711   0.013078   0.012496  -0.237159   \n",
              "feature_767   0.038189  -0.344760   0.158498   0.040056  -0.039707  -0.347955   \n",
              "feature_768  -0.047894   0.158917   0.214362  -0.126484  -0.199933   0.242825   \n",
              "\n",
              "             feature_7  feature_8  feature_9  feature_10  ...  feature_759  \\\n",
              "feature_1     0.137696  -0.072975  -0.043850   -0.113356  ...    -0.225903   \n",
              "feature_2    -0.265063  -0.212084  -0.233523   -0.044382  ...    -0.151111   \n",
              "feature_3    -0.218088  -0.187760   0.148033    0.008087  ...    -0.249580   \n",
              "feature_4     0.196603   0.031122  -0.141089   -0.146779  ...     0.135778   \n",
              "feature_5     0.323135  -0.001072   0.033806   -0.122683  ...    -0.017675   \n",
              "...                ...        ...        ...         ...  ...          ...   \n",
              "feature_764   0.116927   0.012693   0.201621    0.168050  ...     0.069499   \n",
              "feature_765  -0.006739   0.005132   0.054664   -0.120180  ...    -0.105545   \n",
              "feature_766   0.279386  -0.107323   0.094012    0.386221  ...     0.101085   \n",
              "feature_767   0.181550   0.041326   0.109208    0.260041  ...     0.118570   \n",
              "feature_768  -0.389481  -0.031580   0.022276   -0.086748  ...    -0.012334   \n",
              "\n",
              "             feature_760  feature_761  feature_762  feature_763  feature_764  \\\n",
              "feature_1       0.293434     0.009847     0.145848    -0.115566    -0.034812   \n",
              "feature_2      -0.094786     0.281682    -0.099535     0.265121     0.015314   \n",
              "feature_3      -0.162531    -0.022784     0.165992     0.233145     0.205415   \n",
              "feature_4       0.075056    -0.089173    -0.170199    -0.221257     0.106697   \n",
              "feature_5       0.020871    -0.198018     0.029311    -0.369320    -0.092976   \n",
              "...                  ...          ...          ...          ...          ...   \n",
              "feature_764     0.071036    -0.309803    -0.196119    -0.108149     1.000000   \n",
              "feature_765     0.182059    -0.009149    -0.075866     0.231146     0.207256   \n",
              "feature_766     0.295610    -0.266255     0.167763    -0.485058     0.176582   \n",
              "feature_767     0.277248    -0.337285     0.080803    -0.323770     0.402581   \n",
              "feature_768    -0.116659     0.186684     0.089587     0.296990    -0.006868   \n",
              "\n",
              "             feature_765  feature_766  feature_767  feature_768  \n",
              "feature_1       0.134990     0.038377     0.038189    -0.047894  \n",
              "feature_2      -0.066985    -0.197673    -0.344760     0.158917  \n",
              "feature_3       0.134334    -0.068711     0.158498     0.214362  \n",
              "feature_4       0.103314     0.013078     0.040056    -0.126484  \n",
              "feature_5      -0.067953     0.012496    -0.039707    -0.199933  \n",
              "...                  ...          ...          ...          ...  \n",
              "feature_764     0.207256     0.176582     0.402581    -0.006868  \n",
              "feature_765     1.000000    -0.207324     0.276912    -0.173424  \n",
              "feature_766    -0.207324     1.000000     0.385526    -0.064913  \n",
              "feature_767     0.276912     0.385526     1.000000    -0.133094  \n",
              "feature_768    -0.173424    -0.064913    -0.133094     1.000000  \n",
              "\n",
              "[768 rows x 768 columns]"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corr_matrix_l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "titlexI-edzX"
      },
      "outputs": [],
      "source": [
        "def get_corr_features(corr_matrix, threshold):\n",
        "\n",
        "  correlated_features = []\n",
        "\n",
        "  for i in range(len(corr_matrix.columns)):\n",
        "    for j in range(i+1, len(corr_matrix.columns)):\n",
        "      if (abs(corr_matrix.iloc[i, j]) > threshold):\n",
        "        col_name = corr_matrix.columns[j]\n",
        "        if col_name not in correlated_features:\n",
        "          correlated_features.append(col_name)\n",
        "\n",
        "  return correlated_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZN4S05bVedzX",
        "outputId": "0649912e-2a7c-45ab-de9b-6e6adf24dd21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n"
          ]
        }
      ],
      "source": [
        "correlated_features_l2 = get_corr_features(corr_matrix_l2, 0.7)\n",
        "print(len(correlated_features_l2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJE6imtMedzX"
      },
      "source": [
        "#### PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MHQLyqEqedzX"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "x_test_l2 = x_test.copy()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train[L2] = pd.DataFrame(scaler.fit_transform(x_train[L2]), columns=FEATURES)\n",
        "x_valid[L2] = pd.DataFrame(scaler.transform(x_valid[L2]), columns=FEATURES)\n",
        "x_test_l2 = pd.DataFrame(scaler.transform(x_test_l2), columns=FEATURES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kQAGGKpZedzY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of features: 350\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "threshold = 0.96\n",
        "\n",
        "pca = PCA(n_components=threshold, svd_solver='full')\n",
        "x_train_l2_pca = pd.DataFrame(pca.fit_transform(x_train[L2]))\n",
        "x_valid_l2_pca = pd.DataFrame(pca.transform(x_valid[L2]))\n",
        "x_test_l2_pca = pd.DataFrame(pca.transform(x_test_l2))\n",
        "\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "\n",
        "print(f\"Number of features: {len(explained_variance)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "--0z6WiQedzY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy = 0.8057065217391305\n"
          ]
        }
      ],
      "source": [
        "accuracy_1 = weighted_svm_classifier(x_train_l2_pca, y_train[L2], x_valid_l2_pca, y_valid[L2])\n",
        "print(f\"Accuracy = {accuracy_1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNo6SYfcedzY"
      },
      "source": [
        "#### Hyperparameter Tuning - Random Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "OuPhMkVyedzY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'kernel': 'poly', 'gamma': 100.0, 'class_weight': 'balanced', 'C': 100.0}\n",
            "0.2661198288159772\n"
          ]
        }
      ],
      "source": [
        "param_dist = {\n",
        "    'C': np.logspace(-3, 3, 7),\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'gamma': np.logspace(-3, 3, 7),\n",
        "    'class_weight': ['balanced']\n",
        "}\n",
        "cv = 2\n",
        "n_iter = 5\n",
        "svm = SVC()\n",
        "\n",
        "random_search_l2 = random_grid_search(svm, param_dist, cv, n_iter, x_train_l2_pca, y_train[L2])\n",
        "best_model_l2 = random_search_l2.best_estimator_\n",
        "best_accuracy_l2 = random_search_l2.best_score_\n",
        "best_param = random_search_l2.best_params_\n",
        "\n",
        "print(best_param)\n",
        "print(best_accuracy_l2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy after: 0.9347826086956522\n"
          ]
        }
      ],
      "source": [
        "y_pred_l2 = best_model_l2.predict(x_valid_l2_pca)\n",
        "accuracy = accuracy_score(y_valid[L2], y_pred_l2)\n",
        "print(f\"Accuracy after: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-Validation Scores: [0.45827389 0.69561341 0.71968616 0.72628388 0.50499287]\n",
            "Mean Score: 0.6209700427960058\n",
            "Standard Deviation: 0.11517660418375814\n"
          ]
        }
      ],
      "source": [
        "model = SVC(kernel= 'poly', gamma= 100.0, class_weight= 'balanced', C= 100.0)\n",
        "\n",
        "k_fold_cross_validation(model, 5, x_train_l2_pca, y_train[L2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Label 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot: xlabel='label_3', ylabel='count'>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "\n",
        "L3 = 'label_3'\n",
        "\n",
        "plt.figure(figsize=(18,6))\n",
        "sn.countplot(data=y_train, x=L3, color='blue')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Initial Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy = 0.9933333333333333\n"
          ]
        }
      ],
      "source": [
        "accuracy = weighted_svm_classifier(x_train[L3], y_train[L3], x_valid[L3], y_valid[L3])\n",
        "print(f\"Accuracy = {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_matrix_l3 = x_train[L3].corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>feature_10</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_759</th>\n",
              "      <th>feature_760</th>\n",
              "      <th>feature_761</th>\n",
              "      <th>feature_762</th>\n",
              "      <th>feature_763</th>\n",
              "      <th>feature_764</th>\n",
              "      <th>feature_765</th>\n",
              "      <th>feature_766</th>\n",
              "      <th>feature_767</th>\n",
              "      <th>feature_768</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>feature_1</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.065348</td>\n",
              "      <td>-0.039416</td>\n",
              "      <td>0.116528</td>\n",
              "      <td>0.108225</td>\n",
              "      <td>-0.163679</td>\n",
              "      <td>0.131004</td>\n",
              "      <td>-0.073198</td>\n",
              "      <td>-0.045476</td>\n",
              "      <td>-0.120560</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225724</td>\n",
              "      <td>0.290177</td>\n",
              "      <td>0.015310</td>\n",
              "      <td>0.144664</td>\n",
              "      <td>-0.110313</td>\n",
              "      <td>-0.040330</td>\n",
              "      <td>0.132620</td>\n",
              "      <td>0.032706</td>\n",
              "      <td>0.035296</td>\n",
              "      <td>-0.039317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_2</th>\n",
              "      <td>0.065348</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.043611</td>\n",
              "      <td>0.068624</td>\n",
              "      <td>-0.278709</td>\n",
              "      <td>0.052155</td>\n",
              "      <td>-0.267946</td>\n",
              "      <td>-0.214403</td>\n",
              "      <td>-0.235840</td>\n",
              "      <td>-0.056829</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.150852</td>\n",
              "      <td>-0.096604</td>\n",
              "      <td>0.287950</td>\n",
              "      <td>-0.099087</td>\n",
              "      <td>0.269144</td>\n",
              "      <td>0.005612</td>\n",
              "      <td>-0.068710</td>\n",
              "      <td>-0.204834</td>\n",
              "      <td>-0.350866</td>\n",
              "      <td>0.162593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_3</th>\n",
              "      <td>-0.039416</td>\n",
              "      <td>0.043611</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.185437</td>\n",
              "      <td>-0.313107</td>\n",
              "      <td>-0.103496</td>\n",
              "      <td>-0.214606</td>\n",
              "      <td>-0.185952</td>\n",
              "      <td>0.155197</td>\n",
              "      <td>0.011407</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.248988</td>\n",
              "      <td>-0.162378</td>\n",
              "      <td>-0.024814</td>\n",
              "      <td>0.162806</td>\n",
              "      <td>0.231606</td>\n",
              "      <td>0.204807</td>\n",
              "      <td>0.133835</td>\n",
              "      <td>-0.063354</td>\n",
              "      <td>0.159975</td>\n",
              "      <td>0.217143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_4</th>\n",
              "      <td>0.116528</td>\n",
              "      <td>0.068624</td>\n",
              "      <td>-0.185437</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.096349</td>\n",
              "      <td>-0.220416</td>\n",
              "      <td>0.194002</td>\n",
              "      <td>0.027816</td>\n",
              "      <td>-0.144393</td>\n",
              "      <td>-0.148927</td>\n",
              "      <td>...</td>\n",
              "      <td>0.135598</td>\n",
              "      <td>0.071113</td>\n",
              "      <td>-0.084978</td>\n",
              "      <td>-0.166751</td>\n",
              "      <td>-0.220446</td>\n",
              "      <td>0.103712</td>\n",
              "      <td>0.100221</td>\n",
              "      <td>0.006758</td>\n",
              "      <td>0.034292</td>\n",
              "      <td>-0.128138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_5</th>\n",
              "      <td>0.108225</td>\n",
              "      <td>-0.278709</td>\n",
              "      <td>-0.313107</td>\n",
              "      <td>0.096349</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.021056</td>\n",
              "      <td>0.325761</td>\n",
              "      <td>-0.000900</td>\n",
              "      <td>0.038333</td>\n",
              "      <td>-0.116997</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.020572</td>\n",
              "      <td>0.024932</td>\n",
              "      <td>-0.202849</td>\n",
              "      <td>0.031865</td>\n",
              "      <td>-0.371326</td>\n",
              "      <td>-0.087327</td>\n",
              "      <td>-0.063512</td>\n",
              "      <td>0.016875</td>\n",
              "      <td>-0.031415</td>\n",
              "      <td>-0.203071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_764</th>\n",
              "      <td>-0.040330</td>\n",
              "      <td>0.005612</td>\n",
              "      <td>0.204807</td>\n",
              "      <td>0.103712</td>\n",
              "      <td>-0.087327</td>\n",
              "      <td>-0.174192</td>\n",
              "      <td>0.122454</td>\n",
              "      <td>0.012446</td>\n",
              "      <td>0.199985</td>\n",
              "      <td>0.171440</td>\n",
              "      <td>...</td>\n",
              "      <td>0.075743</td>\n",
              "      <td>0.065512</td>\n",
              "      <td>-0.313912</td>\n",
              "      <td>-0.196618</td>\n",
              "      <td>-0.114188</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.208730</td>\n",
              "      <td>0.181622</td>\n",
              "      <td>0.405485</td>\n",
              "      <td>-0.009266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_765</th>\n",
              "      <td>0.132620</td>\n",
              "      <td>-0.068710</td>\n",
              "      <td>0.133835</td>\n",
              "      <td>0.100221</td>\n",
              "      <td>-0.063512</td>\n",
              "      <td>-0.345465</td>\n",
              "      <td>-0.002038</td>\n",
              "      <td>0.005804</td>\n",
              "      <td>0.053829</td>\n",
              "      <td>-0.116723</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.103060</td>\n",
              "      <td>0.180543</td>\n",
              "      <td>-0.010908</td>\n",
              "      <td>-0.076788</td>\n",
              "      <td>0.228983</td>\n",
              "      <td>0.208730</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.204636</td>\n",
              "      <td>0.278358</td>\n",
              "      <td>-0.172730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_766</th>\n",
              "      <td>0.032706</td>\n",
              "      <td>-0.204834</td>\n",
              "      <td>-0.063354</td>\n",
              "      <td>0.006758</td>\n",
              "      <td>0.016875</td>\n",
              "      <td>-0.233690</td>\n",
              "      <td>0.282928</td>\n",
              "      <td>-0.105139</td>\n",
              "      <td>0.097498</td>\n",
              "      <td>0.391228</td>\n",
              "      <td>...</td>\n",
              "      <td>0.096985</td>\n",
              "      <td>0.293527</td>\n",
              "      <td>-0.266795</td>\n",
              "      <td>0.168379</td>\n",
              "      <td>-0.486373</td>\n",
              "      <td>0.181622</td>\n",
              "      <td>-0.204636</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.388446</td>\n",
              "      <td>-0.065182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_767</th>\n",
              "      <td>0.035296</td>\n",
              "      <td>-0.350866</td>\n",
              "      <td>0.159975</td>\n",
              "      <td>0.034292</td>\n",
              "      <td>-0.031415</td>\n",
              "      <td>-0.350340</td>\n",
              "      <td>0.185927</td>\n",
              "      <td>0.045446</td>\n",
              "      <td>0.113304</td>\n",
              "      <td>0.265687</td>\n",
              "      <td>...</td>\n",
              "      <td>0.115303</td>\n",
              "      <td>0.274362</td>\n",
              "      <td>-0.343106</td>\n",
              "      <td>0.081103</td>\n",
              "      <td>-0.327079</td>\n",
              "      <td>0.405485</td>\n",
              "      <td>0.278358</td>\n",
              "      <td>0.388446</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.132940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_768</th>\n",
              "      <td>-0.039317</td>\n",
              "      <td>0.162593</td>\n",
              "      <td>0.217143</td>\n",
              "      <td>-0.128138</td>\n",
              "      <td>-0.203071</td>\n",
              "      <td>0.242545</td>\n",
              "      <td>-0.390389</td>\n",
              "      <td>-0.033126</td>\n",
              "      <td>0.020400</td>\n",
              "      <td>-0.093904</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.012714</td>\n",
              "      <td>-0.117084</td>\n",
              "      <td>0.191413</td>\n",
              "      <td>0.091538</td>\n",
              "      <td>0.299900</td>\n",
              "      <td>-0.009266</td>\n",
              "      <td>-0.172730</td>\n",
              "      <td>-0.065182</td>\n",
              "      <td>-0.132940</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows Ã— 768 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
              "feature_1     1.000000   0.065348  -0.039416   0.116528   0.108225  -0.163679   \n",
              "feature_2     0.065348   1.000000   0.043611   0.068624  -0.278709   0.052155   \n",
              "feature_3    -0.039416   0.043611   1.000000  -0.185437  -0.313107  -0.103496   \n",
              "feature_4     0.116528   0.068624  -0.185437   1.000000   0.096349  -0.220416   \n",
              "feature_5     0.108225  -0.278709  -0.313107   0.096349   1.000000   0.021056   \n",
              "...                ...        ...        ...        ...        ...        ...   \n",
              "feature_764  -0.040330   0.005612   0.204807   0.103712  -0.087327  -0.174192   \n",
              "feature_765   0.132620  -0.068710   0.133835   0.100221  -0.063512  -0.345465   \n",
              "feature_766   0.032706  -0.204834  -0.063354   0.006758   0.016875  -0.233690   \n",
              "feature_767   0.035296  -0.350866   0.159975   0.034292  -0.031415  -0.350340   \n",
              "feature_768  -0.039317   0.162593   0.217143  -0.128138  -0.203071   0.242545   \n",
              "\n",
              "             feature_7  feature_8  feature_9  feature_10  ...  feature_759  \\\n",
              "feature_1     0.131004  -0.073198  -0.045476   -0.120560  ...    -0.225724   \n",
              "feature_2    -0.267946  -0.214403  -0.235840   -0.056829  ...    -0.150852   \n",
              "feature_3    -0.214606  -0.185952   0.155197    0.011407  ...    -0.248988   \n",
              "feature_4     0.194002   0.027816  -0.144393   -0.148927  ...     0.135598   \n",
              "feature_5     0.325761  -0.000900   0.038333   -0.116997  ...    -0.020572   \n",
              "...                ...        ...        ...         ...  ...          ...   \n",
              "feature_764   0.122454   0.012446   0.199985    0.171440  ...     0.075743   \n",
              "feature_765  -0.002038   0.005804   0.053829   -0.116723  ...    -0.103060   \n",
              "feature_766   0.282928  -0.105139   0.097498    0.391228  ...     0.096985   \n",
              "feature_767   0.185927   0.045446   0.113304    0.265687  ...     0.115303   \n",
              "feature_768  -0.390389  -0.033126   0.020400   -0.093904  ...    -0.012714   \n",
              "\n",
              "             feature_760  feature_761  feature_762  feature_763  feature_764  \\\n",
              "feature_1       0.290177     0.015310     0.144664    -0.110313    -0.040330   \n",
              "feature_2      -0.096604     0.287950    -0.099087     0.269144     0.005612   \n",
              "feature_3      -0.162378    -0.024814     0.162806     0.231606     0.204807   \n",
              "feature_4       0.071113    -0.084978    -0.166751    -0.220446     0.103712   \n",
              "feature_5       0.024932    -0.202849     0.031865    -0.371326    -0.087327   \n",
              "...                  ...          ...          ...          ...          ...   \n",
              "feature_764     0.065512    -0.313912    -0.196618    -0.114188     1.000000   \n",
              "feature_765     0.180543    -0.010908    -0.076788     0.228983     0.208730   \n",
              "feature_766     0.293527    -0.266795     0.168379    -0.486373     0.181622   \n",
              "feature_767     0.274362    -0.343106     0.081103    -0.327079     0.405485   \n",
              "feature_768    -0.117084     0.191413     0.091538     0.299900    -0.009266   \n",
              "\n",
              "             feature_765  feature_766  feature_767  feature_768  \n",
              "feature_1       0.132620     0.032706     0.035296    -0.039317  \n",
              "feature_2      -0.068710    -0.204834    -0.350866     0.162593  \n",
              "feature_3       0.133835    -0.063354     0.159975     0.217143  \n",
              "feature_4       0.100221     0.006758     0.034292    -0.128138  \n",
              "feature_5      -0.063512     0.016875    -0.031415    -0.203071  \n",
              "...                  ...          ...          ...          ...  \n",
              "feature_764     0.208730     0.181622     0.405485    -0.009266  \n",
              "feature_765     1.000000    -0.204636     0.278358    -0.172730  \n",
              "feature_766    -0.204636     1.000000     0.388446    -0.065182  \n",
              "feature_767     0.278358     0.388446     1.000000    -0.132940  \n",
              "feature_768    -0.172730    -0.065182    -0.132940     1.000000  \n",
              "\n",
              "[768 rows x 768 columns]"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corr_matrix_l3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_corr_features(corr_matrix, threshold):\n",
        "\n",
        "  correlated_features = []\n",
        "\n",
        "  for i in range(len(corr_matrix.columns)):\n",
        "    for j in range(i+1, len(corr_matrix.columns)):\n",
        "      if (abs(corr_matrix.iloc[i, j]) > threshold):\n",
        "        col_name = corr_matrix.columns[j]\n",
        "        if col_name not in correlated_features:\n",
        "          correlated_features.append(col_name)\n",
        "\n",
        "  return correlated_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n"
          ]
        }
      ],
      "source": [
        "correlated_features_l3 = get_corr_features(corr_matrix_l3, 0.7)\n",
        "print(len(correlated_features_l3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "x_test_l3 = x_test.copy()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train[L3] = pd.DataFrame(scaler.fit_transform(x_train[L3]), columns=FEATURES)\n",
        "x_valid[L3] = pd.DataFrame(scaler.transform(x_valid[L3]), columns=FEATURES)\n",
        "x_test_l3 = pd.DataFrame(scaler.transform(x_test_l3), columns=FEATURES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of features: 350\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "threshold = 0.96\n",
        "\n",
        "pca = PCA(n_components=threshold, svd_solver='full')\n",
        "x_train_l3_pca = pd.DataFrame(pca.fit_transform(x_train[L3]))\n",
        "x_valid_l3_pca = pd.DataFrame(pca.transform(x_valid[L3]))\n",
        "x_test_l3_pca = pd.DataFrame(pca.transform(x_test_l3))\n",
        "\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "\n",
        "print(f\"Number of features: {len(explained_variance)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy = 0.996\n"
          ]
        }
      ],
      "source": [
        "accuracy_1 = weighted_svm_classifier(x_train_l3_pca, y_train[L3], x_valid_l3_pca, y_valid[L3])\n",
        "print(f\"Accuracy = {accuracy_1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Hyperparameter Tuning - Random Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "{'kernel': 'poly', 'gamma': 100.0, 'class_weight': 'balanced', 'C': 0.01}\n",
            "0.9591164095371669\n"
          ]
        }
      ],
      "source": [
        "param_dist = {\n",
        "    'C': np.logspace(-3, 3, 7),\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'gamma': np.logspace(-3, 3, 7),\n",
        "    'class_weight': ['balanced']\n",
        "}\n",
        "cv = 2\n",
        "n_iter = 5\n",
        "svm = SVC()\n",
        "\n",
        "random_search_l3 = random_grid_search(svm, param_dist, cv, n_iter, x_train_l3_pca, y_train[L3])\n",
        "best_model_l3 = random_search_l3.best_estimator_\n",
        "best_accuracy_l3 = random_search_l3.best_score_\n",
        "best_param = random_search_l3.best_params_\n",
        "\n",
        "print(best_param)\n",
        "print(best_accuracy_l3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy after: 0.9973333333333333\n"
          ]
        }
      ],
      "source": [
        "y_pred_l3 = best_model_l3.predict(x_valid_l3_pca)\n",
        "accuracy = accuracy_score(y_valid[L3], y_pred_l3)\n",
        "print(f\"Accuracy after: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-Validation Scores: [0.97492987 0.99509116 0.98159187 0.98264376 0.98439691]\n",
            "Mean Score: 0.9837307152875174\n",
            "Standard Deviation: 0.0065224931323021994\n"
          ]
        }
      ],
      "source": [
        "model = SVC(kernel= 'poly', gamma= 100.0, class_weight= 'balanced', C= 0.01)\n",
        "\n",
        "k_fold_cross_validation(model, 5, x_train_l3_pca, y_train[L3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Label 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot: xlabel='label_4', ylabel='count'>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABdAAAAINCAYAAAA+zF3uAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAABI+0lEQVR4nO3dfZyVdZ0//teADaAyo6gwzIow3qRiqHkTTq2WyTIqWWxW3mWYaNmCipQhmzeotbj6NW/y7mub0mPTTd1vUmJpiKJroiKKigV5M4itDlrKjKACwvn9scv5OXGlgsgZmOfz8TgP51zX+1zndc3nMcJ5eXlNValUKgUAAAAAAGinS6UDAAAAAABAR6RABwAAAACAAgp0AAAAAAAooEAHAAAAAIACCnQAAAAAACigQAcAAAAAgAIKdAAAAAAAKKBABwAAAACAAptUOsDGYuXKlXnxxRfTs2fPVFVVVToOAAAAAAAFSqVSXn/99dTX16dLl3e/xlyBvo68+OKL6devX6VjAAAAAADwPrzwwgvZdttt33VGgb6O9OzZM8n/fNNramoqnAYAAAAAgCJtbW3p169fudN9Nwr0dWTVbVtqamoU6AAAAAAAHdz7uRW3XyIKAAAAAAAFFOgAAAAAAFBAgQ4AAAAAAAUU6AAAAAAAUECBDgAAAAAABRToAAAAAABQQIEOAAAAAAAFFOgAAAAAAFBAgQ4AAAAAAAUU6AAAAAAAUECBDgAAAAAABRToAAAAAABQQIEOAAAAAAAFKlqgT5w4Mfvuu2969uyZ3r17Z/jw4Zk3b167mbfeeiujRo3KVlttlc033zyHH354Fi5c2G5mwYIFGTZsWDbddNP07t07p59+et5+++12M9OnT89ee+2Vbt26Zccdd8ykSZNWy3PllVdmwIAB6d69ewYPHpyHH354nZ8zAAAAAAAbhooW6Pfee29GjRqVBx98MFOnTs3y5cszdOjQLFmypDxz2mmn5bbbbsstt9ySe++9Ny+++GK++MUvlvevWLEiw4YNy7Jly/LAAw/kpz/9aSZNmpSzzz67PNPc3Jxhw4blwAMPzOzZszNmzJiccMIJufPOO8szN910U8aOHZtzzjknjz76aPbYY480NTXl5ZdfXj/fDAAAAAAAOpSqUqlUqnSIVV555ZX07t079957bw444IC0trZmm222yY033pgvfelLSZK5c+dm1113zYwZM7LffvvlN7/5TT73uc/lxRdfTJ8+fZIk11xzTcaNG5dXXnkl1dXVGTduXG6//fbMmTOn/F5HHnlkFi1alDvuuCNJMnjw4Oy777654oorkiQrV65Mv379cvLJJ+eMM854z+xtbW2pra1Na2trampq1vW3BgAAAACAdWBNutwOdQ/01tbWJEmvXr2SJLNmzcry5cszZMiQ8swuu+yS7bbbLjNmzEiSzJgxI4MGDSqX50nS1NSUtra2PPXUU+WZdx5j1cyqYyxbtiyzZs1qN9OlS5cMGTKkPPPXli5dmra2tnYPAAAAAAA2Hh2mQF+5cmXGjBmTT33qU/nYxz6WJGlpaUl1dXW22GKLdrN9+vRJS0tLeead5fmq/av2vdtMW1tb3nzzzfz5z3/OihUrCmdWHeOvTZw4MbW1teVHv3791u7EAQAAAADokDpMgT5q1KjMmTMnP//5zysd5X0ZP358Wltby48XXnih0pEAAAAAAFiHNql0gCQZPXp0pkyZkvvuuy/bbrtteXtdXV2WLVuWRYsWtbsKfeHChamrqyvPPPzww+2Ot3DhwvK+Vf9cte2dMzU1NenRo0e6du2arl27Fs6sOsZf69atW7p167Z2JwwAwDrR0DC/0hE2aM3NAyodAQAAOrSKXoFeKpUyevTo3Hrrrbn77rvT0NDQbv/ee++dj3zkI5k2bVp527x587JgwYI0NjYmSRobG/Pkk0/m5ZdfLs9MnTo1NTU1GThwYHnmncdYNbPqGNXV1dl7773bzaxcuTLTpk0rzwAAAAAA0LlU9Ar0UaNG5cYbb8wvf/nL9OzZs3y/8dra2vTo0SO1tbUZOXJkxo4dm169eqWmpiYnn3xyGhsbs99++yVJhg4dmoEDB+bYY4/NhRdemJaWlpx55pkZNWpU+Qrxk046KVdccUW++93v5vjjj8/dd9+dm2++Obfffns5y9ixYzNixIjss88++cQnPpFLL700S5Ysyde//vX1/40BAAAAAKDiKlqgX3311UmSz3zmM+22X3/99TnuuOOSJJdcckm6dOmSww8/PEuXLk1TU1Ouuuqq8mzXrl0zZcqUfOtb30pjY2M222yzjBgxIuedd155pqGhIbfffntOO+20XHbZZdl2223zb//2b2lqairPHHHEEXnllVdy9tlnp6WlJXvuuWfuuOOO1X6xKAAAAAAAnUNVqVQqVTrExqCtrS21tbVpbW1NTU1NpeMAAHQK7oH+wbgHOgAAndGadLkVvQc6AAAAAAB0VAp0AAAAAAAooEAHAAAAAIACCnQAAAAAACigQAcAAAAAgAIKdAAAAAAAKKBABwAAAACAAgp0AAAAAAAooEAHAAAAAIACCnQAAAAAACigQAcAAAAAgAIKdAAAAAAAKKBABwAAAACAAgp0AAAAAAAooEAHAAAAAIACCnQAAAAAACigQAcAAAAAgAIKdAAAAAAAKKBABwAAAACAAgp0AAAAAAAooEAHAAAAAIACCnQAAAAAACigQAcAAAAAgAIKdAAAAAAAKKBABwAAAACAAgp0AAAAAAAooEAHAAAAAIACCnQAAAAAACigQAcAAAAAgAIKdAAAAAAAKKBABwAAAACAAgp0AAAAAAAooEAHAAAAAIACCnQAAAAAACigQAcAAAAAgAIKdAAAAAAAKKBABwAAAACAAgp0AAAAAAAooEAHAAAAAIACCnQAAAAAACigQAcAAAAAgAIKdAAAAAAAKKBABwAAAACAAgp0AAAAAAAoUNEC/b777sthhx2W+vr6VFVVZfLkye32V1VVFT4uuuii8syAAQNW23/BBRe0O84TTzyR/fffP927d0+/fv1y4YUXrpbllltuyS677JLu3btn0KBB+fWvf/2hnDMAAAAAABuGihboS5YsyR577JErr7yycP9LL73U7nHdddelqqoqhx9+eLu58847r93cySefXN7X1taWoUOHpn///pk1a1YuuuiiTJgwIddee2155oEHHshRRx2VkSNH5rHHHsvw4cMzfPjwzJkz58M5cQAAAAAAOrxNKvnmhxxySA455JC/ub+urq7d81/+8pc58MADs/3227fb3rNnz9VmV7nhhhuybNmyXHfddamurs5uu+2W2bNn54c//GG+8Y1vJEkuu+yyHHzwwTn99NOTJOeff36mTp2aK664Itdcc80HOUUAAAAAADZQG8w90BcuXJjbb789I0eOXG3fBRdckK222iof//jHc9FFF+Xtt98u75sxY0YOOOCAVFdXl7c1NTVl3rx5ee2118ozQ4YMaXfMpqamzJgx42/mWbp0adra2to9AAAAAADYeFT0CvQ18dOf/jQ9e/bMF7/4xXbbTznllOy1117p1atXHnjggYwfPz4vvfRSfvjDHyZJWlpa0tDQ0O41ffr0Ke/bcsst09LSUt72zpmWlpa/mWfixIk599xz18WpAQAAAADQAW0wBfp1112XY445Jt27d2+3fezYseWvd99991RXV+eb3/xmJk6cmG7dun1oecaPH9/uvdva2tKvX78P7f0AAAAAAFi/NogC/b/+678yb9683HTTTe85O3jw4Lz99tuZP39+dt5559TV1WXhwoXtZlY9X3Xf9L8187fuq54k3bp1+1ALegAAAAAAKmuDuAf6T37yk+y9997ZY4893nN29uzZ6dKlS3r37p0kaWxszH333Zfly5eXZ6ZOnZqdd945W265ZXlm2rRp7Y4zderUNDY2rsOzAAAAAABgQ1LRAn3x4sWZPXt2Zs+enSRpbm7O7Nmzs2DBgvJMW1tbbrnllpxwwgmrvX7GjBm59NJL8/jjj+e5557LDTfckNNOOy1f/epXy+X40Ucfnerq6owcOTJPPfVUbrrpplx22WXtbr9y6qmn5o477sjFF1+cuXPnZsKECXnkkUcyevToD/cbAAAAAABAh1VVKpVKlXrz6dOn58ADD1xt+4gRIzJp0qQkybXXXpsxY8bkpZdeSm1tbbu5Rx99NP/0T/+UuXPnZunSpWloaMixxx6bsWPHtru9yhNPPJFRo0Zl5syZ2XrrrXPyySdn3Lhx7Y51yy235Mwzz8z8+fOz00475cILL8yhhx76vs+lra0ttbW1aW1tTU1NzRp8FwAAWFsNDfMrHWGD1tw8oNIRAABgvVuTLreiBfrGRIEOALD+KdA/GAU6AACd0Zp0uRvEPdABAAAAAGB9U6ADAAAAAEABBToAAAAAABRQoAMAAAAAQAEFOgAAAAAAFFCgAwAAAABAAQU6AAAAAAAUUKADAAAAAEABBToAAAAAABRQoAMAAAAAQAEFOgAAAAAAFFCgAwAAAABAAQU6AAAAAAAUUKADAAAAAEABBToAAAAAABRQoAMAAAAAQAEFOgAAAAAAFFCgAwAAAABAAQU6AAAAAAAUUKADAAAAAEABBToAAAAAABRQoAMAAAAAQAEFOgAAAAAAFFCgAwAAAABAAQU6AAAAAAAUUKADAAAAAEABBToAAAAAABRQoAMAAAAAQAEFOgAAAAAAFFCgAwAAAABAAQU6AAAAAAAUUKADAAAAAEABBToAAAAAABRQoAMAAAAAQAEFOgAAAAAAFFCgAwAAAABAAQU6AAAAAAAUUKADAAAAAEABBToAAAAAABRQoAMAAAAAQAEFOgAAAAAAFFCgAwAAAABAAQU6AAAAAAAUUKADAAAAAECBihbo9913Xw477LDU19enqqoqkydPbrf/uOOOS1VVVbvHwQcf3G7m1VdfzTHHHJOamppsscUWGTlyZBYvXtxu5oknnsj++++f7t27p1+/frnwwgtXy3LLLbdkl112Sffu3TNo0KD8+te/XufnCwAAAADAhqOiBfqSJUuyxx575Morr/ybMwcffHBeeuml8uM//uM/2u0/5phj8tRTT2Xq1KmZMmVK7rvvvnzjG98o729ra8vQoUPTv3//zJo1KxdddFEmTJiQa6+9tjzzwAMP5KijjsrIkSPz2GOPZfjw4Rk+fHjmzJmz7k8aAAAAAIANQlWpVCpVOkSSVFVV5dZbb83w4cPL24477rgsWrRotSvTV/nDH/6QgQMHZubMmdlnn32SJHfccUcOPfTQ/OlPf0p9fX2uvvrqfO9730tLS0uqq6uTJGeccUYmT56cuXPnJkmOOOKILFmyJFOmTCkfe7/99suee+6Za6655n3lb2trS21tbVpbW1NTU7MW3wEAANZUQ8P8SkfYoDU3D6h0BAAAWO/WpMvt8PdAnz59enr37p2dd9453/rWt/KXv/ylvG/GjBnZYostyuV5kgwZMiRdunTJQw89VJ454IADyuV5kjQ1NWXevHl57bXXyjNDhgxp975NTU2ZMWPGh3lqAAAAAAB0YJtUOsC7Ofjgg/PFL34xDQ0NefbZZ/PP//zPOeSQQzJjxox07do1LS0t6d27d7vXbLLJJunVq1daWlqSJC0tLWloaGg306dPn/K+LbfcMi0tLeVt75xZdYwiS5cuzdKlS8vP29raPtC5AgAAAADQsXToAv3II48sfz1o0KDsvvvu2WGHHTJ9+vQcdNBBFUyWTJw4Meeee25FMwAAAAAA8OHp8Ldweaftt98+W2+9dZ555pkkSV1dXV5++eV2M2+//XZeffXV1NXVlWcWLlzYbmbV8/eaWbW/yPjx49Pa2lp+vPDCCx/s5AAAAAAA6FA2qAL9T3/6U/7yl7+kb9++SZLGxsYsWrQos2bNKs/cfffdWblyZQYPHlyeue+++7J8+fLyzNSpU7Pzzjtnyy23LM9Mmzat3XtNnTo1jY2NfzNLt27dUlNT0+4BAAAAAMDGo6IF+uLFizN79uzMnj07SdLc3JzZs2dnwYIFWbx4cU4//fQ8+OCDmT9/fqZNm5YvfOEL2XHHHdPU1JQk2XXXXXPwwQfnxBNPzMMPP5zf/e53GT16dI488sjU19cnSY4++uhUV1dn5MiReeqpp3LTTTflsssuy9ixY8s5Tj311Nxxxx25+OKLM3fu3EyYMCGPPPJIRo8evd6/JwAAAAAAdAxVpVKpVKk3nz59eg488MDVto8YMSJXX311hg8fnsceeyyLFi1KfX19hg4dmvPPP7/dL/x89dVXM3r06Nx2223p0qVLDj/88Fx++eXZfPPNyzNPPPFERo0alZkzZ2brrbfOySefnHHjxrV7z1tuuSVnnnlm5s+fn5122ikXXnhhDj300Pd9Lm1tbamtrU1ra6ur0QEA1pOGhvmVjrBBa24eUOkIAACw3q1Jl1vRAn1jokAHAFj/FOgfjAIdAIDOaE263A3qHugAAAAAALC+KNABAAAAAKCAAh0AAAAAAAoo0AEAAAAAoIACHQAAAAAACijQAQAAAACggAIdAAAAAAAKKNABAAAAAKCAAh0AAAAAAAoo0AEAAAAAoIACHQAAAAAACijQAQAAAACggAIdAAAAAAAKKNABAAAAAKCAAh0AAAAAAAoo0AEAAAAAoIACHQAAAAAACijQAQAAAACggAIdAAAAAAAKKNABAAAAAKCAAh0AAAAAAAoo0AEAAAAAoIACHQAAAAAACijQAQAAAACggAIdAAAAAAAKKNABAAAAAKCAAh0AAAAAAAoo0AEAAAAAoIACHQAAAAAACijQAQAAAACggAIdAAAAAAAKKNABAAAAAKCAAh0AAAAAAAoo0AEAAAAAoIACHQAAAAAACijQAQAAAACggAIdAAAAAAAKKNABAAAAAKCAAh0AAAAAAAoo0AEAAAAAoIACHQAAAAAACijQAQAAAACggAIdAAAAAAAKKNABAAAAAKCAAh0AAAAAAApUtEC/7777cthhh6W+vj5VVVWZPHlyed/y5cszbty4DBo0KJtttlnq6+vzta99LS+++GK7YwwYMCBVVVXtHhdccEG7mSeeeCL7779/unfvnn79+uXCCy9cLcstt9ySXXbZJd27d8+gQYPy61//+kM5ZwAAAAAANgwVLdCXLFmSPfbYI1deeeVq+9544408+uijOeuss/Loo4/mF7/4RebNm5fPf/7zq82ed955eemll8qPk08+ubyvra0tQ4cOTf/+/TNr1qxcdNFFmTBhQq699tryzAMPPJCjjjoqI0eOzGOPPZbhw4dn+PDhmTNnzodz4gAAAAAAdHhVpVKpVOkQSVJVVZVbb701w4cP/5szM2fOzCc+8Yk8//zz2W677ZL8zxXoY8aMyZgxYwpfc/XVV+d73/teWlpaUl1dnSQ544wzMnny5MydOzdJcsQRR2TJkiWZMmVK+XX77bdf9txzz1xzzTXvK39bW1tqa2vT2tqampqa9/UaAAA+mIaG+ZWOsEFrbh5Q6QgAALDerUmXu0HdA721tTVVVVXZYost2m2/4IILstVWW+XjH/94Lrroorz99tvlfTNmzMgBBxxQLs+TpKmpKfPmzctrr71WnhkyZEi7YzY1NWXGjBl/M8vSpUvT1tbW7gEAAAAAwMZjk0oHeL/eeuutjBs3LkcddVS7/ypwyimnZK+99kqvXr3ywAMPZPz48XnppZfywx/+MEnS0tKShoaGdsfq06dPed+WW26ZlpaW8rZ3zrS0tPzNPBMnTsy55567rk4PAAAAAIAOZoMo0JcvX56vfOUrKZVKufrqq9vtGzt2bPnr3XffPdXV1fnmN7+ZiRMnplu3bh9apvHjx7d777a2tvTr1+9Dez8AAAAAANavDl+gryrPn3/++dx9993veU+awYMH5+233878+fOz8847p66uLgsXLmw3s+p5XV1d+Z9FM6v2F+nWrduHWtADAAAAAFBZHfoe6KvK86effjp33XVXttpqq/d8zezZs9OlS5f07t07SdLY2Jj77rsvy5cvL89MnTo1O++8c7bccsvyzLRp09odZ+rUqWlsbFyHZwMAAAAAwIakolegL168OM8880z5eXNzc2bPnp1evXqlb9+++dKXvpRHH300U6ZMyYoVK8r3JO/Vq1eqq6szY8aMPPTQQznwwAPTs2fPzJgxI6eddlq++tWvlsvxo48+Oueee25GjhyZcePGZc6cObnssstyySWXlN/31FNPzac//elcfPHFGTZsWH7+85/nkUceybXXXrt+vyEAAAAAAHQYVaVSqVSpN58+fXoOPPDA1baPGDEiEyZMWO2Xf65yzz335DOf+UweffTR/NM//VPmzp2bpUuXpqGhIccee2zGjh3b7vYqTzzxREaNGpWZM2dm6623zsknn5xx48a1O+Ytt9ySM888M/Pnz89OO+2UCy+8MIceeuj7Ppe2trbU1tamtbX1PW8zAwDAutHQML/SETZozc0DKh0BAADWuzXpcitaoG9MFOgAAOufAv2DUaADANAZrUmX26HvgQ4AAAAAAJWiQAcAAAAAgAIKdAAAAAAAKKBABwAAAACAAgp0AAAAAAAooEAHAAAAAIACCnQAAAAAACigQAcAAAAAgAIKdAAAAAAAKKBABwAAAACAAgp0AAAAAAAooEAHAAAAAIACCnQAAAAAACigQAcAAAAAgAIKdAAAAAAAKKBABwAAAACAAgp0AAAAAAAooEAHAAAAAIACCnQAAAAAACigQAcAAAAAgAIKdAAAAAAAKLBWBfpnP/vZLFq0aLXtbW1t+exnP/tBMwEAAAAAQMWtVYE+ffr0LFu2bLXtb731Vv7rv/7rA4cCAAAAAIBK22RNhp944ony17///e/T0tJSfr5ixYrccccd+bu/+7t1lw4AAAAAACpkjQr0PffcM1VVVamqqiq8VUuPHj3yox/9aJ2FAwAAAACASlmjAr25uTmlUinbb799Hn744WyzzTblfdXV1endu3e6du26zkMCAAAAAMD6tkYFev/+/ZMkK1eu/FDCAAAAAABAR7FGBfo7Pf3007nnnnvy8ssvr1aon3322R84GAAAAAAAVNJaFeg//vGP861vfStbb7116urqUlVVVd5XVVWlQAcAAAAAYIO3VgX697///fzgBz/IuHHj1nUeAAAAAADoELqszYtee+21fPnLX17XWQAAAAAAoMNYqwL9y1/+cn7729+u6ywAAAAAANBhrNUtXHbcccecddZZefDBBzNo0KB85CMfabf/lFNOWSfhAAAAAACgUqpKpVJpTV/U0NDwtw9YVZXnnnvuA4XaELW1taW2tjatra2pqampdBwAgE6hoWF+pSNs0JqbB1Q6AgAArHdr0uWu1RXozc3NaxUMAAAAAAA2FGt1D3QAAAAAANjYrdUV6Mcff/y77r/uuuvWKgwAAAAAAHQUa1Wgv/baa+2eL1++PHPmzMmiRYvy2c9+dp0EAwAAAACASlqrAv3WW29dbdvKlSvzrW99KzvssMMHDgUAAAAAAJW2zu6B3qVLl4wdOzaXXHLJujokAAAAAABUzDr9JaLPPvts3n777XV5SAAAAAAAqIi1uoXL2LFj2z0vlUp56aWXcvvtt2fEiBHrJBgAAAAAAFTSWhXojz32WLvnXbp0yTbbbJOLL744xx9//DoJBgAAAAAAlbRWBfo999yzrnMAAAAAAECH8oHugf7KK6/k/vvvz/33359XXnlljV9/33335bDDDkt9fX2qqqoyefLkdvtLpVLOPvvs9O3bNz169MiQIUPy9NNPt5t59dVXc8wxx6SmpiZbbLFFRo4cmcWLF7ebeeKJJ7L//vune/fu6devXy688MLVstxyyy3ZZZdd0r179wwaNCi//vWv1/h8AAAAAADYeKxVgb5kyZIcf/zx6du3bw444IAccMABqa+vz8iRI/PGG2+s0XH22GOPXHnllYX7L7zwwlx++eW55ppr8tBDD2WzzTZLU1NT3nrrrfLMMccck6eeeipTp07NlClTct999+Ub3/hGeX9bW1uGDh2a/v37Z9asWbnooosyYcKEXHvtteWZBx54IEcddVRGjhyZxx57LMOHD8/w4cMzZ86ctfjuAAAAAACwMagqlUqlNX3RN7/5zdx111254oor8qlPfSpJcv/99+eUU07JP/zDP+Tqq69e8yBVVbn11lszfPjwJP9z9Xl9fX2+/e1v5zvf+U6SpLW1NX369MmkSZNy5JFH5g9/+EMGDhyYmTNnZp999kmS3HHHHTn00EPzpz/9KfX19bn66qvzve99Ly0tLamurk6SnHHGGZk8eXLmzp2bJDniiCOyZMmSTJkypZxnv/32y5577plrrrnmfeVva2tLbW1tWltbU1NTs8bnDwDAmmtomF/pCBu05uYBlY4AAADr3Zp0uWt1Bfr/+3//Lz/5yU9yyCGHpKamJjU1NTn00EPz4x//OP/5n/+5VqH/WnNzc1paWjJkyJDyttra2gwePDgzZsxIksyYMSNbbLFFuTxPkiFDhqRLly556KGHyjMHHHBAuTxPkqampsybNy+vvfZaeead77NqZtX7FFm6dGna2traPQAAAAAA2HisVYH+xhtvpE+fPqtt79279xrdwuXdtLS0JMlq79OnT5/yvpaWlvTu3bvd/k022SS9evVqN1N0jHe+x9+aWbW/yMSJE1NbW1t+9OvXb01PEQAAAACADmytCvTGxsacc8457e5F/uabb+bcc89NY2PjOgvXkY0fPz6tra3lxwsvvFDpSAAAAAAArEObrM2LLr300hx88MHZdttts8ceeyRJHn/88XTr1i2//e1v10mwurq6JMnChQvTt2/f8vaFCxdmzz33LM+8/PLL7V739ttv59VXXy2/vq6uLgsXLmw3s+r5e82s2l+kW7du6dat21qcGQAAAAAAG4K1ugJ90KBBefrppzNx4sTsueee2XPPPXPBBRfkmWeeyW677bZOgjU0NKSuri7Tpk0rb2tra8tDDz1Uvsq9sbExixYtyqxZs8ozd999d1auXJnBgweXZ+67774sX768PDN16tTsvPPO2XLLLcsz73yfVTOd5Wp6AAAAAABWt1ZXoE+cODF9+vTJiSee2G77ddddl1deeSXjxo17X8dZvHhxnnnmmfLz5ubmzJ49O7169cp2222XMWPG5Pvf/3522mmnNDQ05Kyzzkp9fX2GDx+eJNl1111z8MEH58QTT8w111yT5cuXZ/To0TnyyCNTX1+fJDn66KNz7rnnZuTIkRk3blzmzJmTyy67LJdcckn5fU899dR8+tOfzsUXX5xhw4bl5z//eR555JFce+21a/PtAQAAAABgI1BVKpVKa/qiAQMG5MYbb8wnP/nJdtsfeuihHHnkkWlubn5fx5k+fXoOPPDA1baPGDEikyZNSqlUyjnnnJNrr702ixYtyt///d/nqquuykc/+tHy7KuvvprRo0fntttuS5cuXXL44Yfn8ssvz+abb16eeeKJJzJq1KjMnDkzW2+9dU4++eTVSv5bbrklZ555ZubPn5+ddtopF154YQ499ND3/T1pa2tLbW1tWltbU1NT875fBwDA2mtomF/pCBu05uYBlY4AAADr3Zp0uWtVoHfv3j1/+MMf0tDQ0G77c889l4EDB7b75aKdhQIdAGD9U6B/MAp0AAA6ozXpctfqHuj9+vXL7373u9W2/+53vyvfOgUAAAAAADZka3UP9BNPPDFjxozJ8uXL89nPfjZJMm3atHz3u9/Nt7/97XUaEAAAAAAAKmGtCvTTTz89f/nLX/JP//RPWbZsWZL/ua3LuHHjMn78+HUaEAAAAAAAKmGt7oG+yuLFi/OHP/whPXr0yE477ZRu3bqty2wbFPdABwBY/9wD/YNxD3QAADqjNely1+oK9FU233zz7Lvvvh/kEAAAAAAA0CGt1S8RBQAAAACAjZ0CHQAAAAAACijQAQAAAACggAIdAAAAAAAKKNABAAAAAKCAAh0AAAAAAAoo0AEAAAAAoIACHQAAAAAACijQAQAAAACggAIdAAAAAAAKKNABAAAAAKCAAh0AAAAAAAoo0AEAAAAAoIACHQAAAAAACijQAQAAAACggAIdAAAAAAAKKNABAAAAAKCAAh0AAAAAAAoo0AEAAAAAoIACHQAAAAAACijQAQAAAACggAIdAAAAAAAKKNABAAAAAKCAAh0AAAAAAAoo0AEAAAAAoIACHQAAAAAACijQAQAAAACggAIdAAAAAAAKKNABAAAAAKCAAh0AAAAAAAoo0AEAAAAAoIACHQAAAAAACijQAQAAAACggAIdAAAAAAAKKNABAAAAAKCAAh0AAAAAAAoo0AEAAAAAoIACHQAAAAAACijQAQAAAACgQIcv0AcMGJCqqqrVHqNGjUqSfOYzn1lt30knndTuGAsWLMiwYcOy6aabpnfv3jn99NPz9ttvt5uZPn169tprr3Tr1i077rhjJk2atL5OEQAAAACADmiTSgd4LzNnzsyKFSvKz+fMmZN/+Id/yJe//OXythNPPDHnnXde+fmmm25a/nrFihUZNmxY6urq8sADD+Sll17K1772tXzkIx/Jv/zLvyRJmpubM2zYsJx00km54YYbMm3atJxwwgnp27dvmpqa1sNZAgAAAADQ0XT4An2bbbZp9/yCCy7IDjvskE9/+tPlbZtuumnq6uoKX//b3/42v//973PXXXelT58+2XPPPXP++edn3LhxmTBhQqqrq3PNNdekoaEhF198cZJk1113zf33359LLrlEgQ4AAAAA0El1+Fu4vNOyZcvys5/9LMcff3yqqqrK22+44YZsvfXW+djHPpbx48fnjTfeKO+bMWNGBg0alD59+pS3NTU1pa2tLU899VR5ZsiQIe3eq6mpKTNmzPibWZYuXZq2trZ2DwAAAAAANh4d/gr0d5o8eXIWLVqU4447rrzt6KOPTv/+/VNfX58nnngi48aNy7x58/KLX/wiSdLS0tKuPE9Sft7S0vKuM21tbXnzzTfTo0eP1bJMnDgx55577ro8PQAAAAAAOpANqkD/yU9+kkMOOST19fXlbd/4xjfKXw8aNCh9+/bNQQcdlGeffTY77LDDh5Zl/PjxGTt2bPl5W1tb+vXr96G9HwAAAAAA69cGU6A///zzueuuu8pXlv8tgwcPTpI888wz2WGHHVJXV5eHH3643czChQuTpHzf9Lq6uvK2d87U1NQUXn2eJN26dUu3bt3W6lwAAAAAAOj4Nph7oF9//fXp3bt3hg0b9q5zs2fPTpL07ds3SdLY2Jgnn3wyL7/8cnlm6tSpqampycCBA8sz06ZNa3ecqVOnprGxcR2eAQAAAAAAG5INokBfuXJlrr/++owYMSKbbPL/XzT/7LPP5vzzz8+sWbMyf/78/OpXv8rXvva1HHDAAdl9992TJEOHDs3AgQNz7LHH5vHHH8+dd96ZM888M6NGjSpfQX7SSSflueeey3e/+93MnTs3V111VW6++eacdtppFTlfAAAAAAAqb4Mo0O+6664sWLAgxx9/fLvt1dXVueuuuzJ06NDssssu+fa3v53DDz88t912W3mma9eumTJlSrp27ZrGxsZ89atfzde+9rWcd9555ZmGhobcfvvtmTp1avbYY49cfPHF+bd/+7c0NTWtt3MEAAAAAKBjqSqVSqVKh9gYtLW1pba2Nq2trampqal0HACATqGhYX6lI2zQmpsHVDoCAACsd2vS5W4QV6ADAAAAAMD6pkAHAAAAAIACCnQAAAAAACigQAcAAAAAgAIKdAAAAAAAKKBABwAAAACAAgp0AAAAAAAooEAHAAAAAIACCnQAAAAAACigQAcAAAAAgAIKdAAAAAAAKKBABwAAAACAAgp0AAAAAAAooEAHAAAAAIACCnQAAAAAACigQAcAAAAAgAIKdAAAAAAAKKBABwAAAACAAgp0AAAAAAAooEAHAAAAAIACCnQAAAAAACigQAcAAAAAgAIKdAAAAAAAKKBABwAAAACAAgp0AAAAAAAooEAHAAAAAIACCnQAAAAAACigQAcAAAAAgAIKdAAAAAAAKKBABwAAAACAAgp0AAAAAAAooEAHAAAAAIACCnQAAAAAACigQAcAAAAAgAIKdAAAAAAAKKBABwAAAACAAgp0AAAAAAAooEAHAAAAAIACCnQAAAAAACigQAcAAAAAgAIKdAAAAAAAKKBABwAAAACAAgp0AAAAAAAooEAHAAAAAIACHbpAnzBhQqqqqto9dtlll/L+t956K6NGjcpWW22VzTffPIcffngWLlzY7hgLFizIsGHDsummm6Z37945/fTT8/bbb7ebmT59evbaa69069YtO+64YyZNmrQ+Tg8AAAAAgA6sQxfoSbLbbrvlpZdeKj/uv//+8r7TTjstt912W2655Zbce++9efHFF/PFL36xvH/FihUZNmxYli1blgceeCA//elPM2nSpJx99tnlmebm5gwbNiwHHnhgZs+enTFjxuSEE07InXfeuV7PEwAAAACAjqWqVCqVKh3ib5kwYUImT56c2bNnr7avtbU122yzTW688cZ86UtfSpLMnTs3u+66a2bMmJH99tsvv/nNb/K5z30uL774Yvr06ZMkueaaazJu3Li88sorqa6uzrhx43L77bdnzpw55WMfeeSRWbRoUe644473nbWtrS21tbVpbW1NTU3NBztxAADel4aG+ZWOsEFrbh5Q6QgAALDerUmX2+GvQH/66adTX1+f7bffPsccc0wWLFiQJJk1a1aWL1+eIUOGlGd32WWXbLfddpkxY0aSZMaMGRk0aFC5PE+SpqamtLW15amnnirPvPMYq2ZWHeNvWbp0adra2to9AAAAAADYeHToAn3w4MGZNGlS7rjjjlx99dVpbm7O/vvvn9dffz0tLS2prq7OFlts0e41ffr0SUtLS5KkpaWlXXm+av+qfe8209bWljfffPNvZps4cWJqa2vLj379+n3Q0wUAAAAAoAPZpNIB3s0hhxxS/nr33XfP4MGD079//9x8883p0aNHBZMl48ePz9ixY8vP29ralOgAAAAAABuRDn0F+l/bYost8tGPfjTPPPNM6urqsmzZsixatKjdzMKFC1NXV5ckqaury8KFC1fbv2rfu83U1NS8a0nfrVu31NTUtHsAAAAAALDx2KAK9MWLF+fZZ59N3759s/fee+cjH/lIpk2bVt4/b968LFiwII2NjUmSxsbGPPnkk3n55ZfLM1OnTk1NTU0GDhxYnnnnMVbNrDoGAAAAAACdU4cu0L/zne/k3nvvzfz58/PAAw/kH//xH9O1a9ccddRRqa2tzciRIzN27Njcc889mTVrVr7+9a+nsbEx++23X5Jk6NChGThwYI499tg8/vjjufPOO3PmmWdm1KhR6datW5LkpJNOynPPPZfvfve7mTt3bq666qrcfPPNOe200yp56gAAAAAAVFiHvgf6n/70pxx11FH5y1/+km222SZ///d/nwcffDDbbLNNkuSSSy5Jly5dcvjhh2fp0qVpamrKVVddVX59165dM2XKlHzrW99KY2NjNttss4wYMSLnnXdeeaahoSG33357TjvttFx22WXZdttt82//9m9pampa7+cLAAAAAEDHUVUqlUqVDrExaGtrS21tbVpbW90PHQBgPWlomF/pCBu05uYBlY4AAADr3Zp0uR36Fi4AAAAAAFApCnQAAAAAACigQAcAAAAAgAIKdAAAAAAAKKBABwAAAACAAgp0AAAAAAAooEAHAAAAAIACCnQAAAAAACigQAcAAAAAgAIKdAAAAAAAKKBABwAAAACAAgp0AAAAAAAooEAHAAAAAIACCnQAAAAAACigQAcAAAAAgAIKdAAAAAAAKKBABwAAAACAAgp0AAAAAAAooEAHAAAAAIACCnQAAAAAACigQAcAAAAAgAIKdAAAAAAAKKBABwAAAACAAgp0AAAAAAAooEAHAAAAAIACCnQAAAAAACigQAcAAAAAgAIKdAAAAAAAKKBABwAAAACAAgp0AAAAAAAooEAHAAAAAIACCnQAAAAAACigQAcAAAAAgAIKdAAAAAAAKKBABwAAAACAAgp0AAAAAAAooEAHAAAAAIACCnQAAAAAACigQAcAAAAAgAIKdAAAAAAAKKBABwAAAACAAgp0AAAAAAAooEAHAAAAAIACCnQAAAAAACjQoQv0iRMnZt99903Pnj3Tu3fvDB8+PPPmzWs385nPfCZVVVXtHieddFK7mQULFmTYsGHZdNNN07t375x++ul5++23281Mnz49e+21V7p165Ydd9wxkyZN+rBPDwAAAACADqxDF+j33ntvRo0alQcffDBTp07N8uXLM3To0CxZsqTd3IknnpiXXnqp/LjwwgvL+1asWJFhw4Zl2bJleeCBB/LTn/40kyZNytlnn12eaW5uzrBhw3LggQdm9uzZGTNmTE444YTceeed6+1cAQAAAADoWKpKpVKp0iHer1deeSW9e/fOvffemwMOOCDJ/1yBvueee+bSSy8tfM1vfvObfO5zn8uLL76YPn36JEmuueaajBs3Lq+88kqqq6szbty43H777ZkzZ075dUceeWQWLVqUO+64431la2trS21tbVpbW1NTU/PBThQAgPeloWF+pSNs0JqbB1Q6AgAArHdr0uV26CvQ/1pra2uSpFevXu2233DDDdl6663zsY99LOPHj88bb7xR3jdjxowMGjSoXJ4nSVNTU9ra2vLUU0+VZ4YMGdLumE1NTZkxY8bfzLJ06dK0tbW1ewAAAAAAsPHYpNIB3q+VK1dmzJgx+dSnPpWPfexj5e1HH310+vfvn/r6+jzxxBMZN25c5s2bl1/84hdJkpaWlnbleZLy85aWlnedaWtry5tvvpkePXqslmfixIk599xz1+k5AgAAAADQcWwwBfqoUaMyZ86c3H///e22f+Mb3yh/PWjQoPTt2zcHHXRQnn322eywww4fWp7x48dn7Nix5edtbW3p16/fh/Z+AAAAAACsXxvELVxGjx6dKVOm5J577sm22277rrODBw9OkjzzzDNJkrq6uixcuLDdzKrndXV17zpTU1NTePV5knTr1i01NTXtHgAAAAAAbDw6dIFeKpUyevTo3Hrrrbn77rvT0NDwnq+ZPXt2kqRv375JksbGxjz55JN5+eWXyzNTp05NTU1NBg4cWJ6ZNm1au+NMnTo1jY2N6+hMAAAAAADY0HToAn3UqFH52c9+lhtvvDE9e/ZMS0tLWlpa8uabbyZJnn322Zx//vmZNWtW5s+fn1/96lf52te+lgMOOCC77757kmTo0KEZOHBgjj322Dz++OO58847c+aZZ2bUqFHp1q1bkuSkk07Kc889l+9+97uZO3durrrqqtx888057bTTKnbuAAAAAABUVlWpVCpVOsTfUlVVVbj9+uuvz3HHHZcXXnghX/3qVzNnzpwsWbIk/fr1yz/+4z/mzDPPbHdLleeffz7f+ta3Mn369Gy22WYZMWJELrjggmyyyf9/C/jp06fntNNOy+9///tsu+22Oeuss3Lccce976xtbW2pra1Na2ur27kAAKwnDQ3zKx1hg9bcPKDSEQAAYL1bky63QxfoGxIFOgDA+qdA/2AU6AAAdEZr0uV26Fu4AAAAAABApSjQAQAAAACggAIdAAAAAAAKKNABAAAAAKCAAh0AAAAAAAoo0AEAAAAAoIACHQAAAAAACijQAQAAAACggAIdAAAAAAAKKNABAAAAAKCAAh0AAAAAAAoo0AEAAAAAoIACHQAAAAAACijQAQAAAACggAIdAAAAAAAKKNABAAAAAKCAAh0AAAAAAApsUukAAKs0NMyvdIQNWnPzgEpHAAAAANiouAIdAAAAAAAKKNABAAAAAKCAAh0AAAAAAAoo0AEAAAAAoIACHQAAAAAACijQAQAAAACggAIdAAAAAAAKKNABAAAAAKCAAh0AAAAAAAoo0AEAAAAAoMAmlQ7QGTU0zK90hA1ac/OASkcAAKCAv+euPX/HBaDS/Dn+wfizfOPlCnQAAAAAACigQAcAAAAAgAIKdAAAAAAAKKBABwAAAACAAgp0AAAAAAAooEAHAAAAAIACCnQAAAAAACigQAcAAAAAgAIKdAAAAAAAKLBJpQNApTU0zK90hA1Wc/OASkfgQ+Rn44NZ1z8f1mPtWYuOxZ8dsH74d9UH48+OjsV6dBzWomPx96qNl5+ND2Zd/2y4Ah0AAAAAAAoo0AEAAAAAoIACHQAAAAAACijQAQAAAACggAIdAAAAAAAKKNABAAAAAKCAAv2vXHnllRkwYEC6d++ewYMH5+GHH650JAAAAAAAKkCB/g433XRTxo4dm3POOSePPvpo9thjjzQ1NeXll1+udDQAAAAAANYzBfo7/PCHP8yJJ56Yr3/96xk4cGCuueaabLrpprnuuusqHQ0AAAAAgPVsk0oH6CiWLVuWWbNmZfz48eVtXbp0yZAhQzJjxozV5pcuXZqlS5eWn7e2tiZJ2tra3vO9Vq58fR0k7rzez/d4TViPtWctOhbr0bFYj47DWnQs1qNjsR4dh7XoWKxHx2I9Og5r0bFYj45lXa6Htfhg3s9arJoplUrvOatA/19//vOfs2LFivTp06fd9j59+mTu3LmrzU+cODHnnnvuatv79ev3oWXkf9TWVjoBq1iLjsV6dCzWo+OwFh2L9ehYrEfHYS06FuvRsViPjsNadCzWo2OxHh3HmqzF66+/ntr3eIECfS2NHz8+Y8eOLT9fuXJlXn311Wy11VapqqqqYLIPpq2tLf369csLL7yQmpqaSsfp9KxHx2EtOhbr0bFYj47DWnQs1qPjsBYdi/XoWKxHx2EtOhbr0bFYj45jY1mLUqmU119/PfX19e85q0D/X1tvvXW6du2ahQsXttu+cOHC1NXVrTbfrVu3dOvWrd22LbbY4sOMuF7V1NRs0D8EGxvr0XFYi47FenQs1qPjsBYdi/XoOKxFx2I9Ohbr0XFYi47FenQs1qPj2BjW4r2uPF/FLxH9X9XV1dl7770zbdq08raVK1dm2rRpaWxsrGAyAAAAAAAqwRXo7zB27NiMGDEi++yzTz7xiU/k0ksvzZIlS/L1r3+90tEAAAAAAFjPFOjvcMQRR+SVV17J2WefnZaWluy555654447VvvFohuzbt265Zxzzlnt9jRUhvXoOKxFx2I9Ohbr0XFYi47FenQc1qJjsR4di/XoOKxFx2I9Ohbr0XF0xrWoKpVKpUqHAAAAAACAjsY90AEAAAAAoIACHQAAAAAACijQAQAAAACggAIdAAAAAAAKKNApu/LKKzNgwIB07949gwcPzsMPP1zpSJ3Wfffdl8MOOyz19fWpqqrK5MmTKx2p05o4cWL23Xff9OzZM717987w4cMzb968SsfqtK6++ursvvvuqampSU1NTRobG/Ob3/ym0rFIcsEFF6SqqipjxoypdJROacKECamqqmr32GWXXSodq9P67//+73z1q1/NVlttlR49emTQoEF55JFHKh2rUxowYMBqPxtVVVUZNWpUpaN1SitWrMhZZ52VhoaG9OjRIzvssEPOP//8lEqlSkfrlF5//fWMGTMm/fv3T48ePfLJT34yM2fOrHSsTuG9Pu+VSqWcffbZ6du3b3r06JEhQ4bk6aefrkzYTuC91uMXv/hFhg4dmq222ipVVVWZPXt2RXJ2Bu+2FsuXL8+4ceMyaNCgbLbZZqmvr8/Xvva1vPjii5ULvJF7r5+NCRMmZJdddslmm22WLbfcMkOGDMlDDz1UmbAfMgU6SZKbbropY8eOzTnnnJNHH300e+yxR5qamvLyyy9XOlqntGTJkuyxxx658sorKx2l07v33nszatSoPPjgg5k6dWqWL1+eoUOHZsmSJZWO1iltu+22ueCCCzJr1qw88sgj+exnP5svfOELeeqppyodrVObOXNm/u///b/ZfffdKx2lU9ttt93y0ksvlR/3339/pSN1Sq+99lo+9alP5SMf+Uh+85vf5Pe//30uvvjibLnllpWO1inNnDmz3c/F1KlTkyRf/vKXK5ysc/rXf/3XXH311bniiivyhz/8If/6r/+aCy+8MD/60Y8qHa1TOuGEEzJ16tT8+7//e5588skMHTo0Q4YMyX//939XOtpG770+71144YW5/PLLc8011+Shhx7KZpttlqamprz11lvrOWnn8F7rsWTJkvz93/99/vVf/3U9J+t83m0t3njjjTz66KM566yz8uijj+YXv/hF5s2bl89//vMVSNo5vNfPxkc/+tFcccUVefLJJ3P//fdnwIABGTp0aF555ZX1nPTDV1Xyn/tJMnjw4Oy777654oorkiQrV65Mv379cvLJJ+eMM86ocLrOraqqKrfeemuGDx9e6SgkeeWVV9K7d+/ce++9OeCAAyodhyS9evXKRRddlJEjR1Y6Sqe0ePHi7LXXXrnqqqvy/e9/P3vuuWcuvfTSSsfqdCZMmJDJkye7IqoDOOOMM/K73/0u//Vf/1XpKBQYM2ZMpkyZkqeffjpVVVWVjtPpfO5zn0ufPn3yk5/8pLzt8MMPT48ePfKzn/2sgsk6nzfffDM9e/bML3/5ywwbNqy8fe+9984hhxyS73//+xVM17n89ee9UqmU+vr6fPvb3853vvOdJElra2v69OmTSZMm5cgjj6xg2o3fu33+nj9/fhoaGvLYY49lzz33XO/ZOpv304XMnDkzn/jEJ/L8889nu+22W3/hOqH3sx5tbW2pra3NXXfdlYMOOmj9hVsPXIFOli1bllmzZmXIkCHlbV26dMmQIUMyY8aMCiaDjqe1tTXJ/5S2VNaKFSvy85//PEuWLEljY2Ol43Rao0aNyrBhw9r9GUJlPP3006mvr8/222+fY445JgsWLKh0pE7pV7/6VfbZZ598+ctfTu/evfPxj388P/7xjysdi/zP33l/9rOf5fjjj1eeV8gnP/nJTJs2LX/84x+TJI8//njuv//+HHLIIRVO1vm8/fbbWbFiRbp3795ue48ePfwfTBXW3NyclpaWdn+3qq2tzeDBg30+h7/S2tqaqqqqbLHFFpWO0uktW7Ys1157bWpra7PHHntUOs46t0mlA1B5f/7zn7NixYr06dOn3fY+ffpk7ty5FUoFHc/KlSszZsyYfOpTn8rHPvaxSsfptJ588sk0Njbmrbfeyuabb55bb701AwcOrHSsTunnP/95Hn30UfdL7QAGDx6cSZMmZeedd85LL72Uc889N/vvv3/mzJmTnj17Vjpep/Lcc8/l6quvztixY/PP//zPmTlzZk455ZRUV1dnxIgRlY7XqU2ePDmLFi3KcccdV+kondYZZ5yRtra27LLLLunatWtWrFiRH/zgBznmmGMqHa3T6dmzZxobG3P++edn1113TZ8+ffIf//EfmTFjRnbcccdKx+vUWlpakqTw8/mqfUDy1ltvZdy4cTnqqKNSU1NT6Tid1pQpU3LkkUfmjTfeSN++fTN16tRsvfXWlY61zinQAd6nUaNGZc6cOa7KqbCdd945s2fPTmtra/7zP/8zI0aMyL333qtEX89eeOGFnHrqqZk6depqV6+x/r3z6s3dd989gwcPTv/+/XPzzTe7vdF6tnLlyuyzzz75l3/5lyTJxz/+8cyZMyfXXHONAr3CfvKTn+SQQw5JfX19paN0WjfffHNuuOGG3Hjjjdltt90ye/bsjBkzJvX19X4+KuDf//3fc/zxx+fv/u7v0rVr1+y111456qijMmvWrEpHA3hXy5cvz1e+8pWUSqVcffXVlY7TqR144IGZPXt2/vznP+fHP/5xvvKVr+Shhx5K7969Kx1tnXILF7L11luna9euWbhwYbvtCxcuTF1dXYVSQccyevToTJkyJffcc0+23XbbSsfp1Kqrq7Pjjjtm7733zsSJE7PHHnvksssuq3SsTmfWrFl5+eWXs9dee2WTTTbJJptsknvvvTeXX355Ntlkk6xYsaLSETu1LbbYIh/96EfzzDPPVDpKp9O3b9/V/oPerrvu6pY6Ffb888/nrrvuygknnFDpKJ3a6aefnjPOOCNHHnlkBg0alGOPPTannXZaJk6cWOlondIOO+yQe++9N4sXL84LL7yQhx9+OMuXL8/2229f6Wid2qrP4D6fQ7FV5fnzzz+fqVOnuvq8wjbbbLPsuOOO2W+//fKTn/wkm2yySbvfdbKxUKCT6urq7L333pk2bVp528qVKzNt2jT3FabTK5VKGT16dG699dbcfffdaWhoqHQk/srKlSuzdOnSSsfodA466KA8+eSTmT17dvmxzz775Jhjjsns2bPTtWvXSkfs1BYvXpxnn302ffv2rXSUTudTn/pU5s2b127bH//4x/Tv379CiUiS66+/Pr179273yxJZ/95444106dL+I2jXrl2zcuXKCiUi+Z/yo2/fvnnttddy55135gtf+EKlI3VqDQ0Nqaura/f5vK2tLQ899JDP53R6q8rzp59+OnfddVe22mqrSkfir2ysn8/dwoUkydixYzNixIjss88++cQnPpFLL700S5Ysyde//vVKR+uUFi9e3O6qwebm5syePTu9evXym6XXs1GjRuXGG2/ML3/5y/Ts2bN838Ha2tr06NGjwuk6n/Hjx+eQQw7Jdtttl9dffz033nhjpk+fnjvvvLPS0Tqdnj17rva7ADbbbLNstdVWfkdABXznO9/JYYcdlv79++fFF1/MOeeck65du+aoo46qdLRO57TTTssnP/nJ/Mu//Eu+8pWv5OGHH861116ba6+9ttLROq2VK1fm+uuvz4gRI7LJJj7+VNJhhx2WH/zgB9luu+2y22675bHHHssPf/jDHH/88ZWO1indeeedKZVK2XnnnfPMM8/k9NNPzy677OIz4HrwXp/3xowZk+9///vZaaed0tDQkLPOOiv19fUZPnx45UJvxN5rPV599dUsWLAgL774YpKU/0N5XV2d/ytgHXu3tejbt2++9KUv5dFHH82UKVOyYsWK8ufzXr16pbq6ulKxN1rvth5bbbVVfvCDH+Tzn/98+vbtmz//+c+58sor89///d/58pe/XMHUH5IS/K8f/ehHpe22265UXV1d+sQnPlF68MEHKx2p07rnnntKSVZ7jBgxotLROp2idUhSuv766ysdrVM6/vjjS/379y9VV1eXttlmm9JBBx1U+u1vf1vpWPyvT3/606VTTz210jE6pSOOOKLUt2/fUnV1denv/u7vSkcccUTpmWeeqXSsTuu2224rfexjHyt169attMsuu5SuvfbaSkfq1O68885SktK8efMqHaXTa2trK5166qml7bbbrtS9e/fS9ttvX/re975XWrp0aaWjdUo33XRTafvtty9VV1eX6urqSqNGjSotWrSo0rE6hff6vLdy5crSWWedVerTp0+pW7dupYMOOsi/wz5E77Ue119/feH+c845p6K5N0bvthbNzc1/8/P5PffcU+noG6V3W48333yz9I//+I+l+vr6UnV1dalv376lz3/+86WHH3640rE/FFWlUqn0IXXzAAAAAACwwXIPdAAAAAAAKKBABwAAAACAAgp0AAAAAAAooEAHAAAAAIACCnQAAAAAACigQAcAAAAAgAIKdAAAAAAAKKBABwCADdxnPvOZjBkz5n3NTp8+PVVVVVm0aNEHes8BAwbk0ksv/UDHAACAjk6BDgAArBelUimHHHJIqqqqMnny5ErHAQCA96RABwAA1otLL700VVVVlY4BAADvmwIdAAA2Iv/+7/+effbZJz179kxdXV2OPvrovPzyy6vN/e53v8vuu++e7t27Z7/99sucOXPa7b///vuz//77p0ePHunXr19OOeWULFmyZK1zzZ49OxdffHGuu+66tT4GAACsbwp0AADYiCxfvjznn39+Hn/88UyePDnz58/Pcccdt9rc6aefnosvvjgzZ87MNttsk8MOOyzLly9Pkjz77LM5+OCDc/jhh+eJJ57ITTfdlPvvvz+jR49eq0xvvPFGjj766Fx55ZWpq6v7IKcHAADr1SaVDgAAAKw7xx9/fPnr7bffPpdffnn23XffLF68OJtvvnl53znnnJN/+Id/SJL89Kc/zbbbbptbb701X/nKVzJx4sQcc8wx5V9MutNOO+Xyyy/Ppz/96Vx99dXp3r37GmU67bTT8slPfjJf+MIXPvgJAgDAeqRABwCAjcisWbMyYcKEPP7443nttdeycuXKJMmCBQsycODA8lxjY2P56169emXnnXfOH/7whyTJ448/nieeeCI33HBDeaZUKmXlypVpbm7Orrvu+r7z/OpXv8rdd9+dxx577IOeGgAArHcKdAAA2EgsWbIkTU1NaWpqyg033JBtttkmCxYsSFNTU5YtW/a+j7N48eJ885vfzCmnnLLavu22226NMt1999159tlns8UWW7Tbfvjhh2f//ffP9OnT1+h4AACwPinQAQBgIzF37tz85S9/yQUXXJB+/folSR555JHC2QcffLBchr/22mv54x//WL6yfK+99srvf//77Ljjjh840xlnnJETTjih3bZBgwblkksuyWGHHfaBjw8AAB8mBToAAGwktttuu1RXV+dHP/pRTjrppMyZMyfnn39+4ex5552XrbbaKn369Mn3vve9bL311hk+fHiSZNy4cdlvv/0yevTonHDCCdlss83y+9//PlOnTs0VV1yxRpnq6uoKf3Hodtttl4aGhjU+RwAAWJ+6VDoAAACwbmyzzTaZNGlSbrnllgwcODAXXHBB/s//+T+FsxdccEFOPfXU7L333mlpacltt92W6urqJMnuu++ee++9N3/84x+z//775+Mf/3jOPvvs1NfXr8/TAQCAiqsqlUqlSocAAAAAAICOxhXoAAAAAABQQIEOAACstRtuuCGbb7554WO33XardDwAAPhA3MIFAABYa6+//noWLlxYuO8jH/lI+vfvv54TAQDAuqNABwAAAACAAm7hAgAAAAAABRToAAAAAABQQIEOAAAAAAAFFOgAAAAAAFBAgQ4AAAAAAAUU6AAAAAAAUECBDgAAAAAABRToAAAAAABQ4P8DRXkuCBLmrK8AAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 1800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "\n",
        "L4 = 'label_4'\n",
        "\n",
        "plt.figure(figsize=(18,6))\n",
        "sn.countplot(data=y_train, x=L4, color='blue')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Initial Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy = 0.8866666666666667\n"
          ]
        }
      ],
      "source": [
        "accuracy = weighted_svm_classifier(x_train[L4], y_train[L4], x_valid[L4], y_valid[L4])\n",
        "print(f\"Accuracy = {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_matrix_l4 = x_train[L4].corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>feature_10</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_759</th>\n",
              "      <th>feature_760</th>\n",
              "      <th>feature_761</th>\n",
              "      <th>feature_762</th>\n",
              "      <th>feature_763</th>\n",
              "      <th>feature_764</th>\n",
              "      <th>feature_765</th>\n",
              "      <th>feature_766</th>\n",
              "      <th>feature_767</th>\n",
              "      <th>feature_768</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>feature_1</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.065348</td>\n",
              "      <td>-0.039416</td>\n",
              "      <td>0.116528</td>\n",
              "      <td>0.108225</td>\n",
              "      <td>-0.163679</td>\n",
              "      <td>0.131004</td>\n",
              "      <td>-0.073198</td>\n",
              "      <td>-0.045476</td>\n",
              "      <td>-0.120560</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225724</td>\n",
              "      <td>0.290177</td>\n",
              "      <td>0.015310</td>\n",
              "      <td>0.144664</td>\n",
              "      <td>-0.110313</td>\n",
              "      <td>-0.040330</td>\n",
              "      <td>0.132620</td>\n",
              "      <td>0.032706</td>\n",
              "      <td>0.035296</td>\n",
              "      <td>-0.039317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_2</th>\n",
              "      <td>0.065348</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.043611</td>\n",
              "      <td>0.068624</td>\n",
              "      <td>-0.278709</td>\n",
              "      <td>0.052155</td>\n",
              "      <td>-0.267946</td>\n",
              "      <td>-0.214403</td>\n",
              "      <td>-0.235840</td>\n",
              "      <td>-0.056829</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.150852</td>\n",
              "      <td>-0.096604</td>\n",
              "      <td>0.287950</td>\n",
              "      <td>-0.099087</td>\n",
              "      <td>0.269144</td>\n",
              "      <td>0.005612</td>\n",
              "      <td>-0.068710</td>\n",
              "      <td>-0.204834</td>\n",
              "      <td>-0.350866</td>\n",
              "      <td>0.162593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_3</th>\n",
              "      <td>-0.039416</td>\n",
              "      <td>0.043611</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.185437</td>\n",
              "      <td>-0.313107</td>\n",
              "      <td>-0.103496</td>\n",
              "      <td>-0.214606</td>\n",
              "      <td>-0.185952</td>\n",
              "      <td>0.155197</td>\n",
              "      <td>0.011407</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.248988</td>\n",
              "      <td>-0.162378</td>\n",
              "      <td>-0.024814</td>\n",
              "      <td>0.162806</td>\n",
              "      <td>0.231606</td>\n",
              "      <td>0.204807</td>\n",
              "      <td>0.133835</td>\n",
              "      <td>-0.063354</td>\n",
              "      <td>0.159975</td>\n",
              "      <td>0.217143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_4</th>\n",
              "      <td>0.116528</td>\n",
              "      <td>0.068624</td>\n",
              "      <td>-0.185437</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.096349</td>\n",
              "      <td>-0.220416</td>\n",
              "      <td>0.194002</td>\n",
              "      <td>0.027816</td>\n",
              "      <td>-0.144393</td>\n",
              "      <td>-0.148927</td>\n",
              "      <td>...</td>\n",
              "      <td>0.135598</td>\n",
              "      <td>0.071113</td>\n",
              "      <td>-0.084978</td>\n",
              "      <td>-0.166751</td>\n",
              "      <td>-0.220446</td>\n",
              "      <td>0.103712</td>\n",
              "      <td>0.100221</td>\n",
              "      <td>0.006758</td>\n",
              "      <td>0.034292</td>\n",
              "      <td>-0.128138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_5</th>\n",
              "      <td>0.108225</td>\n",
              "      <td>-0.278709</td>\n",
              "      <td>-0.313107</td>\n",
              "      <td>0.096349</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.021056</td>\n",
              "      <td>0.325761</td>\n",
              "      <td>-0.000900</td>\n",
              "      <td>0.038333</td>\n",
              "      <td>-0.116997</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.020572</td>\n",
              "      <td>0.024932</td>\n",
              "      <td>-0.202849</td>\n",
              "      <td>0.031865</td>\n",
              "      <td>-0.371326</td>\n",
              "      <td>-0.087327</td>\n",
              "      <td>-0.063512</td>\n",
              "      <td>0.016875</td>\n",
              "      <td>-0.031415</td>\n",
              "      <td>-0.203071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_764</th>\n",
              "      <td>-0.040330</td>\n",
              "      <td>0.005612</td>\n",
              "      <td>0.204807</td>\n",
              "      <td>0.103712</td>\n",
              "      <td>-0.087327</td>\n",
              "      <td>-0.174192</td>\n",
              "      <td>0.122454</td>\n",
              "      <td>0.012446</td>\n",
              "      <td>0.199985</td>\n",
              "      <td>0.171440</td>\n",
              "      <td>...</td>\n",
              "      <td>0.075743</td>\n",
              "      <td>0.065512</td>\n",
              "      <td>-0.313912</td>\n",
              "      <td>-0.196618</td>\n",
              "      <td>-0.114188</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.208730</td>\n",
              "      <td>0.181622</td>\n",
              "      <td>0.405485</td>\n",
              "      <td>-0.009266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_765</th>\n",
              "      <td>0.132620</td>\n",
              "      <td>-0.068710</td>\n",
              "      <td>0.133835</td>\n",
              "      <td>0.100221</td>\n",
              "      <td>-0.063512</td>\n",
              "      <td>-0.345465</td>\n",
              "      <td>-0.002038</td>\n",
              "      <td>0.005804</td>\n",
              "      <td>0.053829</td>\n",
              "      <td>-0.116723</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.103060</td>\n",
              "      <td>0.180543</td>\n",
              "      <td>-0.010908</td>\n",
              "      <td>-0.076788</td>\n",
              "      <td>0.228983</td>\n",
              "      <td>0.208730</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.204636</td>\n",
              "      <td>0.278358</td>\n",
              "      <td>-0.172730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_766</th>\n",
              "      <td>0.032706</td>\n",
              "      <td>-0.204834</td>\n",
              "      <td>-0.063354</td>\n",
              "      <td>0.006758</td>\n",
              "      <td>0.016875</td>\n",
              "      <td>-0.233690</td>\n",
              "      <td>0.282928</td>\n",
              "      <td>-0.105139</td>\n",
              "      <td>0.097498</td>\n",
              "      <td>0.391228</td>\n",
              "      <td>...</td>\n",
              "      <td>0.096985</td>\n",
              "      <td>0.293527</td>\n",
              "      <td>-0.266795</td>\n",
              "      <td>0.168379</td>\n",
              "      <td>-0.486373</td>\n",
              "      <td>0.181622</td>\n",
              "      <td>-0.204636</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.388446</td>\n",
              "      <td>-0.065182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_767</th>\n",
              "      <td>0.035296</td>\n",
              "      <td>-0.350866</td>\n",
              "      <td>0.159975</td>\n",
              "      <td>0.034292</td>\n",
              "      <td>-0.031415</td>\n",
              "      <td>-0.350340</td>\n",
              "      <td>0.185927</td>\n",
              "      <td>0.045446</td>\n",
              "      <td>0.113304</td>\n",
              "      <td>0.265687</td>\n",
              "      <td>...</td>\n",
              "      <td>0.115303</td>\n",
              "      <td>0.274362</td>\n",
              "      <td>-0.343106</td>\n",
              "      <td>0.081103</td>\n",
              "      <td>-0.327079</td>\n",
              "      <td>0.405485</td>\n",
              "      <td>0.278358</td>\n",
              "      <td>0.388446</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.132940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_768</th>\n",
              "      <td>-0.039317</td>\n",
              "      <td>0.162593</td>\n",
              "      <td>0.217143</td>\n",
              "      <td>-0.128138</td>\n",
              "      <td>-0.203071</td>\n",
              "      <td>0.242545</td>\n",
              "      <td>-0.390389</td>\n",
              "      <td>-0.033126</td>\n",
              "      <td>0.020400</td>\n",
              "      <td>-0.093904</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.012714</td>\n",
              "      <td>-0.117084</td>\n",
              "      <td>0.191413</td>\n",
              "      <td>0.091538</td>\n",
              "      <td>0.299900</td>\n",
              "      <td>-0.009266</td>\n",
              "      <td>-0.172730</td>\n",
              "      <td>-0.065182</td>\n",
              "      <td>-0.132940</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows Ã— 768 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
              "feature_1     1.000000   0.065348  -0.039416   0.116528   0.108225  -0.163679   \n",
              "feature_2     0.065348   1.000000   0.043611   0.068624  -0.278709   0.052155   \n",
              "feature_3    -0.039416   0.043611   1.000000  -0.185437  -0.313107  -0.103496   \n",
              "feature_4     0.116528   0.068624  -0.185437   1.000000   0.096349  -0.220416   \n",
              "feature_5     0.108225  -0.278709  -0.313107   0.096349   1.000000   0.021056   \n",
              "...                ...        ...        ...        ...        ...        ...   \n",
              "feature_764  -0.040330   0.005612   0.204807   0.103712  -0.087327  -0.174192   \n",
              "feature_765   0.132620  -0.068710   0.133835   0.100221  -0.063512  -0.345465   \n",
              "feature_766   0.032706  -0.204834  -0.063354   0.006758   0.016875  -0.233690   \n",
              "feature_767   0.035296  -0.350866   0.159975   0.034292  -0.031415  -0.350340   \n",
              "feature_768  -0.039317   0.162593   0.217143  -0.128138  -0.203071   0.242545   \n",
              "\n",
              "             feature_7  feature_8  feature_9  feature_10  ...  feature_759  \\\n",
              "feature_1     0.131004  -0.073198  -0.045476   -0.120560  ...    -0.225724   \n",
              "feature_2    -0.267946  -0.214403  -0.235840   -0.056829  ...    -0.150852   \n",
              "feature_3    -0.214606  -0.185952   0.155197    0.011407  ...    -0.248988   \n",
              "feature_4     0.194002   0.027816  -0.144393   -0.148927  ...     0.135598   \n",
              "feature_5     0.325761  -0.000900   0.038333   -0.116997  ...    -0.020572   \n",
              "...                ...        ...        ...         ...  ...          ...   \n",
              "feature_764   0.122454   0.012446   0.199985    0.171440  ...     0.075743   \n",
              "feature_765  -0.002038   0.005804   0.053829   -0.116723  ...    -0.103060   \n",
              "feature_766   0.282928  -0.105139   0.097498    0.391228  ...     0.096985   \n",
              "feature_767   0.185927   0.045446   0.113304    0.265687  ...     0.115303   \n",
              "feature_768  -0.390389  -0.033126   0.020400   -0.093904  ...    -0.012714   \n",
              "\n",
              "             feature_760  feature_761  feature_762  feature_763  feature_764  \\\n",
              "feature_1       0.290177     0.015310     0.144664    -0.110313    -0.040330   \n",
              "feature_2      -0.096604     0.287950    -0.099087     0.269144     0.005612   \n",
              "feature_3      -0.162378    -0.024814     0.162806     0.231606     0.204807   \n",
              "feature_4       0.071113    -0.084978    -0.166751    -0.220446     0.103712   \n",
              "feature_5       0.024932    -0.202849     0.031865    -0.371326    -0.087327   \n",
              "...                  ...          ...          ...          ...          ...   \n",
              "feature_764     0.065512    -0.313912    -0.196618    -0.114188     1.000000   \n",
              "feature_765     0.180543    -0.010908    -0.076788     0.228983     0.208730   \n",
              "feature_766     0.293527    -0.266795     0.168379    -0.486373     0.181622   \n",
              "feature_767     0.274362    -0.343106     0.081103    -0.327079     0.405485   \n",
              "feature_768    -0.117084     0.191413     0.091538     0.299900    -0.009266   \n",
              "\n",
              "             feature_765  feature_766  feature_767  feature_768  \n",
              "feature_1       0.132620     0.032706     0.035296    -0.039317  \n",
              "feature_2      -0.068710    -0.204834    -0.350866     0.162593  \n",
              "feature_3       0.133835    -0.063354     0.159975     0.217143  \n",
              "feature_4       0.100221     0.006758     0.034292    -0.128138  \n",
              "feature_5      -0.063512     0.016875    -0.031415    -0.203071  \n",
              "...                  ...          ...          ...          ...  \n",
              "feature_764     0.208730     0.181622     0.405485    -0.009266  \n",
              "feature_765     1.000000    -0.204636     0.278358    -0.172730  \n",
              "feature_766    -0.204636     1.000000     0.388446    -0.065182  \n",
              "feature_767     0.278358     0.388446     1.000000    -0.132940  \n",
              "feature_768    -0.172730    -0.065182    -0.132940     1.000000  \n",
              "\n",
              "[768 rows x 768 columns]"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corr_matrix_l4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_corr_features(corr_matrix, threshold):\n",
        "\n",
        "  correlated_features = []\n",
        "\n",
        "  for i in range(len(corr_matrix.columns)):\n",
        "    for j in range(i+1, len(corr_matrix.columns)):\n",
        "      if (abs(corr_matrix.iloc[i, j]) > threshold):\n",
        "        col_name = corr_matrix.columns[j]\n",
        "        if col_name not in correlated_features:\n",
        "          correlated_features.append(col_name)\n",
        "\n",
        "  return correlated_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n"
          ]
        }
      ],
      "source": [
        "correlated_features_l4 = get_corr_features(corr_matrix_l4, 0.7)\n",
        "print(len(correlated_features_l4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "x_test_l4 = x_test.copy()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train[L4] = pd.DataFrame(scaler.fit_transform(x_train[L4]), columns=FEATURES)\n",
        "x_valid[L4] = pd.DataFrame(scaler.transform(x_valid[L4]), columns=FEATURES)\n",
        "x_test_l4 = pd.DataFrame(scaler.transform(x_test_l4), columns=FEATURES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of features: 350\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "threshold = 0.96\n",
        "\n",
        "pca = PCA(n_components=threshold, svd_solver='full')\n",
        "x_train_l4_pca = pd.DataFrame(pca.fit_transform(x_train[L4]))\n",
        "x_valid_l4_pca = pd.DataFrame(pca.transform(x_valid[L4]))\n",
        "x_test_l4_pca = pd.DataFrame(pca.transform(x_test_l4))\n",
        "\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "\n",
        "print(f\"Number of features: {len(explained_variance)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy = 0.8906666666666667\n"
          ]
        }
      ],
      "source": [
        "accuracy_1 = weighted_svm_classifier(x_train_l4_pca, y_train[L4], x_valid_l4_pca, y_valid[L4])\n",
        "print(f\"Accuracy = {accuracy_1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Hyperparameter Tuning - Random Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'kernel': 'poly', 'gamma': 1000.0, 'class_weight': 'balanced', 'C': 0.01}\n",
            "0.8159186535764376\n"
          ]
        }
      ],
      "source": [
        "param_dist = {\n",
        "    'C': np.logspace(-3, 3, 7),\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'gamma': np.logspace(-3, 3, 7),\n",
        "    'class_weight': ['balanced']\n",
        "}\n",
        "cv = 2\n",
        "n_iter = 5\n",
        "svm = SVC()\n",
        "\n",
        "random_search_l4 = random_grid_search(svm, param_dist, cv, n_iter, x_train_l4_pca, y_train[L4])\n",
        "best_model_l4 = random_search_l4.best_estimator_\n",
        "best_accuracy_l4 = random_search_l4.best_score_\n",
        "best_param = random_search_l4.best_params_\n",
        "\n",
        "print(best_param)\n",
        "print(best_accuracy_l4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy after: 0.9746666666666667\n"
          ]
        }
      ],
      "source": [
        "y_pred_l4 = best_model_l4.predict(x_valid_l1_pca)\n",
        "accuracy = accuracy_score(y_valid[L4], y_pred_l4)\n",
        "print(f\"Accuracy after: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-Validation Scores: [0.94161992 0.92952314 0.9414446  0.94670407 0.92180926]\n",
            "Mean Score: 0.9362201963534362\n",
            "Standard Deviation: 0.009153017446849782\n"
          ]
        }
      ],
      "source": [
        "model = SVC(kernel= 'poly', gamma= 1000.0, class_weight= 'balanced', C= 0.01)\n",
        "\n",
        "k_fold_cross_validation(model, 5, x_train_l4_pca, y_train[L4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prediciton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Label 1\n",
        "pred_l1 = best_model_l1.predict(x_test_l1_pca)\n",
        "# Label 2\n",
        "pred_l2 = best_model_l2.predict(x_test_l2_pca)\n",
        "# Label 3\n",
        "pred_l3 = best_model_l3.predict(x_test_l3_pca)\n",
        "# Label 4\n",
        "pred_l4 = best_model_l4.predict(x_test_l4_pca)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "id_list = test_df['ID']\n",
        "\n",
        "result = {\n",
        "    'ID': id_list,\n",
        "    'label_1': pred_l1,\n",
        "    'label_2': pred_l2,\n",
        "    'label_3': pred_l3,\n",
        "    'label_4': pred_l4\n",
        "}\n",
        "\n",
        "result_df = pd.DataFrame(result)\n",
        "\n",
        "result_df.to_csv('layer_9.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
