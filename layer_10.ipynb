{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Layer 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lb_YDijM8zS",
        "outputId": "9ee8d167-935e-47ec-d96f-8cd65af24715"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# DATASET_PATH = \"/content/drive/MyDrive/ML Project/layer 9\"\n",
        "DATASET_PATH = \"layer 10\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-fmzxIArNja4"
      },
      "outputs": [],
      "source": [
        "# CSV files into Pandas DataFrames\n",
        "train_df = pd.read_csv(f\"{DATASET_PATH}/train.csv\")\n",
        "valid_df = pd.read_csv(f\"{DATASET_PATH}/valid.csv\")\n",
        "test_df = pd.read_csv(f\"{DATASET_PATH}/test.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VUVoO3KlOQ3T"
      },
      "outputs": [],
      "source": [
        "temp = list(train_df.columns)\n",
        "\n",
        "FEATURES = temp[:-4]\n",
        "LABELS = temp[-4:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "k9RXSp5jQ9HL",
        "outputId": "9cb6f512-eb01-43a1-9a98-9de7a26c1e89"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>feature_10</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_759</th>\n",
              "      <th>feature_760</th>\n",
              "      <th>feature_761</th>\n",
              "      <th>feature_762</th>\n",
              "      <th>feature_763</th>\n",
              "      <th>feature_764</th>\n",
              "      <th>feature_765</th>\n",
              "      <th>feature_766</th>\n",
              "      <th>feature_767</th>\n",
              "      <th>feature_768</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.063023</td>\n",
              "      <td>0.085030</td>\n",
              "      <td>-0.057909</td>\n",
              "      <td>0.024293</td>\n",
              "      <td>0.028695</td>\n",
              "      <td>-0.113796</td>\n",
              "      <td>0.028477</td>\n",
              "      <td>-0.006041</td>\n",
              "      <td>-0.132434</td>\n",
              "      <td>0.088144</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.160050</td>\n",
              "      <td>0.078897</td>\n",
              "      <td>0.120168</td>\n",
              "      <td>-0.160152</td>\n",
              "      <td>-0.200884</td>\n",
              "      <td>0.046231</td>\n",
              "      <td>-0.115850</td>\n",
              "      <td>0.182974</td>\n",
              "      <td>0.047106</td>\n",
              "      <td>-0.118783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.036403</td>\n",
              "      <td>0.115930</td>\n",
              "      <td>-0.066521</td>\n",
              "      <td>0.045771</td>\n",
              "      <td>-0.027250</td>\n",
              "      <td>-0.164679</td>\n",
              "      <td>0.023611</td>\n",
              "      <td>0.056512</td>\n",
              "      <td>-0.171498</td>\n",
              "      <td>-0.021133</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.137038</td>\n",
              "      <td>0.042576</td>\n",
              "      <td>0.006788</td>\n",
              "      <td>-0.207013</td>\n",
              "      <td>-0.205184</td>\n",
              "      <td>-0.053462</td>\n",
              "      <td>-0.003775</td>\n",
              "      <td>-0.035003</td>\n",
              "      <td>-0.041118</td>\n",
              "      <td>-0.079211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.030672</td>\n",
              "      <td>0.045321</td>\n",
              "      <td>-0.163811</td>\n",
              "      <td>0.142376</td>\n",
              "      <td>-0.125894</td>\n",
              "      <td>-0.083943</td>\n",
              "      <td>-0.039693</td>\n",
              "      <td>-0.004867</td>\n",
              "      <td>-0.127951</td>\n",
              "      <td>0.111345</td>\n",
              "      <td>...</td>\n",
              "      <td>0.090191</td>\n",
              "      <td>0.038063</td>\n",
              "      <td>0.070423</td>\n",
              "      <td>-0.253409</td>\n",
              "      <td>-0.072147</td>\n",
              "      <td>0.016236</td>\n",
              "      <td>-0.144047</td>\n",
              "      <td>-0.122405</td>\n",
              "      <td>-0.063079</td>\n",
              "      <td>-0.188233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.000984</td>\n",
              "      <td>0.080593</td>\n",
              "      <td>-0.067086</td>\n",
              "      <td>0.005251</td>\n",
              "      <td>-0.141851</td>\n",
              "      <td>-0.125211</td>\n",
              "      <td>-0.016161</td>\n",
              "      <td>0.106323</td>\n",
              "      <td>-0.203491</td>\n",
              "      <td>-0.027378</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.107041</td>\n",
              "      <td>0.028166</td>\n",
              "      <td>-0.073713</td>\n",
              "      <td>-0.073180</td>\n",
              "      <td>-0.109380</td>\n",
              "      <td>-0.027901</td>\n",
              "      <td>-0.006863</td>\n",
              "      <td>0.016840</td>\n",
              "      <td>-0.171139</td>\n",
              "      <td>0.086868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.059806</td>\n",
              "      <td>0.088846</td>\n",
              "      <td>-0.058021</td>\n",
              "      <td>0.133098</td>\n",
              "      <td>-0.083380</td>\n",
              "      <td>-0.026724</td>\n",
              "      <td>-0.033793</td>\n",
              "      <td>-0.004055</td>\n",
              "      <td>-0.057890</td>\n",
              "      <td>-0.011114</td>\n",
              "      <td>...</td>\n",
              "      <td>0.047907</td>\n",
              "      <td>0.026333</td>\n",
              "      <td>0.012204</td>\n",
              "      <td>-0.245772</td>\n",
              "      <td>-0.044506</td>\n",
              "      <td>0.058273</td>\n",
              "      <td>-0.005203</td>\n",
              "      <td>-0.104552</td>\n",
              "      <td>0.002035</td>\n",
              "      <td>-0.091528</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 768 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
              "0  -0.063023   0.085030  -0.057909   0.024293   0.028695  -0.113796   \n",
              "1  -0.036403   0.115930  -0.066521   0.045771  -0.027250  -0.164679   \n",
              "2   0.030672   0.045321  -0.163811   0.142376  -0.125894  -0.083943   \n",
              "3  -0.000984   0.080593  -0.067086   0.005251  -0.141851  -0.125211   \n",
              "4   0.059806   0.088846  -0.058021   0.133098  -0.083380  -0.026724   \n",
              "\n",
              "   feature_7  feature_8  feature_9  feature_10  ...  feature_759  feature_760  \\\n",
              "0   0.028477  -0.006041  -0.132434    0.088144  ...    -0.160050     0.078897   \n",
              "1   0.023611   0.056512  -0.171498   -0.021133  ...    -0.137038     0.042576   \n",
              "2  -0.039693  -0.004867  -0.127951    0.111345  ...     0.090191     0.038063   \n",
              "3  -0.016161   0.106323  -0.203491   -0.027378  ...    -0.107041     0.028166   \n",
              "4  -0.033793  -0.004055  -0.057890   -0.011114  ...     0.047907     0.026333   \n",
              "\n",
              "   feature_761  feature_762  feature_763  feature_764  feature_765  \\\n",
              "0     0.120168    -0.160152    -0.200884     0.046231    -0.115850   \n",
              "1     0.006788    -0.207013    -0.205184    -0.053462    -0.003775   \n",
              "2     0.070423    -0.253409    -0.072147     0.016236    -0.144047   \n",
              "3    -0.073713    -0.073180    -0.109380    -0.027901    -0.006863   \n",
              "4     0.012204    -0.245772    -0.044506     0.058273    -0.005203   \n",
              "\n",
              "   feature_766  feature_767  feature_768  \n",
              "0     0.182974     0.047106    -0.118783  \n",
              "1    -0.035003    -0.041118    -0.079211  \n",
              "2    -0.122405    -0.063079    -0.188233  \n",
              "3     0.016840    -0.171139     0.086868  \n",
              "4    -0.104552     0.002035    -0.091528  \n",
              "\n",
              "[5 rows x 768 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# drop ID column from the test dataset\n",
        "x_test = test_df.drop('ID', axis=1)\n",
        "\n",
        "x_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4xf-J1lmPIRn"
      },
      "outputs": [],
      "source": [
        "# dict to store train and valid dataset for each label\n",
        "x_train = {}\n",
        "y_train = {}\n",
        "x_valid = {}\n",
        "y_valid = {}\n",
        "\n",
        "# seperate the train and valid datasets into labels\n",
        "# remove the rows where label is NaN\n",
        "\n",
        "for label in LABELS:\n",
        "\n",
        "    train_df_temp = train_df[~np.isnan(train_df[label])]\n",
        "    valid_df_temp = valid_df[~np.isnan(valid_df[label])]\n",
        "\n",
        "    x_train[label] = train_df_temp.drop(LABELS, axis=1)\n",
        "    y_train[label] = train_df_temp[label]\n",
        "    x_valid[label] = valid_df_temp.drop(LABELS, axis=1)\n",
        "    y_valid[label] = valid_df_temp[label]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "wLKxs_WvRljJ",
        "outputId": "e96748ee-8d75-4126-eb26-c784c7d1d231"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>feature_10</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_759</th>\n",
              "      <th>feature_760</th>\n",
              "      <th>feature_761</th>\n",
              "      <th>feature_762</th>\n",
              "      <th>feature_763</th>\n",
              "      <th>feature_764</th>\n",
              "      <th>feature_765</th>\n",
              "      <th>feature_766</th>\n",
              "      <th>feature_767</th>\n",
              "      <th>feature_768</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>480</th>\n",
              "      <td>0.053179</td>\n",
              "      <td>0.094833</td>\n",
              "      <td>-0.098983</td>\n",
              "      <td>0.131190</td>\n",
              "      <td>-0.031974</td>\n",
              "      <td>-0.049086</td>\n",
              "      <td>0.038929</td>\n",
              "      <td>0.091135</td>\n",
              "      <td>-0.107005</td>\n",
              "      <td>0.018532</td>\n",
              "      <td>...</td>\n",
              "      <td>0.073301</td>\n",
              "      <td>-0.008309</td>\n",
              "      <td>0.096050</td>\n",
              "      <td>-0.319057</td>\n",
              "      <td>-0.084282</td>\n",
              "      <td>0.057429</td>\n",
              "      <td>-0.064677</td>\n",
              "      <td>0.017584</td>\n",
              "      <td>-0.007926</td>\n",
              "      <td>-0.144536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>481</th>\n",
              "      <td>0.033278</td>\n",
              "      <td>0.059124</td>\n",
              "      <td>-0.020353</td>\n",
              "      <td>0.168918</td>\n",
              "      <td>0.036165</td>\n",
              "      <td>-0.117302</td>\n",
              "      <td>-0.081979</td>\n",
              "      <td>-0.070096</td>\n",
              "      <td>-0.161345</td>\n",
              "      <td>0.106618</td>\n",
              "      <td>...</td>\n",
              "      <td>0.066489</td>\n",
              "      <td>0.002962</td>\n",
              "      <td>0.003712</td>\n",
              "      <td>-0.235858</td>\n",
              "      <td>-0.051955</td>\n",
              "      <td>0.121809</td>\n",
              "      <td>0.007508</td>\n",
              "      <td>0.074416</td>\n",
              "      <td>0.000140</td>\n",
              "      <td>0.115385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>482</th>\n",
              "      <td>0.046853</td>\n",
              "      <td>0.076299</td>\n",
              "      <td>-0.012859</td>\n",
              "      <td>0.089680</td>\n",
              "      <td>0.046729</td>\n",
              "      <td>-0.000054</td>\n",
              "      <td>-0.045814</td>\n",
              "      <td>0.023595</td>\n",
              "      <td>-0.104441</td>\n",
              "      <td>0.025995</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.054697</td>\n",
              "      <td>0.027111</td>\n",
              "      <td>0.087195</td>\n",
              "      <td>-0.142816</td>\n",
              "      <td>-0.202896</td>\n",
              "      <td>0.099567</td>\n",
              "      <td>-0.069376</td>\n",
              "      <td>0.061420</td>\n",
              "      <td>0.003834</td>\n",
              "      <td>0.000445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>483</th>\n",
              "      <td>0.001946</td>\n",
              "      <td>0.060066</td>\n",
              "      <td>0.012458</td>\n",
              "      <td>0.001349</td>\n",
              "      <td>-0.057288</td>\n",
              "      <td>-0.219725</td>\n",
              "      <td>0.001473</td>\n",
              "      <td>0.036990</td>\n",
              "      <td>-0.210818</td>\n",
              "      <td>0.055353</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.095423</td>\n",
              "      <td>0.013749</td>\n",
              "      <td>-0.041319</td>\n",
              "      <td>-0.207143</td>\n",
              "      <td>-0.175213</td>\n",
              "      <td>-0.030503</td>\n",
              "      <td>-0.081459</td>\n",
              "      <td>0.106127</td>\n",
              "      <td>0.039627</td>\n",
              "      <td>0.025073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>484</th>\n",
              "      <td>0.046541</td>\n",
              "      <td>0.113568</td>\n",
              "      <td>-0.009204</td>\n",
              "      <td>0.058154</td>\n",
              "      <td>0.027733</td>\n",
              "      <td>-0.095826</td>\n",
              "      <td>0.072213</td>\n",
              "      <td>-0.013832</td>\n",
              "      <td>-0.007329</td>\n",
              "      <td>0.074815</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.065764</td>\n",
              "      <td>0.016530</td>\n",
              "      <td>0.109589</td>\n",
              "      <td>-0.095758</td>\n",
              "      <td>-0.142571</td>\n",
              "      <td>0.081530</td>\n",
              "      <td>-0.058456</td>\n",
              "      <td>-0.049127</td>\n",
              "      <td>-0.061282</td>\n",
              "      <td>0.041392</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 768 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
              "480   0.053179   0.094833  -0.098983   0.131190  -0.031974  -0.049086   \n",
              "481   0.033278   0.059124  -0.020353   0.168918   0.036165  -0.117302   \n",
              "482   0.046853   0.076299  -0.012859   0.089680   0.046729  -0.000054   \n",
              "483   0.001946   0.060066   0.012458   0.001349  -0.057288  -0.219725   \n",
              "484   0.046541   0.113568  -0.009204   0.058154   0.027733  -0.095826   \n",
              "\n",
              "     feature_7  feature_8  feature_9  feature_10  ...  feature_759  \\\n",
              "480   0.038929   0.091135  -0.107005    0.018532  ...     0.073301   \n",
              "481  -0.081979  -0.070096  -0.161345    0.106618  ...     0.066489   \n",
              "482  -0.045814   0.023595  -0.104441    0.025995  ...    -0.054697   \n",
              "483   0.001473   0.036990  -0.210818    0.055353  ...    -0.095423   \n",
              "484   0.072213  -0.013832  -0.007329    0.074815  ...    -0.065764   \n",
              "\n",
              "     feature_760  feature_761  feature_762  feature_763  feature_764  \\\n",
              "480    -0.008309     0.096050    -0.319057    -0.084282     0.057429   \n",
              "481     0.002962     0.003712    -0.235858    -0.051955     0.121809   \n",
              "482     0.027111     0.087195    -0.142816    -0.202896     0.099567   \n",
              "483     0.013749    -0.041319    -0.207143    -0.175213    -0.030503   \n",
              "484     0.016530     0.109589    -0.095758    -0.142571     0.081530   \n",
              "\n",
              "     feature_765  feature_766  feature_767  feature_768  \n",
              "480    -0.064677     0.017584    -0.007926    -0.144536  \n",
              "481     0.007508     0.074416     0.000140     0.115385  \n",
              "482    -0.069376     0.061420     0.003834     0.000445  \n",
              "483    -0.081459     0.106127     0.039627     0.025073  \n",
              "484    -0.058456    -0.049127    -0.061282     0.041392  \n",
              "\n",
              "[5 rows x 768 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train['label_2'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9F-q9lf2yGK"
      },
      "source": [
        "### Classifires"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nbaLk6MO1K8L"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def svm_classifier(x_train, y_train, x_valid, y_valid):\n",
        "  model = SVC(kernel='linear')\n",
        "  model.fit(x_train, y_train)\n",
        "  y_predict = model.predict(x_valid)\n",
        "  accuracy = accuracy_score(y_valid, y_predict)\n",
        "  return accuracy\n",
        "\n",
        "def weighted_svm_classifier(x_train, y_train, x_valid, y_valid):\n",
        "  model = SVC(kernel='linear', class_weight='balanced')\n",
        "  model.fit(x_train, y_train)\n",
        "  y_predict = model.predict(x_valid)\n",
        "  accuracy = accuracy_score(y_valid, y_predict)\n",
        "  return accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9IRNfkhz3VSf"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "def xgb_classifier(x_train, y_train, x_valid, y_valid):\n",
        "  model = xgb.XGBClassifier()\n",
        "  model.fit(x_train, y_train)\n",
        "  y_predict = model.predict(x_valid)\n",
        "  accuracy = accuracy_score(y_valid, y_predict)\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LBz5GoTyumk"
      },
      "source": [
        "### Grid Search / Random Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "agXQQLdLy0rv"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "def random_grid_search(model, param_dist, cv, n_iter, x_train, y_train):\n",
        "\n",
        "  random_search = RandomizedSearchCV(\n",
        "      estimator=model,\n",
        "      param_distributions=param_dist,\n",
        "      scoring='accuracy',\n",
        "      cv=cv,\n",
        "      verbose=1,\n",
        "      n_jobs=-1,\n",
        "      n_iter=n_iter\n",
        "  )\n",
        "\n",
        "  random_search.fit(x_train, y_train)\n",
        "\n",
        "  return random_search\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def grid_search(model, param_dist, cv, x_train, y_train):\n",
        "\n",
        "  grid_search = GridSearchCV(\n",
        "      estimator=model,\n",
        "      param_grid=param_dist,\n",
        "      scoring='accuracy',\n",
        "      cv=cv,\n",
        "      verbose=1,\n",
        "      n_jobs=-1\n",
        "  )\n",
        "\n",
        "  grid_search.fit(x_train, y_train)\n",
        "\n",
        "  return grid_search\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def k_fold_cross_validation(model, k, x_train, y_train):\n",
        "\n",
        "    scores = cross_val_score(model, x_train, y_train, cv=k)\n",
        "    mean_score = np.mean(scores)\n",
        "    std_deviation = np.std(scores)\n",
        "    print(\"Cross-Validation Scores:\", scores)\n",
        "    print(\"Mean Score:\", mean_score)\n",
        "    print(\"Standard Deviation:\", std_deviation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLmbK_vUP8EV"
      },
      "source": [
        "## Label 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "Yq9CpFLiSRjj",
        "outputId": "3dbb3d8a-ffe4-4aa1-874c-b9e698ac05ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot: xlabel='label_1', ylabel='count'>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABb4AAAINCAYAAADx4mktAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAABJIklEQVR4nO3deXyU9b0v8G9YEjYTRCERWdRqRaxLXaqxrXqQApaLWnlpF2qxem21YLX0WKR1q54WtYseLW69il1cWu+pe4siKp4qqCAoLkVUWqwQ8KoQASEIv/tHX+QQIMlkZkjw8f1+veYlmefJZ34z5ptn5pPJk5KUUgoAAAAAAMiIdm29AAAAAAAAKCbFNwAAAAAAmaL4BgAAAAAgUxTfAAAAAABkiuIbAAAAAIBMUXwDAAAAAJApim8AAAAAADJF8Q0AAAAAQKZ0aOsFbA82bNgQixcvjh122CFKSkraejkAAAAAAGxFSinef//96N27d7Rr1/j7uhXfEbF48eLo27dvWy8DAAAAAIAcvPnmm9GnT59Gtyu+I2KHHXaIiH89WOXl5W28GgAAAAAAtqa2tjb69u1b3+k2RvEdUX96k/LycsU3AAAAAMB2rrlTVvvjlgAAAAAAZEqbFt+XXHJJlJSUNLgMGDCgfvuaNWtizJgxsdNOO0W3bt1i5MiRsXTp0gYZixYtiuHDh0eXLl2iV69ecd5558WHH37Y2ncFAAAAAIDtRJuf6mTfffeNRx55pP7jDh3+Z0nf+9734sEHH4y77rorKioqYuzYsXHiiSfGk08+GRER69evj+HDh0dVVVU89dRTsWTJkvjGN74RHTt2jJ/+9Ketfl8AAAAAAGh7bV58d+jQIaqqqra4fsWKFXHzzTfH7bffHoMGDYqIiMmTJ8c+++wTM2fOjMMPPzwefvjhePnll+ORRx6JysrKOPDAA+Oyyy6L8ePHxyWXXBKlpaWtfXcAAAAAAGhjbX6O7wULFkTv3r1jjz32iFGjRsWiRYsiImL27Nmxbt26GDx4cP2+AwYMiH79+sWMGTMiImLGjBmx3377RWVlZf0+Q4cOjdra2njppZcavc21a9dGbW1tgwsAAAAAANnQpsX3YYcdFrfeemtMmTIlrr/++li4cGF8/vOfj/fffz9qamqitLQ0unfv3uBzKisro6amJiIiampqGpTeG7dv3NaYiRMnRkVFRf2lb9++xb1jAAAAAAC0mTY91cmxxx5b/+/9998/DjvssOjfv3/88Y9/jM6dO2+z250wYUKMGzeu/uPa2lrlNwAAAABARrT5qU421b179/jkJz8Zr732WlRVVUVdXV0sX768wT5Lly6tPyd4VVVVLF26dIvtG7c1pqysLMrLyxtcAAAAAADIhu2q+F65cmW8/vrrscsuu8TBBx8cHTt2jGnTptVvnz9/fixatCiqq6sjIqK6ujrmzZsXy5Ytq99n6tSpUV5eHgMHDmz19QMAAAAA0Pba9FQn//7v/x4jRoyI/v37x+LFi+Piiy+O9u3bx1e/+tWoqKiI008/PcaNGxc9evSI8vLyOPvss6O6ujoOP/zwiIgYMmRIDBw4ME455ZS48soro6amJi644IIYM2ZMlJWVteVdAwAAAACgjbRp8f3Pf/4zvvrVr8Y777wTPXv2jM997nMxc+bM6NmzZ0REXHXVVdGuXbsYOXJkrF27NoYOHRrXXXdd/ee3b98+HnjggTjrrLOiuro6unbtGqNHj45LL720re4SAAAAAABtrCSllNp6EW2ttrY2KioqYsWKFc73DQAAAACwncq1y92uzvENAAAAAACFUnwDAAAAAJApim8AAAAAADJF8Q0AAAAAQKYovgEAAAAAyBTFNwAAAAAAmaL4BgAAAAAgUzq09QIAthe77/73ouQsXLhbUXIAgI+uYj2viPDcAgAgH4pvAAC2oLQDAAA+yhTfAADbkN8mAQAAPs7a6jWR4hsoKu8QBGg9vucCANAWPA/Nlqz+/1R8w8dQVr+hAQDAR5Hn563PYw6QfYrvVuTA2vo85gAAwMeZ10TZ4v8nFM6pCD8+FN8Z4eAHH1/mH4As25bHOcdQANqaEha2HcX3Zjz5BbYF31vYXnhivSXzCQD5cQwFYHum+AYAtnteWPNx8FH+OvdDNXL1Uf46BwrzUZ3/j+q6Iz7aa4diUHwDAAAAANsFhT3FovgmJ97Fs6Vt/Y3YYw6F8WSp9XnM2V44hsLHk+fnUDhf50CWKL4BaJQiEwAAANqe1+ctp/imzRlcAPh4cewHAAC2NcU3AABknB82AADwcaP4Bj4yvGjn48DXOWzfzCgAzXGsANg+KL4BaDP+eA4A5McxFACgaYpvAAAA6nm3KtsLP+AhV75vAVuj+AYAAAAAKJAfwmxfFN8A0EKezAAAAMD2rV1bLwAAAAAAAIpJ8Q0AAAAAQKYovgEAAAAAyBTFNwAAAAAAmaL4BgAAAAAgUxTfAAAAAABkiuIbAAAAAIBMUXwDAAAAAJApim8AAAAAADJF8Q0AAAAAQKYovgEAAAAAyBTFNwAAAAAAmaL4BgAAAAAgUxTfAAAAAABkiuIbAAAAAIBMUXwDAAAAAJApim8AAAAAADJF8Q0AAAAAQKYovgEAAAAAyBTFNwAAAAAAmaL4BgAAAAAgUxTfAAAAAABkiuIbAAAAAIBMUXwDAAAAAJApim8AAAAAADJF8Q0AAAAAQKYovgEAAAAAyBTFNwAAAAAAmaL4BgAAAAAgUxTfAAAAAABkiuIbAAAAAIBMUXwDAAAAAJApim8AAAAAADJF8Q0AAAAAQKYovgEAAAAAyBTFNwAAAAAAmaL4BgAAAAAgUxTfAAAAAABkiuIbAAAAAIBMUXwDAAAAAJApim8AAAAAADJF8Q0AAAAAQKYovgEAAAAAyBTFNwAAAAAAmaL4BgAAAAAgUxTfAAAAAABkiuIbAAAAAIBMUXwDAAAAAJApim8AAAAAADJF8Q0AAAAAQKYovgEAAAAAyBTFNwAAAAAAmaL4BgAAAAAgUxTfAAAAAABkynZTfF9++eVRUlIS5557bv11a9asiTFjxsROO+0U3bp1i5EjR8bSpUsbfN6iRYti+PDh0aVLl+jVq1ecd9558eGHH7by6gEAAAAA2F5sF8X3s88+GzfeeGPsv//+Da7/3ve+F/fff3/cddddMX369Fi8eHGceOKJ9dvXr18fw4cPj7q6unjqqafiN7/5Tdx6661x0UUXtfZdAAAAAABgO9HmxffKlStj1KhR8etf/zp23HHH+utXrFgRN998c/zyl7+MQYMGxcEHHxyTJ0+Op556KmbOnBkREQ8//HC8/PLL8fvf/z4OPPDAOPbYY+Oyyy6LSZMmRV1dXVvdJQAAAAAA2lCbF99jxoyJ4cOHx+DBgxtcP3v27Fi3bl2D6wcMGBD9+vWLGTNmRETEjBkzYr/99ovKysr6fYYOHRq1tbXx0ksvNXqba9eujdra2gYXAAAAAACyoUNb3vidd94Zzz33XDz77LNbbKupqYnS0tLo3r17g+srKyujpqamfp9NS++N2zdua8zEiRPjxz/+cYGrBwAAAABge9Rm7/h+880345xzzonbbrstOnXq1Kq3PWHChFixYkX95c0332zV2wcAAAAAYNtps+J79uzZsWzZsjjooIOiQ4cO0aFDh5g+fXpcc8010aFDh6isrIy6urpYvnx5g89bunRpVFVVRUREVVVVLF26dIvtG7c1pqysLMrLyxtcAAAAAADIhjYrvo855piYN29ezJ07t/5yyCGHxKhRo+r/3bFjx5g2bVr958yfPz8WLVoU1dXVERFRXV0d8+bNi2XLltXvM3Xq1CgvL4+BAwe2+n0CAAAAAKDttdk5vnfYYYf41Kc+1eC6rl27xk477VR//emnnx7jxo2LHj16RHl5eZx99tlRXV0dhx9+eEREDBkyJAYOHBinnHJKXHnllVFTUxMXXHBBjBkzJsrKylr9PgEAAAAA0Pba9I9bNueqq66Kdu3axciRI2Pt2rUxdOjQuO666+q3t2/fPh544IE466yzorq6Orp27RqjR4+OSy+9tA1XDQAAAABAW9quiu/HH3+8wcedOnWKSZMmxaRJkxr9nP79+8ef//znbbwyAAAAAAA+KtrsHN8AAAAAALAtKL4BAAAAAMgUxTcAAAAAAJmi+AYAAAAAIFMU3wAAAAAAZIriGwAAAACATFF8AwAAAACQKYpvAAAAAAAyRfENAAAAAECmKL4BAAAAAMgUxTcAAAAAAJmi+AYAAAAAIFMU3wAAAAAAZIriGwAAAACATFF8AwAAAACQKYpvAAAAAAAyRfENAAAAAECmKL4BAAAAAMgUxTcAAAAAAJmi+AYAAAAAIFMU3wAAAAAAZIriGwAAAACATFF8AwAAAACQKYpvAAAAAAAyRfENAAAAAECmKL4BAAAAAMgUxTcAAAAAAJmi+AYAAAAAIFMU3wAAAAAAZIriGwAAAACATFF8AwAAAACQKYpvAAAAAAAyRfENAAAAAECmKL4BAAAAAMgUxTcAAAAAAJmi+AYAAAAAIFMU3wAAAAAAZIriGwAAAACATFF8AwAAAACQKYpvAAAAAAAyRfENAAAAAECmKL4BAAAAAMgUxTcAAAAAAJmi+AYAAAAAIFMU3wAAAAAAZIriGwAAAACATFF8AwAAAACQKYpvAAAAAAAyRfENAAAAAECmKL4BAAAAAMgUxTcAAAAAAJmi+AYAAAAAIFMU3wAAAAAAZIriGwAAAACATFF8AwAAAACQKYpvAAAAAAAyRfENAAAAAECmKL4BAAAAAMgUxTcAAAAAAJmi+AYAAAAAIFMU3wAAAAAAZIriGwAAAACATFF8AwAAAACQKYpvAAAAAAAyRfENAAAAAECmKL4BAAAAAMgUxTcAAAAAAJmi+AYAAAAAIFMU3wAAAAAAZIriGwAAAACATFF8AwAAAACQKYpvAAAAAAAyRfENAAAAAECmKL4BAAAAAMgUxTcAAAAAAJmi+AYAAAAAIFMU3wAAAAAAZIriGwAAAACATFF8AwAAAACQKW1afF9//fWx//77R3l5eZSXl0d1dXX85S9/qd++Zs2aGDNmTOy0007RrVu3GDlyZCxdurRBxqJFi2L48OHRpUuX6NWrV5x33nnx4YcftvZdAQAAAABgO9GmxXefPn3i8ssvj9mzZ8esWbNi0KBBcfzxx8dLL70UERHf+9734v7774+77rorpk+fHosXL44TTzyx/vPXr18fw4cPj7q6unjqqafiN7/5Tdx6661x0UUXtdVdAgAAAACgjXVoyxsfMWJEg49/8pOfxPXXXx8zZ86MPn36xM033xy33357DBo0KCIiJk+eHPvss0/MnDkzDj/88Hj44Yfj5ZdfjkceeSQqKyvjwAMPjMsuuyzGjx8fl1xySZSWlrbF3QIAAAAAoA1tN+f4Xr9+fdx5552xatWqqK6ujtmzZ8e6deti8ODB9fsMGDAg+vXrFzNmzIiIiBkzZsR+++0XlZWV9fsMHTo0amtr6981vjVr166N2traBhcAAAAAALKhzYvvefPmRbdu3aKsrCzOPPPMuPvuu2PgwIFRU1MTpaWl0b179wb7V1ZWRk1NTURE1NTUNCi9N27fuK0xEydOjIqKivpL3759i3unAAAAAABoM21efO+9994xd+7cePrpp+Oss86K0aNHx8svv7xNb3PChAmxYsWK+subb765TW8PAAAAAIDW06bn+I6IKC0tjT333DMiIg4++OB49tln4z//8z/jy1/+ctTV1cXy5csbvOt76dKlUVVVFRERVVVV8cwzzzTIW7p0af22xpSVlUVZWVmR7wkAAAAAANuDNn/H9+Y2bNgQa9eujYMPPjg6duwY06ZNq982f/78WLRoUVRXV0dERHV1dcybNy+WLVtWv8/UqVOjvLw8Bg4c2OprBwAAAACg7bXpO74nTJgQxx57bPTr1y/ef//9uP322+Pxxx+Phx56KCoqKuL000+PcePGRY8ePaK8vDzOPvvsqK6ujsMPPzwiIoYMGRIDBw6MU045Ja688sqoqamJCy64IMaMGeMd3QAAAAAAH1NtWnwvW7YsvvGNb8SSJUuioqIi9t9//3jooYfiC1/4QkREXHXVVdGuXbsYOXJkrF27NoYOHRrXXXdd/ee3b98+HnjggTjrrLOiuro6unbtGqNHj45LL720re4SAAAAAABtrE2L75tvvrnJ7Z06dYpJkybFpEmTGt2nf//+8ec//7nYSwMAAAAA4CNquzvHNwAAAAAAFELxDQAAAABApii+AQAAAADIFMU3AAAAAACZovgGAAAAACBTFN8AAAAAAGSK4hsAAAAAgExRfAMAAAAAkCmKbwAAAAAAMkXxDQAAAABApii+AQAAAADIFMU3AAAAAACZovgGAAAAACBTFN8AAAAAAGSK4hsAAAAAgExRfAMAAAAAkCmKbwAAAAAAMkXxDQAAAABApuRVfA8aNCiWL1++xfW1tbUxaNCgQtcEAAAAAAB5y6v4fvzxx6Ourm6L69esWRP//d//XfCiAAAAAAAgXx1asvMLL7xQ/++XX345ampq6j9ev359TJkyJXbdddfirQ4AAAAAAFqoRcX3gQceGCUlJVFSUrLVU5p07tw5rr322qItDgAAAAAAWqpFxffChQsjpRR77LFHPPPMM9GzZ8/6baWlpdGrV69o37590RcJAAAAAAC5alHx3b9//4iI2LBhwzZZDAAAAAAAFKpFxfemFixYEI899lgsW7ZsiyL8oosuKnhhAAAAAACQj7yK71//+tdx1llnxc477xxVVVVRUlJSv62kpETxDQAAAABAm8mr+P6P//iP+MlPfhLjx48v9noAAAAAAKAg7fL5pPfeey9OOumkYq8FAAAAAAAKllfxfdJJJ8XDDz9c7LUAAAAAAEDB8jrVyZ577hkXXnhhzJw5M/bbb7/o2LFjg+3f/e53i7I4AAAAAABoqbyK75tuuim6desW06dPj+nTpzfYVlJSovgGAAAAAKDN5FV8L1y4sNjrAAAAAACAosjrHN8AAAAAALC9yusd36eddlqT22+55Za8FgMAAAAAAIXKq/h+7733Gny8bt26ePHFF2P58uUxaNCgoiwMAAAAAADykVfxfffdd29x3YYNG+Kss86KT3ziEwUvCgAAAAAA8lW0c3y3a9cuxo0bF1dddVWxIgEAAAAAoMWK+sctX3/99fjwww+LGQkAAAAAAC2S16lOxo0b1+DjlFIsWbIkHnzwwRg9enRRFgYAAAAAAPnIq/ieM2dOg4/btWsXPXv2jF/84hdx2mmnFWVhAAAAAACQj7yK78cee6zY6wAAAAAAgKLIq/je6O2334758+dHRMTee+8dPXv2LMqiAAAAAAAgX3n9cctVq1bFaaedFrvssksceeSRceSRR0bv3r3j9NNPj9WrVxd7jQAAAAAAkLO8iu9x48bF9OnT4/7774/ly5fH8uXL4957743p06fH97///WKvEQAAAAAAcpbXqU7+67/+K/7v//2/cfTRR9df98UvfjE6d+4cJ598clx//fXFWh8AAAAAALRIXu/4Xr16dVRWVm5xfa9evZzqBAAAAACANpVX8V1dXR0XX3xxrFmzpv66Dz74IH784x9HdXV10RYHAAAAAAAtldepTq6++uoYNmxY9OnTJw444ICIiHj++eejrKwsHn744aIuEAAAAAAAWiKv4nu//faLBQsWxG233RZ/+9vfIiLiq1/9aowaNSo6d+5c1AUCAAAAAEBL5FV8T5w4MSorK+OMM85ocP0tt9wSb7/9dowfP74oiwMAAAAAgJbK6xzfN954YwwYMGCL6/fdd9+44YYbCl4UAAAAAADkK6/iu6amJnbZZZctru/Zs2csWbKk4EUBAAAAAEC+8iq++/btG08++eQW1z/55JPRu3fvghcFAAAAAAD5yusc32eccUace+65sW7duhg0aFBEREybNi1+8IMfxPe///2iLhAAAAAAAFoir+L7vPPOi3feeSe+853vRF1dXUREdOrUKcaPHx8TJkwo6gIBAAAAAKAl8iq+S0pK4oorrogLL7wwXnnllejcuXPstddeUVZWVuz1AQAAAABAi+RVfG/UrVu3OPTQQ4u1FgAAAAAAKFhef9wSAAAAAAC2V4pvAAAAAAAyRfENAAAAAECmKL4BAAAAAMgUxTcAAAAAAJmi+AYAAAAAIFMU3wAAAAAAZIriGwAAAACATFF8AwAAAACQKYpvAAAAAAAyRfENAAAAAECmKL4BAAAAAMgUxTcAAAAAAJmi+AYAAAAAIFMU3wAAAAAAZIriGwAAAACATFF8AwAAAACQKYpvAAAAAAAyRfENAAAAAECmKL4BAAAAAMgUxTcAAAAAAJmi+AYAAAAAIFMU3wAAAAAAZEqbFt8TJ06MQw89NHbYYYfo1atXnHDCCTF//vwG+6xZsybGjBkTO+20U3Tr1i1GjhwZS5cubbDPokWLYvjw4dGlS5fo1atXnHfeefHhhx+25l0BAAAAAGA70abF9/Tp02PMmDExc+bMmDp1aqxbty6GDBkSq1atqt/ne9/7Xtx///1x1113xfTp02Px4sVx4okn1m9fv359DB8+POrq6uKpp56K3/zmN3HrrbfGRRdd1BZ3CQAAAACANtahLW98ypQpDT6+9dZbo1evXjF79uw48sgjY8WKFXHzzTfH7bffHoMGDYqIiMmTJ8c+++wTM2fOjMMPPzwefvjhePnll+ORRx6JysrKOPDAA+Oyyy6L8ePHxyWXXBKlpaVtcdcAAAAAAGgj29U5vlesWBERET169IiIiNmzZ8e6deti8ODB9fsMGDAg+vXrFzNmzIiIiBkzZsR+++0XlZWV9fsMHTo0amtr46WXXtrq7axduzZqa2sbXAAAAAAAyIbtpvjesGFDnHvuufHZz342PvWpT0VERE1NTZSWlkb37t0b7FtZWRk1NTX1+2xaem/cvnHb1kycODEqKirqL3379i3yvQEAAAAAoK1sN8X3mDFj4sUXX4w777xzm9/WhAkTYsWKFfWXN998c5vfJgAAAAAAraNNz/G90dixY+OBBx6IJ554Ivr06VN/fVVVVdTV1cXy5csbvOt76dKlUVVVVb/PM8880yBv6dKl9du2pqysLMrKyop8LwAAAAAA2B606Tu+U0oxduzYuPvuu+PRRx+N3XffvcH2gw8+ODp27BjTpk2rv27+/PmxaNGiqK6ujoiI6urqmDdvXixbtqx+n6lTp0Z5eXkMHDiwde4IAAAAAADbjTZ9x/eYMWPi9ttvj3vvvTd22GGH+nNyV1RUROfOnaOioiJOP/30GDduXPTo0SPKy8vj7LPPjurq6jj88MMjImLIkCExcODAOOWUU+LKK6+MmpqauOCCC2LMmDHe1Q0AAAAA8DHUpsX39ddfHxERRx99dIPrJ0+eHKeeempERFx11VXRrl27GDlyZKxduzaGDh0a1113Xf2+7du3jwceeCDOOuusqK6ujq5du8bo0aPj0ksvba27AQAAAADAdqRNi++UUrP7dOrUKSZNmhSTJk1qdJ/+/fvHn//852IuDQAAAACAj6g2Pcc3AAAAAAAUm+IbAAAAAIBMUXwDAAAAAJApim8AAAAAADJF8Q0AAAAAQKYovgEAAAAAyBTFNwAAAAAAmaL4BgAAAAAgUxTfAAAAAABkiuIbAAAAAIBMUXwDAAAAAJApim8AAAAAADJF8Q0AAAAAQKYovgEAAAAAyBTFNwAAAAAAmaL4BgAAAAAgUxTfAAAAAABkiuIbAAAAAIBMUXwDAAAAAJApim8AAAAAADJF8Q0AAAAAQKYovgEAAAAAyBTFNwAAAAAAmaL4BgAAAAAgUxTfAAAAAABkiuIbAAAAAIBMUXwDAAAAAJApim8AAAAAADJF8Q0AAAAAQKYovgEAAAAAyBTFNwAAAAAAmaL4BgAAAAAgUxTfAAAAAABkiuIbAAAAAIBMUXwDAAAAAJApim8AAAAAADJF8Q0AAAAAQKYovgEAAAAAyBTFNwAAAAAAmaL4BgAAAAAgUxTfAAAAAABkiuIbAAAAAIBMUXwDAAAAAJApim8AAAAAADJF8Q0AAAAAQKYovgEAAAAAyBTFNwAAAAAAmaL4BgAAAAAgUxTfAAAAAABkiuIbAAAAAIBMUXwDAAAAAJApim8AAAAAADJF8Q0AAAAAQKYovgEAAAAAyBTFNwAAAAAAmaL4BgAAAAAgUxTfAAAAAABkiuIbAAAAAIBMUXwDAAAAAJApim8AAAAAADJF8Q0AAAAAQKYovgEAAAAAyBTFNwAAAAAAmaL4BgAAAAAgUxTfAAAAAABkiuIbAAAAAIBMUXwDAAAAAJApim8AAAAAADJF8Q0AAAAAQKYovgEAAAAAyBTFNwAAAAAAmaL4BgAAAAAgUxTfAAAAAABkiuIbAAAAAIBMUXwDAAAAAJApim8AAAAAADJF8Q0AAAAAQKYovgEAAAAAyBTFNwAAAAAAmaL4BgAAAAAgU9q0+H7iiSdixIgR0bt37ygpKYl77rmnwfaUUlx00UWxyy67ROfOnWPw4MGxYMGCBvu8++67MWrUqCgvL4/u3bvH6aefHitXrmzFewEAAAAAwPakTYvvVatWxQEHHBCTJk3a6vYrr7wyrrnmmrjhhhvi6aefjq5du8bQoUNjzZo19fuMGjUqXnrppZg6dWo88MAD8cQTT8S3vvWt1roLAAAAAABsZzq05Y0fe+yxceyxx251W0oprr766rjgggvi+OOPj4iI3/72t1FZWRn33HNPfOUrX4lXXnklpkyZEs8++2wccsghERFx7bXXxhe/+MX4+c9/Hr179261+wIAAAAAwPZhuz3H98KFC6OmpiYGDx5cf11FRUUcdthhMWPGjIiImDFjRnTv3r2+9I6IGDx4cLRr1y6efvrpRrPXrl0btbW1DS4AAAAAAGTDdlt819TUREREZWVlg+srKyvrt9XU1ESvXr0abO/QoUP06NGjfp+tmThxYlRUVNRf+vbtW+TVAwAAAADQVrbb4ntbmjBhQqxYsaL+8uabb7b1kgAAAAAAKJLttviuqqqKiIilS5c2uH7p0qX126qqqmLZsmUNtn/44Yfx7rvv1u+zNWVlZVFeXt7gAgAAAABANmy3xffuu+8eVVVVMW3atPrramtr4+mnn47q6uqIiKiuro7ly5fH7Nmz6/d59NFHY8OGDXHYYYe1+poBAAAAAGh7HdryxleuXBmvvfZa/ccLFy6MuXPnRo8ePaJfv35x7rnnxn/8x3/EXnvtFbvvvntceOGF0bt37zjhhBMiImKfffaJYcOGxRlnnBE33HBDrFu3LsaOHRtf+cpXonfv3m10rwAAAAAAaEttWnzPmjUr/u3f/q3+43HjxkVExOjRo+PWW2+NH/zgB7Fq1ar41re+FcuXL4/Pfe5zMWXKlOjUqVP959x2220xduzYOOaYY6Jdu3YxcuTIuOaaa1r9vgAAAAAAsH1o0+L76KOPjpRSo9tLSkri0ksvjUsvvbTRfXr06BG33377tlgeAAAAAAAfQdvtOb4BAAAAACAfim8AAAAAADJF8Q0AAAAAQKYovgEAAAAAyBTFNwAAAAAAmaL4BgAAAAAgUxTfAAAAAABkiuIbAAAAAIBMUXwDAAAAAJApim8AAAAAADJF8Q0AAAAAQKYovgEAAAAAyBTFNwAAAAAAmaL4BgAAAAAgUxTfAAAAAABkiuIbAAAAAIBMUXwDAAAAAJApim8AAAAAADJF8Q0AAAAAQKYovgEAAAAAyBTFNwAAAAAAmaL4BgAAAAAgUxTfAAAAAABkiuIbAAAAAIBMUXwDAAAAAJApim8AAAAAADJF8Q0AAAAAQKYovgEAAAAAyBTFNwAAAAAAmaL4BgAAAAAgUxTfAAAAAABkiuIbAAAAAIBMUXwDAAAAAJApim8AAAAAADJF8Q0AAAAAQKYovgEAAAAAyBTFNwAAAAAAmaL4BgAAAAAgUxTfAAAAAABkiuIbAAAAAIBMUXwDAAAAAJApim8AAAAAADJF8Q0AAAAAQKYovgEAAAAAyBTFNwAAAAAAmaL4BgAAAAAgUxTfAAAAAABkiuIbAAAAAIBMUXwDAAAAAJApim8AAAAAADJF8Q0AAAAAQKYovgEAAAAAyBTFNwAAAAAAmaL4BgAAAAAgUxTfAAAAAABkiuIbAAAAAIBMUXwDAAAAAJApim8AAAAAADJF8Q0AAAAAQKYovgEAAAAAyBTFNwAAAAAAmaL4BgAAAAAgUxTfAAAAAABkiuIbAAAAAIBMUXwDAAAAAJApim8AAAAAADJF8Q0AAAAAQKYovgEAAAAAyBTFNwAAAAAAmaL4BgAAAAAgUxTfAAAAAABkiuIbAAAAAIBMUXwDAAAAAJApim8AAAAAADJF8Q0AAAAAQKYovgEAAAAAyBTFNwAAAAAAmaL4BgAAAAAgUxTfAAAAAABkiuIbAAAAAIBMyUzxPWnSpNhtt92iU6dOcdhhh8UzzzzT1ksCAAAAAKANZKL4/sMf/hDjxo2Liy++OJ577rk44IADYujQobFs2bK2XhoAAAAAAK0sE8X3L3/5yzjjjDPim9/8ZgwcODBuuOGG6NKlS9xyyy1tvTQAAAAAAFpZh7ZeQKHq6upi9uzZMWHChPrr2rVrF4MHD44ZM2Zs9XPWrl0ba9eurf94xYoVERFRW1sbGza8X7S11dbWNvj4o5pdzPxtmb21/I9qdjHzPea5ZRcz32OeW3Yx8z3muWUXM99jnlt2MfM95rllFzPfY55bdjHzPea5ZRcz32OeW3Yx8z3muWUXM99jnlt2MfM95rllFzPfY55bdjHzPea5ZRczf2P2xv+mlJrcvyQ1t8d2bvHixbHrrrvGU089FdXV1fXX/+AHP4jp06fH008/vcXnXHLJJfHjH/+4NZcJAAAAAECRvPnmm9GnT59Gt3/k3/GdjwkTJsS4cePqP96wYUO8++67sdNOO0VJSUmTn1tbWxt9+/aNN998M8rLy4u+tm2ZL7v182W3fr7s1s+X3fr5sls/X3br58tu/XzZrZ8vu/XzZbd+vuzWz5fd+vmyWz9fduvnb0/ZKaV4//33o3fv3k3u95Evvnfeeedo3759LF26tMH1S5cujaqqqq1+TllZWZSVlTW4rnv37i263fLy8m3yBdoa+bJbP1926+fLbv182a2fL7v182W3fr7s1s+X3fr5sls/X3br58tu/XzZrZ8vu/XzZbd+/vaSXVFR0ew+H/k/bllaWhoHH3xwTJs2rf66DRs2xLRp0xqc+gQAAAAAgI+Hj/w7viMixo0bF6NHj45DDjkkPvOZz8TVV18dq1atim9+85ttvTQAAAAAAFpZJorvL3/5y/H222/HRRddFDU1NXHggQfGlClTorKysui3VVZWFhdffPEWp0r5KOTLbv182a2fL7v182W3fr7s1s+X3fr5sls/X3br58tu/XzZrZ8vu/XzZbd+vuzWz5fd+vkfxeySlFIqaiIAAAAAALShj/w5vgEAAAAAYFOKbwAAAAAAMkXxDQAAAABApii+AQAAAADIFMV3jp544okYMWJE9O7dO0pKSuKee+4pWvbEiRPj0EMPjR122CF69eoVJ5xwQsyfP78o2ddff33sv//+UV5eHuXl5VFdXR1/+ctfipK9ucsvvzxKSkri3HPPLUreJZdcEiUlJQ0uAwYMKEp2RMRbb70VX//612OnnXaKzp07x3777RezZs0qSvZuu+22xdpLSkpizJgxBWevX78+Lrzwwth9992jc+fO8YlPfCIuu+yyKNbfqX3//ffj3HPPjf79+0fnzp3jiCOOiGeffbbFOc3NTEopLrroothll12ic+fOMXjw4FiwYEFRsv/0pz/FkCFDYqeddoqSkpKYO3du0da+bt26GD9+fOy3337RtWvX6N27d3zjG9+IxYsXF2Xtl1xySQwYMCC6du0aO+64YwwePDiefvrpomRv6swzz4ySkpK4+uqrc8rOJf/UU0/d4mt+2LBhRVv7K6+8Escdd1xUVFRE165d49BDD41FixYVnL21WS0pKYmf/exnBWevXLkyxo4dG3369InOnTvHwIED44Ybbmg2N5fspUuXxqmnnhq9e/eOLl26xLBhw3KeoVyOO2vWrIkxY8bETjvtFN26dYuRI0fG0qVLi5J90003xdFHHx3l5eVRUlISy5cvz2ndueS/++67cfbZZ8fee+8dnTt3jn79+sV3v/vdWLFiRVHW/u1vfzs+8YlPROfOnaNnz55x/PHHx9/+9reiZG+UUopjjz22Rc83csk/+uijt/g6P/PMM4u29hkzZsSgQYOia9euUV5eHkceeWR88MEHBWX//e9/b3RG77rrroLXXVNTE6ecckpUVVVF165d46CDDor/+q//Kspj8vrrr8eXvvSl6NmzZ5SXl8fJJ5+c0wxFNP/8Ld/5zCW7kPlsKruQ2cx17fnOZy7ZG+Uzn81l5zubua47n9nMJb+Q+cxl7fnOZy7Zhczn5rb2GqiQGW0uu5AZbSq7GDPa3NoLmdHmsjfKZ0abyy5kRnNZdyEz2lR+oTPa3NoLmdHmsguZ0eZ6hELms7nsQuazqexizGdzay9kPnPtbvKZz+ayC5nPXNZdyHw2lV/ofDa39kLms7nsQo+hzXVxhXRFW6P4ztGqVavigAMOiEmTJhU9e/r06TFmzJiYOXNmTJ06NdatWxdDhgyJVatWFZzdp0+fuPzyy2P27Nkxa9asGDRoUBx//PHx0ksvFWHl/+PZZ5+NG2+8Mfbff/+i5u67776xZMmS+stf//rXouS+99578dnPfjY6duwYf/nLX+Lll1+OX/ziF7HjjjsWJf/ZZ59tsO6pU6dGRMRJJ51UcPYVV1wR119/ffzqV7+KV155Ja644oq48sor49prry04OyLif//v/x1Tp06N3/3udzFv3rwYMmRIDB48ON56660W5TQ3M1deeWVcc801ccMNN8TTTz8dXbt2jaFDh8aaNWsKzl61alV87nOfiyuuuKJFa84lf/Xq1fHcc8/FhRdeGM8991z86U9/ivnz58dxxx1XcHZExCc/+cn41a9+FfPmzYu//vWvsdtuu8WQIUPi7bffLjh7o7vvvjtmzpwZvXv3zmnNLckfNmxYg6/9O+64oyjZr7/+enzuc5+LAQMGxOOPPx4vvPBCXHjhhdGpU6eCszdd75IlS+KWW26JkpKSGDlyZMHZ48aNiylTpsTvf//7eOWVV+Lcc8+NsWPHxn333VdQdkopTjjhhHjjjTfi3nvvjTlz5kT//v1j8ODBOR07cjnufO9734v7778/7rrrrpg+fXosXrw4TjzxxKJkr169OoYNGxY//OEPm81raf7ixYtj8eLF8fOf/zxefPHFuPXWW2PKlClx+umnF2XtBx98cEyePDleeeWVeOihhyKlFEOGDIn169cXnL3R1VdfHSUlJUV9XDY644wzGny9X3nllUXJnjFjRgwbNiyGDBkSzzzzTDz77LMxduzYaNeu6aeazWX37dt3ixn98Y9/HN26dYtjjz224HV/4xvfiPnz58d9990X8+bNixNPPDFOPvnkmDNnTkHZq1atiiFDhkRJSUk8+uij8eSTT0ZdXV2MGDEiNmzY0GR2RPPP3/Kdz1yyC5nPprILmc1c157vfOaSvVE+85lLdj6zmUt2vrOZS34h85nL2vOdz+ayC53PTTX2GqiQGW0uu5AZbSq7GDPa3NoLmdHmsjfKZ0Zzyc53RpvLLnRGm8ovdEabW3shM9pUdjFmtKkeodD5bCq70PlsLLtY89nU2gudz1y6m3zns7nsQuazqexizGdj+cWYz6bWXuh8NpZd6Hzm0sUV0hVtVaLFIiLdfffd2yx/2bJlKSLS9OnTt0n+jjvumP7P//k/Rct7//3301577ZWmTp2ajjrqqHTOOecUJffiiy9OBxxwQFGyNjd+/Pj0uc99bptkb80555yTPvGJT6QNGzYUnDV8+PB02mmnNbjuxBNPTKNGjSo4e/Xq1al9+/bpgQceaHD9QQcdlH70ox/lnbv5zGzYsCFVVVWln/3sZ/XXLV++PJWVlaU77rijoOxNLVy4MEVEmjNnTh6rbj5/o2eeeSZFRPrHP/5R9OwVK1akiEiPPPJIUbL/+c9/pl133TW9+OKLqX///umqq65qUW5T+aNHj07HH398XnnNZX/5y19OX//617dJ9uaOP/74NGjQoKJk77vvvunSSy9tcF0+87R59vz581NEpBdffLH+uvXr16eePXumX//61y1e++bHneXLl6eOHTumu+66q36fV155JUVEmjFjRkHZm3rsscdSRKT33nuvxWvOJX+jP/7xj6m0tDStW7eu6NnPP/98ioj02muvFSV7zpw5adddd01Lliwp6PnG1vKLdYzeWvZhhx2WLrjggm2SvbkDDzxwi+Ngvtldu3ZNv/3tbxvs16NHjxbP0ebZDz30UGrXrl1asWJF/T7Lly9PJSUlaerUqS1ee0r/8/ytmPO5efamijGfjWVvlO9s5pqf73w2ll2s+dw8u5jPnzfPLtZsNpa/uXznc2vZxZrPzbOLNZ+NvQYqxozm8voq3xltyWu3fGa0JfktndHmsguZ0aayC53RprKLMaMtecxbOqNNZRc6o41lFzqjTfUIhc5nrh1FPvPZ0v6jpfPZ0vyWzGcu2fnOZ3PZhcxnc9mFzmdLH/OWzGdz2YXMZ1PZhc5nc11cMbuijbzjezu08ddVevToUdTc9evXx5133hmrVq2K6urqouWOGTMmhg8fHoMHDy5a5kYLFiyI3r17xx577BGjRo3K6bQGubjvvvvikEMOiZNOOil69eoVn/70p+PXv/51UbI3V1dXF7///e/jtNNOy/vdB5s64ogjYtq0afHqq69GRMTzzz8ff/3rX1v0U/vGfPjhh7F+/fot3kXbuXPnor3bPiJi4cKFUVNT0+BrpqKiIg477LCYMWNG0W6ntaxYsSJKSkqie/fuRc2tq6uLm266KSoqKuKAAw4oOG/Dhg1xyimnxHnnnRf77rtvEVa4pccffzx69eoVe++9d5x11lnxzjvvFJy5YcOGePDBB+OTn/xkDB06NHr16hWHHXZYUU85tdHSpUvjwQcfzOvdTVtzxBFHxH333RdvvfVWpJTisccei1dffTWGDBlSUO7atWsjIhrMart27aKsrCyvWd38uDN79uxYt25dgxkdMGBA9OvXr8Uzuq2OaS3JX7FiRZSXl0eHDh2Kmr1q1aqYPHly7L777tG3b9+Cs1evXh1f+9rXYtKkSVFVVdWivFzyIyJuu+222HnnneNTn/pUTJgwIVavXl1w9rJly+Lpp5+OXr16xRFHHBGVlZVx1FFHFeVrcXOzZ8+OuXPn5jWjW8s+4ogj4g9/+EO8++67sWHDhrjzzjtjzZo1cfTRRxeUvXbt2igpKYmysrL6fTp16hTt2rVr8eOy+fO3Ys7ntnpumGt2vrOZS34h87m17GLNZ2PrLsZsbp5dzNlsau0bFTKfW8su1nxunl2s+WzsNVAxZnRbvr5qSXY+M5prfj4z2lR2oTPa3LoLmdHGsos1o7k+5vnMaFPZhc5oY9nFmNHGeoRizOe26ihamp3PfOaan898NpVd6Hw2t+5C5rOx7GLNZ66PeT7z2VR2ofPZWHah89lcF7dNuqK86vKPudiG7/hev359Gj58ePrsZz9btMwXXnghde3aNbVv3z5VVFSkBx98sGjZd9xxR/rUpz6VPvjgg5RScd+x8uc//zn98Y9/TM8//3yaMmVKqq6uTv369Uu1tbUFZ5eVlaWysrI0YcKE9Nxzz6Ubb7wxderUKd16661FWHlDf/jDH1L79u3TW2+9VZS89evXp/Hjx6eSkpLUoUOHVFJSkn76058WJTullKqrq9NRRx2V3nrrrfThhx+m3/3ud6ldu3bpk5/8ZN6Zm8/Mk08+mSIiLV68uMF+J510Ujr55JMLyt5Ua7zj+4MPPkgHHXRQ+trXvla07Pvvvz917do1lZSUpN69e6dnnnmmKNk//elP0xe+8IX63zwo9ju+77jjjnTvvfemF154Id19991pn332SYceemj68MMPC8re+K6ALl26pF/+8pdpzpw5aeLEiamkpCQ9/vjjBa97U1dccUXacccd67+nFZq9Zs2a9I1vfCNFROrQoUMqLS1Nv/nNbwrOrqurS/369UsnnXRSevfdd9PatWvT5ZdfniIiDRkypEXZWzvu3Hbbbam0tHSLfQ899ND0gx/8oKDsTRX6jtJcjplvv/126tevX/rhD39YtOxJkyalrl27pohIe++9d4vfTdpY9re+9a10+umn13+c7/ONxvJvvPHGNGXKlPTCCy+k3//+92nXXXdNX/rSlwrOnjFjRoqI1KNHj3TLLbek5557Lp177rmptLQ0vfrqqwWve1NnnXVW2meffVq05qay33vvvTRkyJD6GS0vL08PPfRQwdnLli1L5eXl6ZxzzkmrVq1KK1euTGPHjk0Rkb71rW/llNvY87dizGcuzw3znc9cn3fmO5vN5Rcyn01lFzqfTWUXOpuNZRdrNnP9f5rPfDaVXeh8NpZdjPls6jVQoTOa6+urfGa0Ja/d8pnRXPLzndHmsguZ0eayC5nRprKLMaMt+X/a0hltLruQGW0qu9AZbapHKHQ+c+0o8pnPlvQf+cxnLvn5zmdz2YXMZ3PZhcxnU9nFmM+W/D9t6Xw2l13IfDaVXeh8NtfFFbMr2kjxnYdtWXyfeeaZqX///unNN98sWubatWvTggUL0qxZs9L555+fdt555/TSSy8VnLto0aLUq1ev9Pzzz9dfV+xf1dzUe++9l8rLy4tympaOHTum6urqBtedffbZ6fDDDy84e3NDhgxJ/+t//a+i5d1xxx2pT58+6Y477kgvvPBC+u1vf5t69OhRtNL+tddeS0ceeWSKiNS+fft06KGHplGjRqUBAwbknZnV4ruuri6NGDEiffrTn27wqz6FZq9cuTItWLAgzZgxI5122mlpt912S0uXLi0oe9asWamysrLBD2CKXXxv7vXXXy/KaVreeuutFBHpq1/9aoP9RowYkb7yla8UlL25vffeO40dO7ZFmU1l/+xnP0uf/OQn03333Zeef/75dO2116Zu3bq1+FQHW8ueNWtWOuCAA+pndejQoenYY49Nw4YNa1H21o47xSq+mzumFVp8N5e/YsWK9JnPfCYNGzYs1dXVFS17+fLl6dVXX03Tp09PI0aMSAcddFCLfliytex777037bnnnun999+vvy7f5xu5PpeYNm1ai08DsbXsjd/TJ0yY0GDf/fbbL51//vlFW/fq1atTRUVF+vnPf55zZnPZY8eOTZ/5zGfSI488kubOnZsuueSSVFFRkV544YWCsx966KG0xx57pJKSktS+ffv09a9/PR100EHpzDPPzCm3sedvxZjPXJ4b5jufuWQXMpvN5Rcyn41lF2M+W/J8vKWz2Vh2sWYzl7XnO59NZRc6n01lFzKfzb0GKmRGW/L6qqUz2pLsfGY01/x8ZrS57EJmNJ/XtLnOaHPZhc5oS9be0hnNJTvfGc0lu9Bj6KY27RGK9Rx3a9mbKsbpwhrLLuQY2lx+oc9xt5ZdzOe4ja17U/k8v91adrGOobmsvZDnuI1lF+M5bmPZhcxnc12c4ns7sa2K7zFjxqQ+ffqkN954o+jZmzrmmGNyfjdDU+6+++76wmXjJSLqv/hb+i7PXBxyyCF5f5PZVL9+/Rr8xDGllK677rrUu3fvgrM39fe//z21a9cu3XPPPUXL7NOnT/rVr37V4LrLLrss7b333kW7jZT+Vb5u/GZz8sknpy9+8Yt5Z20+MxsL0c0L6SOPPDJ997vfLSh7U9uy+K6rq0snnHBC2n///dP/+3//r6jZm9tzzz1b/K7+zbOvuuqq+tncdF7btWuX+vfv37KFbyW/MTvvvHO64YYbCspeu3Zt6tChQ7rssssa7PeDH/wgHXHEEQVlb+qJJ55IEZHmzp3boszGslevXp06duy4xTnzTz/99DR06NCCsje1fPnytGzZspRSSp/5zGfSd77znZxzGzvubHzCuPmT9X79+qVf/vKXBWVvqpAXBc3l19bWpurq6nTMMce0+Al7S47Ha9euTV26dEm33357QdnnnHNOozN61FFHbZO1r1y5MkVEmjJlSkHZb7zxRoqI9Lvf/a7B9SeffHLOvw2Ty7p/+9vfpo4dO9Z/veeqsezXXntti3Plp/Sv50nf/va3i7but99+u/5rvLKyMl155ZUtWv+m6/rWt75VlPlsLHtTxTrH9+bZhcxmLvmbaul8NpZdrPnMdd0tnc3Gsosxm03lbyrf+Wwsuxjz2Vj2pvKZz+ZeAz3yyCN5z2hLXl+1dEZzzc53RvN5bZjrjDaXPXbs2LxnNJ915zqjzWVv/DrPd0ZbsvaWzmiua89nRluy7mIdQzf2CNviGLq1jqJYx9DNs4t9DG2qXyn0GLoxe1scQ5tad6HH0I3Z2+oYurW1F+sYujF7WxxDt7bufOazuS6umF3RRs7xvR1IKcXYsWPj7rvvjkcffTR23333bXp7GzZsqD8/bCGOOeaYmDdvXsydO7f+csghh8SoUaNi7ty50b59+yKs9n+sXLkyXn/99dhll10KzvrsZz8b8+fPb3Ddq6++Gv379y84e1OTJ0+OXr16xfDhw4uWuXr16i3+inD79u1b/Ffom9O1a9fYZZdd4r333ouHHnoojj/++KJl77777lFVVRXTpk2rv662tjaefvrpop9jdFtYt25dnHzyybFgwYJ45JFHYqeddtqmt1eMmT3llFPihRdeaDCvvXv3jvPOOy8eeuihIq20oX/+85/xzjvvFDyzpaWlceihh27zmb355pvj4IMPLsr51CP+9XWybt26bT6vFRUV0bNnz1iwYEHMmjUrp1lt7rhz8MEHR8eOHRvM6Pz582PRokXNzui2Pqblkl9bWxtDhgyJ0tLSuO+++7b4uwXFXHv615sImp3R5rLPP//8LWY0IuKqq66KyZMnb5O1b7yN5ma0uezddtstevfundeMtmTdN998cxx33HHRs2fPJjNzzd54/sd8ZrQl6955552je/fu8eijj8ayZcviuOOOy2n9m9t4LChkPpvL3hY2zc53NnPN31yu89lcdqHz2dJ15zqbzWUXMpu55G+qpfPZXHYh89lc9qbymc/mXgMdcsghec/otnx9lUt2ITOaz9pzndHmsn/0ox/lPaP5rDvXGW0ue4899ihoRluy9pbOaHPZhcxoS9ZdjGPopj1CsY+hxewomssu9jG0ubUXcgzdNLvYx9Dm1l3IMXTT7G1xDG1s7cU4hm6aXexjaGPrzmc+m+vitklXlFdd/jH0/vvvpzlz5qQ5c+akiKg/z+w//vGPgrPPOuusVFFRkR5//PG0ZMmS+svq1asLzj7//PPT9OnT08KFC9MLL7yQzj///FRSUpIefvjhgrO3ppinOvn+97+fHn/88bRw4cL05JNPpsGDB6edd9654J+CpZTSM888kzp06JB+8pOfpAULFqTbbrstdenSJf3+978vwsr/Zf369alfv35p/PjxRctMKaXRo0enXXfdNT3wwANp4cKF6U9/+lPaeeed8/rVrK2ZMmVK+stf/pLeeOON9PDDD6cDDjggHXbYYS3+NarmZubyyy9P3bt3rz8n9PHHH5923333nH5y3Vz2O++8k+bMmZMefPDBFBHpzjvvTHPmzElLliwpeO11dXXpuOOOS3369Elz585tMLNr164tKHvlypVpwoQJacaMGenvf/97mjVrVvrmN7+ZysrKtvhpbT6Py+ZaeqqTpvLff//99O///u9pxowZaeHChemRRx5JBx10UNprr73SmjVrCl77n/70p9SxY8d00003pQULFqRrr702tW/fPv33f/93UR6XFStWpC5duqTrr78+58cjl+yjjjoq7bvvvumxxx5Lb7zxRpo8eXLq1KlTuu666wrO/uMf/5gee+yx9Prrr6d77rkn9e/fP5144ok5rTuX486ZZ56Z+vXrlx599NE0a9asVF1dvcWvpeWbvWTJkjRnzpz061//OkVEeuKJJ9KcOXPSO++8U3D+ihUr0mGHHZb222+/9NprrzXYp7nfRGou+/XXX08//elP06xZs9I//vGP9OSTT6YRI0akHj16NHs6onyO9dGC3zBrLv+1115Ll156aZo1a1ZauHBhuvfee9Mee+yRjjzyyIKzU/rXb5WUl5enu+66Ky1YsCBdcMEFqVOnTs3+mmmuj8uCBQtSSUlJ+stf/pLT45FLdl1dXdpzzz3T5z//+fT000+n1157Lf385z9PJSUlzf49lFzWfcstt6QZM2ak1157Lf3ud79LPXr0SOPGjctp7c09f8t3PnPJLmQ+m8ouZDZzyS9kPnN5XDbXkvlsKruQ2cxl3fnOZksel3zms7nsQuYzl3UXMp9bs/lroEJmtLnsQma0qexizGhT+YXOaFPZW9OSGW0qu9AZbSo7pcJntLn8lPKf0aayC53R5tZdyIw21yMUMp/NZRcyn01lF2M+m8ovdD5b2t20ZD6byi50Pptbd6Hzmcvjku98NpVd6Hw2t+5C5jOXLq6QrmhrFN852virKptfRo8eXXD21nIjIk2ePLng7NNOOy31798/lZaWpp49e6Zjjjlmm5XeKRW3+P7yl7+cdtlll1RaWpp23XXX9OUvfznvJwBbc//996dPfepTqaysLA0YMCDddNNNRctO6V/nPYqINH/+/KLm1tbWpnPOOSf169cvderUKe2xxx7pRz/6UU6lay7+8Ic/pD322COVlpamqqqqNGbMmLR8+fIW5zQ3Mxs2bEgXXnhhqqysTGVlZemYY47J+bFqLnvy5Mlb3X7xxRcXnL/x9Clbuzz22GMFZX/wwQfpS1/6Uurdu3cqLS1Nu+yySzruuONy/uOWLf0+1dLiu6n81atXpyFDhqSePXumjh07pv79+6czzjgj1dTUFG3tN998c9pzzz1Tp06d0gEHHJDzKYRyyb7xxhtT586dW/y13lz2kiVL0qmnnpp69+6dOnXqlPbee+/0i1/8ov4PjBaS/Z//+Z+pT58+qWPHjqlfv37pggsuyPn7QC7HnQ8++CB95zvfSTvuuGPq0qVL+tKXvpTTD49yyb744ovzPu41l9/Y4xYRaeHChQVlv/XWW+nYY49NvXr1Sh07dkx9+vRJX/va19Lf/va3ojwuW/ucXF8UNJe/aNGidOSRR6YePXqksrKytOeee6bzzjsvp79PkOvaJ06cmPr06ZO6dOmSqqurc/rBVK7ZEyZMSH379k3r16/P6fHINfvVV19NJ554YurVq1fq0qVL2n///dNvf/vbomSPHz8+VVZWpo4dO6a99tor59lPqfnnb/nOZy7ZhcxnU9mFzGYu+YXMZy6Py+ZaMp9NZRcym7muO5/ZbEl+PvOZS3a+85lLdiHzuTWbvwYqZEabyy5kRpvKLsaMNpVf6Iw2lb01LZnRprILndGmsjcqZEZzyc93RpvLLmRGm8suZEab6xEKmc/msguZz6ayizGfTeUXOp8t7W5aMp9NZRc6n7msu5D5zCU/3/lsLruQ+Wwuu9BjaHNdXCFd0daUpJRSAAAAAABARjjHNwAAAAAAmaL4BgAAAAAgUxTfAAAAAABkiuIbAAAAAIBMUXwDAAAAAJApim8AAAAAADJF8Q0AAAAAQKYovgEAoA0dffTRce655+a07+OPPx4lJSWxfPnygm5zt912i6uvvrqgDAAA2J4pvgEAgEbddNNNcfTRR0d5eXlRSncAAGgNim8AAKBRq1evjmHDhsUPf/jDtl4KAADkTPENAADbid/97ndxyCGHxA477BBVVVXxta99LZYtW7bFfk8++WTsv//+0alTpzj88MPjxRdfbLD9r3/9a3z+85+Pzp07R9++feO73/1urFq1Kq81nXvuuXH++efH4YcfntfnAwBAW1B8AwDAdmLdunVx2WWXxfPPPx/33HNP/P3vf49TTz11i/3OO++8+MUvfhHPPvts9OzZM0aMGBHr1q2LiIjXX389hg0bFiNHjowXXngh/vCHP8Rf//rXGDt2bCvfGwAAaDsd2noBAADAv5x22mn1/95jjz3immuuiUMPPTRWrlwZ3bp1q9928cUXxxe+8IWIiPjNb34Tffr0ibvvvjtOPvnkmDhxYowaNar+D2butddecc0118RRRx0V119/fXTq1KlV7xMAALQF7/gGAIDtxOzZs2PEiBHRr1+/2GGHHeKoo46KiIhFixY12K+6urr+3z169Ii99947XnnllYiIeP755+PWW2+Nbt261V+GDh0aGzZsiIULF7benQEAgDbkHd8AALAdWLVqVQwdOjSGDh0at912W/Ts2TMWLVoUQ4cOjbq6upxzVq5cGd/+9rfju9/97hbb+vXrV8wlAwDAdkvxDQAA24G//e1v8c4778Tll18effv2jYiIWbNmbXXfmTNn1pfY7733Xrz66quxzz77RETEQQcdFC+//HLsueeerbNwAADYDjnVCQAAbAf69esXpaWlce2118Ybb7wR9913X1x22WVb3ffSSy+NadOmxYsvvhinnnpq7LzzznHCCSdERMT48ePjqaeeirFjx8bcuXNjwYIFce+99+b9xy1rampi7ty58dprr0VExLx582Lu3Lnx7rvv5pUHAACtQfENAADbgZ49e8att94ad911VwwcODAuv/zy+PnPf77VfS+//PI455xz4uCDD46ampq4//77o7S0NCIi9t9//5g+fXq8+uqr8fnPfz4+/elPx0UXXRS9e/fOa1033HBDfPrTn44zzjgjIiKOPPLI+PSnPx333XdffncUAABaQUlKKbX1IgAAAAAAoFi84xsAAAAAgExRfAMAwMfUbbfdFt26ddvqZd99923r5QEAQN6c6gQAAD6m3n///Vi6dOlWt3Xs2DH69+/fyisCAIDiUHwDAAAAAJApTnUCAAAAAECmKL4BAAAAAMgUxTcAAAAAAJmi+AYAAAAAIFMU3wAAAAAAZIriGwAAAACATFF8AwAAAACQKYpvAAAAAAAy5f8DKoX2vNkPF+sAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 1800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "\n",
        "L1 = 'label_1'\n",
        "\n",
        "plt.figure(figsize=(18,6))\n",
        "sn.countplot(data=y_train, x=L1, color='blue')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Initial Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOHeNnVdZ34U",
        "outputId": "0a68dfb6-7226-4824-ade4-6a95c112f87e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy = 0.9733333333333334\n"
          ]
        }
      ],
      "source": [
        "accuracy = svm_classifier(x_train[L1], y_train[L1], x_valid[L1], y_valid[L1])\n",
        "print(f\"Accuracy = {accuracy}\")\n",
        "# accuracy = xgb_classifier(x_train[L1], y_train[L1]-1, x_valid[L1], y_valid[L1]-1)\n",
        "# print(f\"Accuracy = {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6JAQS1QXCpj"
      },
      "source": [
        "#### Correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "aoLK40S_TMVV"
      },
      "outputs": [],
      "source": [
        "corr_matrix_l1 = x_train[L1].corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "kYtJbnyTTv_e",
        "outputId": "13748243-6ff7-4a79-b47e-a8d82e47ac28"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>feature_10</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_759</th>\n",
              "      <th>feature_760</th>\n",
              "      <th>feature_761</th>\n",
              "      <th>feature_762</th>\n",
              "      <th>feature_763</th>\n",
              "      <th>feature_764</th>\n",
              "      <th>feature_765</th>\n",
              "      <th>feature_766</th>\n",
              "      <th>feature_767</th>\n",
              "      <th>feature_768</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>feature_1</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.267338</td>\n",
              "      <td>0.071490</td>\n",
              "      <td>0.414422</td>\n",
              "      <td>0.036982</td>\n",
              "      <td>0.207898</td>\n",
              "      <td>0.118319</td>\n",
              "      <td>0.147709</td>\n",
              "      <td>0.368570</td>\n",
              "      <td>-0.190114</td>\n",
              "      <td>...</td>\n",
              "      <td>0.294503</td>\n",
              "      <td>0.016181</td>\n",
              "      <td>0.253096</td>\n",
              "      <td>-0.245060</td>\n",
              "      <td>0.423731</td>\n",
              "      <td>0.443474</td>\n",
              "      <td>0.216448</td>\n",
              "      <td>-0.372152</td>\n",
              "      <td>0.081136</td>\n",
              "      <td>0.266223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_2</th>\n",
              "      <td>0.267338</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.027042</td>\n",
              "      <td>0.004284</td>\n",
              "      <td>0.009556</td>\n",
              "      <td>-0.175189</td>\n",
              "      <td>0.118727</td>\n",
              "      <td>0.047381</td>\n",
              "      <td>0.146719</td>\n",
              "      <td>0.004041</td>\n",
              "      <td>...</td>\n",
              "      <td>0.036397</td>\n",
              "      <td>0.120084</td>\n",
              "      <td>0.058233</td>\n",
              "      <td>-0.095840</td>\n",
              "      <td>0.066372</td>\n",
              "      <td>0.357378</td>\n",
              "      <td>0.107098</td>\n",
              "      <td>0.008878</td>\n",
              "      <td>-0.021500</td>\n",
              "      <td>0.233835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_3</th>\n",
              "      <td>0.071490</td>\n",
              "      <td>-0.027042</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.005692</td>\n",
              "      <td>0.187217</td>\n",
              "      <td>-0.184922</td>\n",
              "      <td>-0.071054</td>\n",
              "      <td>-0.217118</td>\n",
              "      <td>0.112494</td>\n",
              "      <td>-0.045269</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.054550</td>\n",
              "      <td>0.048824</td>\n",
              "      <td>-0.087434</td>\n",
              "      <td>0.183482</td>\n",
              "      <td>-0.184763</td>\n",
              "      <td>-0.133512</td>\n",
              "      <td>-0.018046</td>\n",
              "      <td>0.164799</td>\n",
              "      <td>-0.030219</td>\n",
              "      <td>0.204483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_4</th>\n",
              "      <td>0.414422</td>\n",
              "      <td>0.004284</td>\n",
              "      <td>0.005692</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.017515</td>\n",
              "      <td>0.295999</td>\n",
              "      <td>-0.119338</td>\n",
              "      <td>0.077402</td>\n",
              "      <td>0.123430</td>\n",
              "      <td>-0.147437</td>\n",
              "      <td>...</td>\n",
              "      <td>0.402941</td>\n",
              "      <td>-0.048514</td>\n",
              "      <td>0.175835</td>\n",
              "      <td>-0.130880</td>\n",
              "      <td>0.364475</td>\n",
              "      <td>0.317812</td>\n",
              "      <td>0.156064</td>\n",
              "      <td>-0.313222</td>\n",
              "      <td>0.200493</td>\n",
              "      <td>0.071073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_5</th>\n",
              "      <td>0.036982</td>\n",
              "      <td>0.009556</td>\n",
              "      <td>0.187217</td>\n",
              "      <td>-0.017515</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.139041</td>\n",
              "      <td>-0.020940</td>\n",
              "      <td>-0.116694</td>\n",
              "      <td>0.187147</td>\n",
              "      <td>-0.095713</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002091</td>\n",
              "      <td>0.094546</td>\n",
              "      <td>0.062270</td>\n",
              "      <td>0.143789</td>\n",
              "      <td>-0.263428</td>\n",
              "      <td>0.032675</td>\n",
              "      <td>-0.091599</td>\n",
              "      <td>0.159690</td>\n",
              "      <td>-0.051591</td>\n",
              "      <td>-0.072895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_764</th>\n",
              "      <td>0.443474</td>\n",
              "      <td>0.357378</td>\n",
              "      <td>-0.133512</td>\n",
              "      <td>0.317812</td>\n",
              "      <td>0.032675</td>\n",
              "      <td>0.202273</td>\n",
              "      <td>0.078858</td>\n",
              "      <td>0.117481</td>\n",
              "      <td>0.085433</td>\n",
              "      <td>-0.282476</td>\n",
              "      <td>...</td>\n",
              "      <td>0.192540</td>\n",
              "      <td>0.068779</td>\n",
              "      <td>0.145485</td>\n",
              "      <td>-0.230508</td>\n",
              "      <td>0.315251</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.204746</td>\n",
              "      <td>-0.159590</td>\n",
              "      <td>0.181170</td>\n",
              "      <td>0.216180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_765</th>\n",
              "      <td>0.216448</td>\n",
              "      <td>0.107098</td>\n",
              "      <td>-0.018046</td>\n",
              "      <td>0.156064</td>\n",
              "      <td>-0.091599</td>\n",
              "      <td>-0.113032</td>\n",
              "      <td>-0.079667</td>\n",
              "      <td>0.106025</td>\n",
              "      <td>0.118023</td>\n",
              "      <td>-0.205155</td>\n",
              "      <td>...</td>\n",
              "      <td>0.213167</td>\n",
              "      <td>0.136531</td>\n",
              "      <td>0.093549</td>\n",
              "      <td>-0.129885</td>\n",
              "      <td>0.327689</td>\n",
              "      <td>0.204746</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.117247</td>\n",
              "      <td>0.154951</td>\n",
              "      <td>0.388355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_766</th>\n",
              "      <td>-0.372152</td>\n",
              "      <td>0.008878</td>\n",
              "      <td>0.164799</td>\n",
              "      <td>-0.313222</td>\n",
              "      <td>0.159690</td>\n",
              "      <td>-0.411833</td>\n",
              "      <td>-0.139678</td>\n",
              "      <td>-0.374096</td>\n",
              "      <td>-0.342061</td>\n",
              "      <td>0.119664</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.559327</td>\n",
              "      <td>0.201898</td>\n",
              "      <td>-0.053654</td>\n",
              "      <td>0.334765</td>\n",
              "      <td>-0.503721</td>\n",
              "      <td>-0.159590</td>\n",
              "      <td>-0.117247</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.224632</td>\n",
              "      <td>0.129305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_767</th>\n",
              "      <td>0.081136</td>\n",
              "      <td>-0.021500</td>\n",
              "      <td>-0.030219</td>\n",
              "      <td>0.200493</td>\n",
              "      <td>-0.051591</td>\n",
              "      <td>0.173833</td>\n",
              "      <td>-0.109424</td>\n",
              "      <td>0.160097</td>\n",
              "      <td>0.017900</td>\n",
              "      <td>-0.064848</td>\n",
              "      <td>...</td>\n",
              "      <td>0.242810</td>\n",
              "      <td>-0.086578</td>\n",
              "      <td>-0.004117</td>\n",
              "      <td>-0.247390</td>\n",
              "      <td>0.280897</td>\n",
              "      <td>0.181170</td>\n",
              "      <td>0.154951</td>\n",
              "      <td>-0.224632</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.043913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_768</th>\n",
              "      <td>0.266223</td>\n",
              "      <td>0.233835</td>\n",
              "      <td>0.204483</td>\n",
              "      <td>0.071073</td>\n",
              "      <td>-0.072895</td>\n",
              "      <td>-0.208364</td>\n",
              "      <td>-0.122569</td>\n",
              "      <td>-0.007818</td>\n",
              "      <td>-0.078739</td>\n",
              "      <td>0.064398</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.049451</td>\n",
              "      <td>-0.056708</td>\n",
              "      <td>0.031914</td>\n",
              "      <td>0.022605</td>\n",
              "      <td>0.258167</td>\n",
              "      <td>0.216180</td>\n",
              "      <td>0.388355</td>\n",
              "      <td>0.129305</td>\n",
              "      <td>0.043913</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows × 768 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
              "feature_1     1.000000   0.267338   0.071490   0.414422   0.036982   0.207898   \n",
              "feature_2     0.267338   1.000000  -0.027042   0.004284   0.009556  -0.175189   \n",
              "feature_3     0.071490  -0.027042   1.000000   0.005692   0.187217  -0.184922   \n",
              "feature_4     0.414422   0.004284   0.005692   1.000000  -0.017515   0.295999   \n",
              "feature_5     0.036982   0.009556   0.187217  -0.017515   1.000000  -0.139041   \n",
              "...                ...        ...        ...        ...        ...        ...   \n",
              "feature_764   0.443474   0.357378  -0.133512   0.317812   0.032675   0.202273   \n",
              "feature_765   0.216448   0.107098  -0.018046   0.156064  -0.091599  -0.113032   \n",
              "feature_766  -0.372152   0.008878   0.164799  -0.313222   0.159690  -0.411833   \n",
              "feature_767   0.081136  -0.021500  -0.030219   0.200493  -0.051591   0.173833   \n",
              "feature_768   0.266223   0.233835   0.204483   0.071073  -0.072895  -0.208364   \n",
              "\n",
              "             feature_7  feature_8  feature_9  feature_10  ...  feature_759  \\\n",
              "feature_1     0.118319   0.147709   0.368570   -0.190114  ...     0.294503   \n",
              "feature_2     0.118727   0.047381   0.146719    0.004041  ...     0.036397   \n",
              "feature_3    -0.071054  -0.217118   0.112494   -0.045269  ...    -0.054550   \n",
              "feature_4    -0.119338   0.077402   0.123430   -0.147437  ...     0.402941   \n",
              "feature_5    -0.020940  -0.116694   0.187147   -0.095713  ...     0.002091   \n",
              "...                ...        ...        ...         ...  ...          ...   \n",
              "feature_764   0.078858   0.117481   0.085433   -0.282476  ...     0.192540   \n",
              "feature_765  -0.079667   0.106025   0.118023   -0.205155  ...     0.213167   \n",
              "feature_766  -0.139678  -0.374096  -0.342061    0.119664  ...    -0.559327   \n",
              "feature_767  -0.109424   0.160097   0.017900   -0.064848  ...     0.242810   \n",
              "feature_768  -0.122569  -0.007818  -0.078739    0.064398  ...    -0.049451   \n",
              "\n",
              "             feature_760  feature_761  feature_762  feature_763  feature_764  \\\n",
              "feature_1       0.016181     0.253096    -0.245060     0.423731     0.443474   \n",
              "feature_2       0.120084     0.058233    -0.095840     0.066372     0.357378   \n",
              "feature_3       0.048824    -0.087434     0.183482    -0.184763    -0.133512   \n",
              "feature_4      -0.048514     0.175835    -0.130880     0.364475     0.317812   \n",
              "feature_5       0.094546     0.062270     0.143789    -0.263428     0.032675   \n",
              "...                  ...          ...          ...          ...          ...   \n",
              "feature_764     0.068779     0.145485    -0.230508     0.315251     1.000000   \n",
              "feature_765     0.136531     0.093549    -0.129885     0.327689     0.204746   \n",
              "feature_766     0.201898    -0.053654     0.334765    -0.503721    -0.159590   \n",
              "feature_767    -0.086578    -0.004117    -0.247390     0.280897     0.181170   \n",
              "feature_768    -0.056708     0.031914     0.022605     0.258167     0.216180   \n",
              "\n",
              "             feature_765  feature_766  feature_767  feature_768  \n",
              "feature_1       0.216448    -0.372152     0.081136     0.266223  \n",
              "feature_2       0.107098     0.008878    -0.021500     0.233835  \n",
              "feature_3      -0.018046     0.164799    -0.030219     0.204483  \n",
              "feature_4       0.156064    -0.313222     0.200493     0.071073  \n",
              "feature_5      -0.091599     0.159690    -0.051591    -0.072895  \n",
              "...                  ...          ...          ...          ...  \n",
              "feature_764     0.204746    -0.159590     0.181170     0.216180  \n",
              "feature_765     1.000000    -0.117247     0.154951     0.388355  \n",
              "feature_766    -0.117247     1.000000    -0.224632     0.129305  \n",
              "feature_767     0.154951    -0.224632     1.000000     0.043913  \n",
              "feature_768     0.388355     0.129305     0.043913     1.000000  \n",
              "\n",
              "[768 rows x 768 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corr_matrix_l1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "CUISG7RyXf2u"
      },
      "outputs": [],
      "source": [
        "def get_corr_features(corr_matrix, threshold):\n",
        "\n",
        "  correlated_features = []\n",
        "\n",
        "  for i in range(len(corr_matrix.columns)):\n",
        "    for j in range(i+1, len(corr_matrix.columns)):\n",
        "      if (abs(corr_matrix.iloc[i, j]) > threshold):\n",
        "        col_name = corr_matrix.columns[j]\n",
        "        if col_name not in correlated_features:\n",
        "          correlated_features.append(col_name)\n",
        "\n",
        "  return correlated_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3D6Sbv9Ya39c",
        "outputId": "0649912e-2a7c-45ab-de9b-6e6adf24dd21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27\n"
          ]
        }
      ],
      "source": [
        "correlated_features_l1 = get_corr_features(corr_matrix_l1, 0.7)\n",
        "print(len(correlated_features_l1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQE4ZYMeKqj1"
      },
      "source": [
        "#### PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "l5k-Wm2DKulX"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "x_test_l1 = x_test.copy()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train[L1] = pd.DataFrame(scaler.fit_transform(x_train[L1]), columns=FEATURES)\n",
        "x_valid[L1] = pd.DataFrame(scaler.transform(x_valid[L1]), columns=FEATURES)\n",
        "x_test_l1 = pd.DataFrame(scaler.transform(x_test_l1), columns=FEATURES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN98_Gi5aU17",
        "outputId": "22fce5b6-c971-41f4-f57d-7e9374f9daea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of features: 311\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "threshold = 0.96\n",
        "\n",
        "pca = PCA(n_components=threshold, svd_solver='full')\n",
        "x_train_l1_pca = pd.DataFrame(pca.fit_transform(x_train[L1]))\n",
        "x_valid_l1_pca = pd.DataFrame(pca.transform(x_valid[L1]))\n",
        "x_test_l1_pca = pd.DataFrame(pca.transform(x_test_l1))\n",
        "\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "\n",
        "print(f\"Number of features: {len(explained_variance)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asP6QOkfacvy",
        "outputId": "aa4f73c8-1cea-4fab-ed50-c0379cc42b78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy = 0.9573333333333334\n"
          ]
        }
      ],
      "source": [
        "accuracy_1 = svm_classifier(x_train_l1_pca, y_train[L1], x_valid_l1_pca, y_valid[L1])\n",
        "print(f\"Accuracy = {accuracy_1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgSvtyBUdDxc"
      },
      "source": [
        "#### Hyperparameter Tuning - Random Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYIAt9GtdHIT",
        "outputId": "dfbd9633-0fd4-468f-e455-06c921afb4e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "{'kernel': 'linear', 'gamma': 1000.0, 'C': 0.01}\n",
            "0.9408134642356241\n"
          ]
        }
      ],
      "source": [
        "param_dist = {\n",
        "    'C': np.logspace(-3, 3, 7),\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'gamma': np.logspace(-3, 3, 7)\n",
        "}\n",
        "cv = 2\n",
        "n_iter = 5\n",
        "svm = SVC()\n",
        "\n",
        "# random_search_l1 = grid_search(svm, param_dist, cv, x_train_l1_pca, y_train[L1])\n",
        "random_search_l1 = random_grid_search(svm, param_dist, cv, n_iter, x_train_l1_pca, y_train[L1])\n",
        "best_model_l1 = random_search_l1.best_estimator_\n",
        "best_accuracy_l1 = random_search_l1.best_score_\n",
        "best_param = random_search_l1.best_params_\n",
        "\n",
        "print(best_param)\n",
        "print(best_accuracy_l1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy after: 0.96\n"
          ]
        }
      ],
      "source": [
        "y_pred_l1 = best_model_l1.predict(x_valid_l1_pca)\n",
        "accuracy = accuracy_score(y_valid[L1], y_pred_l1)\n",
        "print(f\"Accuracy after: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-Validation Scores: [0.94915849 0.94950912 0.94775596 0.94950912 0.95091164]\n",
            "Mean Score: 0.9493688639551191\n",
            "Standard Deviation: 0.0010065007078827013\n"
          ]
        }
      ],
      "source": [
        "model = SVC(kernel= best_param['kernel'], gamma= best_param['gamma'], C= best_param['C'])\n",
        "\n",
        "k_fold_cross_validation(model, 5, x_train_l1_pca, y_train[L1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRH_NdswedzL"
      },
      "source": [
        "## Label 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "YAMMp3VJedzV",
        "outputId": "72155a8e-b778-4a0d-b404-628d7587a0c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot: xlabel='label_2', ylabel='count'>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "\n",
        "L2 = 'label_2'\n",
        "\n",
        "plt.figure(figsize=(18,6))\n",
        "sn.countplot(data=y_train, x=L2, color='blue')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Initial Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-eUyfsE-edzV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy = 0.8546195652173914\n"
          ]
        }
      ],
      "source": [
        "accuracy = weighted_svm_classifier(x_train[L2], y_train[L2], x_valid[L2], y_valid[L2])\n",
        "print(f\"Accuracy = {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tmfnrgTedzV"
      },
      "source": [
        "#### Correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "TvfltvkmedzW"
      },
      "outputs": [],
      "source": [
        "corr_matrix_l2 = x_train[L2].corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "gsUZ9F4tedzW",
        "outputId": "13748243-6ff7-4a79-b47e-a8d82e47ac28"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>feature_10</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_759</th>\n",
              "      <th>feature_760</th>\n",
              "      <th>feature_761</th>\n",
              "      <th>feature_762</th>\n",
              "      <th>feature_763</th>\n",
              "      <th>feature_764</th>\n",
              "      <th>feature_765</th>\n",
              "      <th>feature_766</th>\n",
              "      <th>feature_767</th>\n",
              "      <th>feature_768</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>feature_1</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.267813</td>\n",
              "      <td>0.070144</td>\n",
              "      <td>0.417878</td>\n",
              "      <td>0.033714</td>\n",
              "      <td>0.209910</td>\n",
              "      <td>0.116550</td>\n",
              "      <td>0.150595</td>\n",
              "      <td>0.370029</td>\n",
              "      <td>-0.189436</td>\n",
              "      <td>...</td>\n",
              "      <td>0.297201</td>\n",
              "      <td>0.018032</td>\n",
              "      <td>0.255393</td>\n",
              "      <td>-0.246138</td>\n",
              "      <td>0.426069</td>\n",
              "      <td>0.446561</td>\n",
              "      <td>0.215418</td>\n",
              "      <td>-0.375987</td>\n",
              "      <td>0.081306</td>\n",
              "      <td>0.264334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_2</th>\n",
              "      <td>0.267813</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.026523</td>\n",
              "      <td>0.009167</td>\n",
              "      <td>0.009995</td>\n",
              "      <td>-0.172705</td>\n",
              "      <td>0.113808</td>\n",
              "      <td>0.049757</td>\n",
              "      <td>0.149616</td>\n",
              "      <td>0.001501</td>\n",
              "      <td>...</td>\n",
              "      <td>0.038700</td>\n",
              "      <td>0.123209</td>\n",
              "      <td>0.061163</td>\n",
              "      <td>-0.094431</td>\n",
              "      <td>0.069125</td>\n",
              "      <td>0.359796</td>\n",
              "      <td>0.106820</td>\n",
              "      <td>0.006775</td>\n",
              "      <td>-0.018043</td>\n",
              "      <td>0.232196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_3</th>\n",
              "      <td>0.070144</td>\n",
              "      <td>-0.026523</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.005353</td>\n",
              "      <td>0.180449</td>\n",
              "      <td>-0.186466</td>\n",
              "      <td>-0.071249</td>\n",
              "      <td>-0.211689</td>\n",
              "      <td>0.111781</td>\n",
              "      <td>-0.041346</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.051653</td>\n",
              "      <td>0.044712</td>\n",
              "      <td>-0.088962</td>\n",
              "      <td>0.182082</td>\n",
              "      <td>-0.181114</td>\n",
              "      <td>-0.131502</td>\n",
              "      <td>-0.012662</td>\n",
              "      <td>0.162441</td>\n",
              "      <td>-0.027672</td>\n",
              "      <td>0.208699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_4</th>\n",
              "      <td>0.417878</td>\n",
              "      <td>0.009167</td>\n",
              "      <td>0.005353</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.022295</td>\n",
              "      <td>0.292640</td>\n",
              "      <td>-0.112259</td>\n",
              "      <td>0.076150</td>\n",
              "      <td>0.122772</td>\n",
              "      <td>-0.138988</td>\n",
              "      <td>...</td>\n",
              "      <td>0.402741</td>\n",
              "      <td>-0.049930</td>\n",
              "      <td>0.172788</td>\n",
              "      <td>-0.137451</td>\n",
              "      <td>0.368121</td>\n",
              "      <td>0.322847</td>\n",
              "      <td>0.151794</td>\n",
              "      <td>-0.320019</td>\n",
              "      <td>0.190503</td>\n",
              "      <td>0.074772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_5</th>\n",
              "      <td>0.033714</td>\n",
              "      <td>0.009995</td>\n",
              "      <td>0.180449</td>\n",
              "      <td>-0.022295</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.142908</td>\n",
              "      <td>-0.017537</td>\n",
              "      <td>-0.114017</td>\n",
              "      <td>0.186643</td>\n",
              "      <td>-0.087017</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005789</td>\n",
              "      <td>0.091802</td>\n",
              "      <td>0.062721</td>\n",
              "      <td>0.142031</td>\n",
              "      <td>-0.260692</td>\n",
              "      <td>0.033650</td>\n",
              "      <td>-0.093082</td>\n",
              "      <td>0.155329</td>\n",
              "      <td>-0.058548</td>\n",
              "      <td>-0.075744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_764</th>\n",
              "      <td>0.446561</td>\n",
              "      <td>0.359796</td>\n",
              "      <td>-0.131502</td>\n",
              "      <td>0.322847</td>\n",
              "      <td>0.033650</td>\n",
              "      <td>0.205621</td>\n",
              "      <td>0.080360</td>\n",
              "      <td>0.118297</td>\n",
              "      <td>0.087449</td>\n",
              "      <td>-0.285009</td>\n",
              "      <td>...</td>\n",
              "      <td>0.193659</td>\n",
              "      <td>0.071836</td>\n",
              "      <td>0.151612</td>\n",
              "      <td>-0.229925</td>\n",
              "      <td>0.320523</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.202905</td>\n",
              "      <td>-0.159847</td>\n",
              "      <td>0.185768</td>\n",
              "      <td>0.216945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_765</th>\n",
              "      <td>0.215418</td>\n",
              "      <td>0.106820</td>\n",
              "      <td>-0.012662</td>\n",
              "      <td>0.151794</td>\n",
              "      <td>-0.093082</td>\n",
              "      <td>-0.115739</td>\n",
              "      <td>-0.084028</td>\n",
              "      <td>0.103865</td>\n",
              "      <td>0.115217</td>\n",
              "      <td>-0.206392</td>\n",
              "      <td>...</td>\n",
              "      <td>0.212146</td>\n",
              "      <td>0.141885</td>\n",
              "      <td>0.090349</td>\n",
              "      <td>-0.128055</td>\n",
              "      <td>0.325169</td>\n",
              "      <td>0.202905</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.116333</td>\n",
              "      <td>0.149274</td>\n",
              "      <td>0.386537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_766</th>\n",
              "      <td>-0.375987</td>\n",
              "      <td>0.006775</td>\n",
              "      <td>0.162441</td>\n",
              "      <td>-0.320019</td>\n",
              "      <td>0.155329</td>\n",
              "      <td>-0.415908</td>\n",
              "      <td>-0.136781</td>\n",
              "      <td>-0.373673</td>\n",
              "      <td>-0.345407</td>\n",
              "      <td>0.124422</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.560405</td>\n",
              "      <td>0.202560</td>\n",
              "      <td>-0.053245</td>\n",
              "      <td>0.331708</td>\n",
              "      <td>-0.502737</td>\n",
              "      <td>-0.159847</td>\n",
              "      <td>-0.116333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.227493</td>\n",
              "      <td>0.127959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_767</th>\n",
              "      <td>0.081306</td>\n",
              "      <td>-0.018043</td>\n",
              "      <td>-0.027672</td>\n",
              "      <td>0.190503</td>\n",
              "      <td>-0.058548</td>\n",
              "      <td>0.168175</td>\n",
              "      <td>-0.102376</td>\n",
              "      <td>0.156081</td>\n",
              "      <td>0.014244</td>\n",
              "      <td>-0.058061</td>\n",
              "      <td>...</td>\n",
              "      <td>0.240173</td>\n",
              "      <td>-0.086312</td>\n",
              "      <td>-0.008781</td>\n",
              "      <td>-0.256112</td>\n",
              "      <td>0.283299</td>\n",
              "      <td>0.185768</td>\n",
              "      <td>0.149274</td>\n",
              "      <td>-0.227493</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.047130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_768</th>\n",
              "      <td>0.264334</td>\n",
              "      <td>0.232196</td>\n",
              "      <td>0.208699</td>\n",
              "      <td>0.074772</td>\n",
              "      <td>-0.075744</td>\n",
              "      <td>-0.206682</td>\n",
              "      <td>-0.133609</td>\n",
              "      <td>-0.004985</td>\n",
              "      <td>-0.079681</td>\n",
              "      <td>0.062276</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.046074</td>\n",
              "      <td>-0.053288</td>\n",
              "      <td>0.032905</td>\n",
              "      <td>0.027226</td>\n",
              "      <td>0.259485</td>\n",
              "      <td>0.216945</td>\n",
              "      <td>0.386537</td>\n",
              "      <td>0.127959</td>\n",
              "      <td>0.047130</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows × 768 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
              "feature_1     1.000000   0.267813   0.070144   0.417878   0.033714   0.209910   \n",
              "feature_2     0.267813   1.000000  -0.026523   0.009167   0.009995  -0.172705   \n",
              "feature_3     0.070144  -0.026523   1.000000   0.005353   0.180449  -0.186466   \n",
              "feature_4     0.417878   0.009167   0.005353   1.000000  -0.022295   0.292640   \n",
              "feature_5     0.033714   0.009995   0.180449  -0.022295   1.000000  -0.142908   \n",
              "...                ...        ...        ...        ...        ...        ...   \n",
              "feature_764   0.446561   0.359796  -0.131502   0.322847   0.033650   0.205621   \n",
              "feature_765   0.215418   0.106820  -0.012662   0.151794  -0.093082  -0.115739   \n",
              "feature_766  -0.375987   0.006775   0.162441  -0.320019   0.155329  -0.415908   \n",
              "feature_767   0.081306  -0.018043  -0.027672   0.190503  -0.058548   0.168175   \n",
              "feature_768   0.264334   0.232196   0.208699   0.074772  -0.075744  -0.206682   \n",
              "\n",
              "             feature_7  feature_8  feature_9  feature_10  ...  feature_759  \\\n",
              "feature_1     0.116550   0.150595   0.370029   -0.189436  ...     0.297201   \n",
              "feature_2     0.113808   0.049757   0.149616    0.001501  ...     0.038700   \n",
              "feature_3    -0.071249  -0.211689   0.111781   -0.041346  ...    -0.051653   \n",
              "feature_4    -0.112259   0.076150   0.122772   -0.138988  ...     0.402741   \n",
              "feature_5    -0.017537  -0.114017   0.186643   -0.087017  ...     0.005789   \n",
              "...                ...        ...        ...         ...  ...          ...   \n",
              "feature_764   0.080360   0.118297   0.087449   -0.285009  ...     0.193659   \n",
              "feature_765  -0.084028   0.103865   0.115217   -0.206392  ...     0.212146   \n",
              "feature_766  -0.136781  -0.373673  -0.345407    0.124422  ...    -0.560405   \n",
              "feature_767  -0.102376   0.156081   0.014244   -0.058061  ...     0.240173   \n",
              "feature_768  -0.133609  -0.004985  -0.079681    0.062276  ...    -0.046074   \n",
              "\n",
              "             feature_760  feature_761  feature_762  feature_763  feature_764  \\\n",
              "feature_1       0.018032     0.255393    -0.246138     0.426069     0.446561   \n",
              "feature_2       0.123209     0.061163    -0.094431     0.069125     0.359796   \n",
              "feature_3       0.044712    -0.088962     0.182082    -0.181114    -0.131502   \n",
              "feature_4      -0.049930     0.172788    -0.137451     0.368121     0.322847   \n",
              "feature_5       0.091802     0.062721     0.142031    -0.260692     0.033650   \n",
              "...                  ...          ...          ...          ...          ...   \n",
              "feature_764     0.071836     0.151612    -0.229925     0.320523     1.000000   \n",
              "feature_765     0.141885     0.090349    -0.128055     0.325169     0.202905   \n",
              "feature_766     0.202560    -0.053245     0.331708    -0.502737    -0.159847   \n",
              "feature_767    -0.086312    -0.008781    -0.256112     0.283299     0.185768   \n",
              "feature_768    -0.053288     0.032905     0.027226     0.259485     0.216945   \n",
              "\n",
              "             feature_765  feature_766  feature_767  feature_768  \n",
              "feature_1       0.215418    -0.375987     0.081306     0.264334  \n",
              "feature_2       0.106820     0.006775    -0.018043     0.232196  \n",
              "feature_3      -0.012662     0.162441    -0.027672     0.208699  \n",
              "feature_4       0.151794    -0.320019     0.190503     0.074772  \n",
              "feature_5      -0.093082     0.155329    -0.058548    -0.075744  \n",
              "...                  ...          ...          ...          ...  \n",
              "feature_764     0.202905    -0.159847     0.185768     0.216945  \n",
              "feature_765     1.000000    -0.116333     0.149274     0.386537  \n",
              "feature_766    -0.116333     1.000000    -0.227493     0.127959  \n",
              "feature_767     0.149274    -0.227493     1.000000     0.047130  \n",
              "feature_768     0.386537     0.127959     0.047130     1.000000  \n",
              "\n",
              "[768 rows x 768 columns]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corr_matrix_l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "titlexI-edzX"
      },
      "outputs": [],
      "source": [
        "def get_corr_features(corr_matrix, threshold):\n",
        "\n",
        "  correlated_features = []\n",
        "\n",
        "  for i in range(len(corr_matrix.columns)):\n",
        "    for j in range(i+1, len(corr_matrix.columns)):\n",
        "      if (abs(corr_matrix.iloc[i, j]) > threshold):\n",
        "        col_name = corr_matrix.columns[j]\n",
        "        if col_name not in correlated_features:\n",
        "          correlated_features.append(col_name)\n",
        "\n",
        "  return correlated_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZN4S05bVedzX",
        "outputId": "0649912e-2a7c-45ab-de9b-6e6adf24dd21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27\n"
          ]
        }
      ],
      "source": [
        "correlated_features_l2 = get_corr_features(corr_matrix_l2, 0.7)\n",
        "print(len(correlated_features_l2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJE6imtMedzX"
      },
      "source": [
        "#### PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "MHQLyqEqedzX"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "x_test_l2 = x_test.copy()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train[L2] = pd.DataFrame(scaler.fit_transform(x_train[L2]), columns=FEATURES)\n",
        "x_valid[L2] = pd.DataFrame(scaler.transform(x_valid[L2]), columns=FEATURES)\n",
        "x_test_l2 = pd.DataFrame(scaler.transform(x_test_l2), columns=FEATURES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "kQAGGKpZedzY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of features: 310\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "threshold = 0.96\n",
        "\n",
        "pca = PCA(n_components=threshold, svd_solver='full')\n",
        "x_train_l2_pca = pd.DataFrame(pca.fit_transform(x_train[L2]))\n",
        "x_valid_l2_pca = pd.DataFrame(pca.transform(x_valid[L2]))\n",
        "x_test_l2_pca = pd.DataFrame(pca.transform(x_test_l2))\n",
        "\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "\n",
        "print(f\"Number of features: {len(explained_variance)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "--0z6WiQedzY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy = 0.8165760869565217\n"
          ]
        }
      ],
      "source": [
        "accuracy_1 = weighted_svm_classifier(x_train_l2_pca, y_train[L2], x_valid_l2_pca, y_valid[L2])\n",
        "print(f\"Accuracy = {accuracy_1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNo6SYfcedzY"
      },
      "source": [
        "#### Hyperparameter Tuning - Random Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "OuPhMkVyedzY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'kernel': 'poly', 'gamma': 0.1, 'class_weight': 'balanced', 'C': 1000.0}\n",
            "0.2671540656205421\n"
          ]
        }
      ],
      "source": [
        "param_dist = {\n",
        "    'C': np.logspace(-3, 3, 7),\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'gamma': np.logspace(-3, 3, 7),\n",
        "    'class_weight': ['balanced']\n",
        "}\n",
        "cv = 2\n",
        "n_iter = 5\n",
        "svm = SVC()\n",
        "\n",
        "random_search_l2 = random_grid_search(svm, param_dist, cv, n_iter, x_train_l2_pca, y_train[L2])\n",
        "best_model_l2 = random_search_l2.best_estimator_\n",
        "best_accuracy_l2 = random_search_l2.best_score_\n",
        "best_param = random_search_l2.best_params_\n",
        "\n",
        "print(best_param)\n",
        "print(best_accuracy_l2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy after: 0.9524456521739131\n"
          ]
        }
      ],
      "source": [
        "y_pred_l2 = best_model_l2.predict(x_valid_l2_pca)\n",
        "accuracy = accuracy_score(y_valid[L2], y_pred_l2)\n",
        "print(f\"Accuracy after: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-Validation Scores: [0.45952211 0.72075606 0.74643367 0.74054922 0.52549929]\n",
            "Mean Score: 0.6385520684736091\n",
            "Standard Deviation: 0.12135238837544056\n"
          ]
        }
      ],
      "source": [
        "model = SVC(kernel= best_param['kernel'], gamma= best_param['gamma'], class_weight= 'balanced', C= best_param['C'])\n",
        "\n",
        "\n",
        "k_fold_cross_validation(model, 5, x_train_l2_pca, y_train[L2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Label 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot: xlabel='label_3', ylabel='count'>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "\n",
        "L3 = 'label_3'\n",
        "\n",
        "plt.figure(figsize=(18,6))\n",
        "sn.countplot(data=y_train, x=L3, color='blue')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Initial Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy = 0.9893333333333333\n"
          ]
        }
      ],
      "source": [
        "accuracy = weighted_svm_classifier(x_train[L3], y_train[L3], x_valid[L3], y_valid[L3])\n",
        "print(f\"Accuracy = {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_matrix_l3 = x_train[L3].corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>feature_10</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_759</th>\n",
              "      <th>feature_760</th>\n",
              "      <th>feature_761</th>\n",
              "      <th>feature_762</th>\n",
              "      <th>feature_763</th>\n",
              "      <th>feature_764</th>\n",
              "      <th>feature_765</th>\n",
              "      <th>feature_766</th>\n",
              "      <th>feature_767</th>\n",
              "      <th>feature_768</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>feature_1</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.267338</td>\n",
              "      <td>0.071490</td>\n",
              "      <td>0.414422</td>\n",
              "      <td>0.036982</td>\n",
              "      <td>0.207898</td>\n",
              "      <td>0.118319</td>\n",
              "      <td>0.147709</td>\n",
              "      <td>0.368570</td>\n",
              "      <td>-0.190114</td>\n",
              "      <td>...</td>\n",
              "      <td>0.294503</td>\n",
              "      <td>0.016181</td>\n",
              "      <td>0.253096</td>\n",
              "      <td>-0.245060</td>\n",
              "      <td>0.423731</td>\n",
              "      <td>0.443474</td>\n",
              "      <td>0.216448</td>\n",
              "      <td>-0.372152</td>\n",
              "      <td>0.081136</td>\n",
              "      <td>0.266223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_2</th>\n",
              "      <td>0.267338</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.027042</td>\n",
              "      <td>0.004284</td>\n",
              "      <td>0.009556</td>\n",
              "      <td>-0.175189</td>\n",
              "      <td>0.118727</td>\n",
              "      <td>0.047381</td>\n",
              "      <td>0.146719</td>\n",
              "      <td>0.004041</td>\n",
              "      <td>...</td>\n",
              "      <td>0.036397</td>\n",
              "      <td>0.120084</td>\n",
              "      <td>0.058233</td>\n",
              "      <td>-0.095840</td>\n",
              "      <td>0.066372</td>\n",
              "      <td>0.357378</td>\n",
              "      <td>0.107098</td>\n",
              "      <td>0.008878</td>\n",
              "      <td>-0.021500</td>\n",
              "      <td>0.233835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_3</th>\n",
              "      <td>0.071490</td>\n",
              "      <td>-0.027042</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.005692</td>\n",
              "      <td>0.187217</td>\n",
              "      <td>-0.184922</td>\n",
              "      <td>-0.071054</td>\n",
              "      <td>-0.217118</td>\n",
              "      <td>0.112494</td>\n",
              "      <td>-0.045269</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.054550</td>\n",
              "      <td>0.048824</td>\n",
              "      <td>-0.087434</td>\n",
              "      <td>0.183482</td>\n",
              "      <td>-0.184763</td>\n",
              "      <td>-0.133512</td>\n",
              "      <td>-0.018046</td>\n",
              "      <td>0.164799</td>\n",
              "      <td>-0.030219</td>\n",
              "      <td>0.204483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_4</th>\n",
              "      <td>0.414422</td>\n",
              "      <td>0.004284</td>\n",
              "      <td>0.005692</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.017515</td>\n",
              "      <td>0.295999</td>\n",
              "      <td>-0.119338</td>\n",
              "      <td>0.077402</td>\n",
              "      <td>0.123430</td>\n",
              "      <td>-0.147437</td>\n",
              "      <td>...</td>\n",
              "      <td>0.402941</td>\n",
              "      <td>-0.048514</td>\n",
              "      <td>0.175835</td>\n",
              "      <td>-0.130880</td>\n",
              "      <td>0.364475</td>\n",
              "      <td>0.317812</td>\n",
              "      <td>0.156064</td>\n",
              "      <td>-0.313222</td>\n",
              "      <td>0.200493</td>\n",
              "      <td>0.071073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_5</th>\n",
              "      <td>0.036982</td>\n",
              "      <td>0.009556</td>\n",
              "      <td>0.187217</td>\n",
              "      <td>-0.017515</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.139041</td>\n",
              "      <td>-0.020940</td>\n",
              "      <td>-0.116694</td>\n",
              "      <td>0.187147</td>\n",
              "      <td>-0.095713</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002091</td>\n",
              "      <td>0.094546</td>\n",
              "      <td>0.062270</td>\n",
              "      <td>0.143789</td>\n",
              "      <td>-0.263428</td>\n",
              "      <td>0.032675</td>\n",
              "      <td>-0.091599</td>\n",
              "      <td>0.159690</td>\n",
              "      <td>-0.051591</td>\n",
              "      <td>-0.072895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_764</th>\n",
              "      <td>0.443474</td>\n",
              "      <td>0.357378</td>\n",
              "      <td>-0.133512</td>\n",
              "      <td>0.317812</td>\n",
              "      <td>0.032675</td>\n",
              "      <td>0.202273</td>\n",
              "      <td>0.078858</td>\n",
              "      <td>0.117481</td>\n",
              "      <td>0.085433</td>\n",
              "      <td>-0.282476</td>\n",
              "      <td>...</td>\n",
              "      <td>0.192540</td>\n",
              "      <td>0.068779</td>\n",
              "      <td>0.145485</td>\n",
              "      <td>-0.230508</td>\n",
              "      <td>0.315251</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.204746</td>\n",
              "      <td>-0.159590</td>\n",
              "      <td>0.181170</td>\n",
              "      <td>0.216180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_765</th>\n",
              "      <td>0.216448</td>\n",
              "      <td>0.107098</td>\n",
              "      <td>-0.018046</td>\n",
              "      <td>0.156064</td>\n",
              "      <td>-0.091599</td>\n",
              "      <td>-0.113032</td>\n",
              "      <td>-0.079667</td>\n",
              "      <td>0.106025</td>\n",
              "      <td>0.118023</td>\n",
              "      <td>-0.205155</td>\n",
              "      <td>...</td>\n",
              "      <td>0.213167</td>\n",
              "      <td>0.136531</td>\n",
              "      <td>0.093549</td>\n",
              "      <td>-0.129885</td>\n",
              "      <td>0.327689</td>\n",
              "      <td>0.204746</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.117247</td>\n",
              "      <td>0.154951</td>\n",
              "      <td>0.388355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_766</th>\n",
              "      <td>-0.372152</td>\n",
              "      <td>0.008878</td>\n",
              "      <td>0.164799</td>\n",
              "      <td>-0.313222</td>\n",
              "      <td>0.159690</td>\n",
              "      <td>-0.411833</td>\n",
              "      <td>-0.139678</td>\n",
              "      <td>-0.374096</td>\n",
              "      <td>-0.342061</td>\n",
              "      <td>0.119664</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.559327</td>\n",
              "      <td>0.201898</td>\n",
              "      <td>-0.053654</td>\n",
              "      <td>0.334765</td>\n",
              "      <td>-0.503721</td>\n",
              "      <td>-0.159590</td>\n",
              "      <td>-0.117247</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.224632</td>\n",
              "      <td>0.129305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_767</th>\n",
              "      <td>0.081136</td>\n",
              "      <td>-0.021500</td>\n",
              "      <td>-0.030219</td>\n",
              "      <td>0.200493</td>\n",
              "      <td>-0.051591</td>\n",
              "      <td>0.173833</td>\n",
              "      <td>-0.109424</td>\n",
              "      <td>0.160097</td>\n",
              "      <td>0.017900</td>\n",
              "      <td>-0.064848</td>\n",
              "      <td>...</td>\n",
              "      <td>0.242810</td>\n",
              "      <td>-0.086578</td>\n",
              "      <td>-0.004117</td>\n",
              "      <td>-0.247390</td>\n",
              "      <td>0.280897</td>\n",
              "      <td>0.181170</td>\n",
              "      <td>0.154951</td>\n",
              "      <td>-0.224632</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.043913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_768</th>\n",
              "      <td>0.266223</td>\n",
              "      <td>0.233835</td>\n",
              "      <td>0.204483</td>\n",
              "      <td>0.071073</td>\n",
              "      <td>-0.072895</td>\n",
              "      <td>-0.208364</td>\n",
              "      <td>-0.122569</td>\n",
              "      <td>-0.007818</td>\n",
              "      <td>-0.078739</td>\n",
              "      <td>0.064398</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.049451</td>\n",
              "      <td>-0.056708</td>\n",
              "      <td>0.031914</td>\n",
              "      <td>0.022605</td>\n",
              "      <td>0.258167</td>\n",
              "      <td>0.216180</td>\n",
              "      <td>0.388355</td>\n",
              "      <td>0.129305</td>\n",
              "      <td>0.043913</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows × 768 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
              "feature_1     1.000000   0.267338   0.071490   0.414422   0.036982   0.207898   \n",
              "feature_2     0.267338   1.000000  -0.027042   0.004284   0.009556  -0.175189   \n",
              "feature_3     0.071490  -0.027042   1.000000   0.005692   0.187217  -0.184922   \n",
              "feature_4     0.414422   0.004284   0.005692   1.000000  -0.017515   0.295999   \n",
              "feature_5     0.036982   0.009556   0.187217  -0.017515   1.000000  -0.139041   \n",
              "...                ...        ...        ...        ...        ...        ...   \n",
              "feature_764   0.443474   0.357378  -0.133512   0.317812   0.032675   0.202273   \n",
              "feature_765   0.216448   0.107098  -0.018046   0.156064  -0.091599  -0.113032   \n",
              "feature_766  -0.372152   0.008878   0.164799  -0.313222   0.159690  -0.411833   \n",
              "feature_767   0.081136  -0.021500  -0.030219   0.200493  -0.051591   0.173833   \n",
              "feature_768   0.266223   0.233835   0.204483   0.071073  -0.072895  -0.208364   \n",
              "\n",
              "             feature_7  feature_8  feature_9  feature_10  ...  feature_759  \\\n",
              "feature_1     0.118319   0.147709   0.368570   -0.190114  ...     0.294503   \n",
              "feature_2     0.118727   0.047381   0.146719    0.004041  ...     0.036397   \n",
              "feature_3    -0.071054  -0.217118   0.112494   -0.045269  ...    -0.054550   \n",
              "feature_4    -0.119338   0.077402   0.123430   -0.147437  ...     0.402941   \n",
              "feature_5    -0.020940  -0.116694   0.187147   -0.095713  ...     0.002091   \n",
              "...                ...        ...        ...         ...  ...          ...   \n",
              "feature_764   0.078858   0.117481   0.085433   -0.282476  ...     0.192540   \n",
              "feature_765  -0.079667   0.106025   0.118023   -0.205155  ...     0.213167   \n",
              "feature_766  -0.139678  -0.374096  -0.342061    0.119664  ...    -0.559327   \n",
              "feature_767  -0.109424   0.160097   0.017900   -0.064848  ...     0.242810   \n",
              "feature_768  -0.122569  -0.007818  -0.078739    0.064398  ...    -0.049451   \n",
              "\n",
              "             feature_760  feature_761  feature_762  feature_763  feature_764  \\\n",
              "feature_1       0.016181     0.253096    -0.245060     0.423731     0.443474   \n",
              "feature_2       0.120084     0.058233    -0.095840     0.066372     0.357378   \n",
              "feature_3       0.048824    -0.087434     0.183482    -0.184763    -0.133512   \n",
              "feature_4      -0.048514     0.175835    -0.130880     0.364475     0.317812   \n",
              "feature_5       0.094546     0.062270     0.143789    -0.263428     0.032675   \n",
              "...                  ...          ...          ...          ...          ...   \n",
              "feature_764     0.068779     0.145485    -0.230508     0.315251     1.000000   \n",
              "feature_765     0.136531     0.093549    -0.129885     0.327689     0.204746   \n",
              "feature_766     0.201898    -0.053654     0.334765    -0.503721    -0.159590   \n",
              "feature_767    -0.086578    -0.004117    -0.247390     0.280897     0.181170   \n",
              "feature_768    -0.056708     0.031914     0.022605     0.258167     0.216180   \n",
              "\n",
              "             feature_765  feature_766  feature_767  feature_768  \n",
              "feature_1       0.216448    -0.372152     0.081136     0.266223  \n",
              "feature_2       0.107098     0.008878    -0.021500     0.233835  \n",
              "feature_3      -0.018046     0.164799    -0.030219     0.204483  \n",
              "feature_4       0.156064    -0.313222     0.200493     0.071073  \n",
              "feature_5      -0.091599     0.159690    -0.051591    -0.072895  \n",
              "...                  ...          ...          ...          ...  \n",
              "feature_764     0.204746    -0.159590     0.181170     0.216180  \n",
              "feature_765     1.000000    -0.117247     0.154951     0.388355  \n",
              "feature_766    -0.117247     1.000000    -0.224632     0.129305  \n",
              "feature_767     0.154951    -0.224632     1.000000     0.043913  \n",
              "feature_768     0.388355     0.129305     0.043913     1.000000  \n",
              "\n",
              "[768 rows x 768 columns]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corr_matrix_l3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_corr_features(corr_matrix, threshold):\n",
        "\n",
        "  correlated_features = []\n",
        "\n",
        "  for i in range(len(corr_matrix.columns)):\n",
        "    for j in range(i+1, len(corr_matrix.columns)):\n",
        "      if (abs(corr_matrix.iloc[i, j]) > threshold):\n",
        "        col_name = corr_matrix.columns[j]\n",
        "        if col_name not in correlated_features:\n",
        "          correlated_features.append(col_name)\n",
        "\n",
        "  return correlated_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27\n"
          ]
        }
      ],
      "source": [
        "correlated_features_l3 = get_corr_features(corr_matrix_l3, 0.7)\n",
        "print(len(correlated_features_l3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "x_test_l3 = x_test.copy()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train[L3] = pd.DataFrame(scaler.fit_transform(x_train[L3]), columns=FEATURES)\n",
        "x_valid[L3] = pd.DataFrame(scaler.transform(x_valid[L3]), columns=FEATURES)\n",
        "x_test_l3 = pd.DataFrame(scaler.transform(x_test_l3), columns=FEATURES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of features: 311\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "threshold = 0.96\n",
        "\n",
        "pca = PCA(n_components=threshold, svd_solver='full')\n",
        "x_train_l3_pca = pd.DataFrame(pca.fit_transform(x_train[L3]))\n",
        "x_valid_l3_pca = pd.DataFrame(pca.transform(x_valid[L3]))\n",
        "x_test_l3_pca = pd.DataFrame(pca.transform(x_test_l3))\n",
        "\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "\n",
        "print(f\"Number of features: {len(explained_variance)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy = 0.9906666666666667\n"
          ]
        }
      ],
      "source": [
        "accuracy_1 = weighted_svm_classifier(x_train_l3_pca, y_train[L3], x_valid_l3_pca, y_valid[L3])\n",
        "print(f\"Accuracy = {accuracy_1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Hyperparameter Tuning - Random Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "{'kernel': 'linear', 'gamma': 0.1, 'class_weight': 'balanced', 'C': 0.001}\n",
            "0.9715988779803647\n"
          ]
        }
      ],
      "source": [
        "param_dist = {\n",
        "    'C': np.logspace(-3, 3, 7),\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'gamma': np.logspace(-3, 3, 7),\n",
        "    'class_weight': ['balanced']\n",
        "}\n",
        "cv = 2\n",
        "n_iter = 5\n",
        "svm = SVC()\n",
        "\n",
        "random_search_l3 = random_grid_search(svm, param_dist, cv, n_iter, x_train_l3_pca, y_train[L3])\n",
        "best_model_l3 = random_search_l3.best_estimator_\n",
        "best_accuracy_l3 = random_search_l3.best_score_\n",
        "best_param = random_search_l3.best_params_\n",
        "\n",
        "print(best_param)\n",
        "print(best_accuracy_l3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy after: 0.9853333333333333\n"
          ]
        }
      ],
      "source": [
        "y_pred_l3 = best_model_l3.predict(x_valid_l3_pca)\n",
        "accuracy = accuracy_score(y_valid[L3], y_pred_l3)\n",
        "print(f\"Accuracy after: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-Validation Scores: [0.96861851 0.98913043 0.98229313 0.98071529 0.9943899 ]\n",
            "Mean Score: 0.9830294530154278\n",
            "Standard Deviation: 0.008716128675680182\n"
          ]
        }
      ],
      "source": [
        "model = SVC(kernel= best_param['kernel'], gamma= best_param['gamma'], class_weight= 'balanced', C= best_param['C'])\n",
        "\n",
        "k_fold_cross_validation(model, 5, x_train_l3_pca, y_train[L3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Label 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot: xlabel='label_4', ylabel='count'>"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "\n",
        "L4 = 'label_4'\n",
        "\n",
        "plt.figure(figsize=(18,6))\n",
        "sn.countplot(data=y_train, x=L4, color='blue')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Initial Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy = 0.892\n"
          ]
        }
      ],
      "source": [
        "accuracy = weighted_svm_classifier(x_train[L4], y_train[L4], x_valid[L4], y_valid[L4])\n",
        "print(f\"Accuracy = {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_matrix_l4 = x_train[L4].corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>feature_10</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_759</th>\n",
              "      <th>feature_760</th>\n",
              "      <th>feature_761</th>\n",
              "      <th>feature_762</th>\n",
              "      <th>feature_763</th>\n",
              "      <th>feature_764</th>\n",
              "      <th>feature_765</th>\n",
              "      <th>feature_766</th>\n",
              "      <th>feature_767</th>\n",
              "      <th>feature_768</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>feature_1</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.267338</td>\n",
              "      <td>0.071490</td>\n",
              "      <td>0.414422</td>\n",
              "      <td>0.036982</td>\n",
              "      <td>0.207898</td>\n",
              "      <td>0.118319</td>\n",
              "      <td>0.147709</td>\n",
              "      <td>0.368570</td>\n",
              "      <td>-0.190114</td>\n",
              "      <td>...</td>\n",
              "      <td>0.294503</td>\n",
              "      <td>0.016181</td>\n",
              "      <td>0.253096</td>\n",
              "      <td>-0.245060</td>\n",
              "      <td>0.423731</td>\n",
              "      <td>0.443474</td>\n",
              "      <td>0.216448</td>\n",
              "      <td>-0.372152</td>\n",
              "      <td>0.081136</td>\n",
              "      <td>0.266223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_2</th>\n",
              "      <td>0.267338</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.027042</td>\n",
              "      <td>0.004284</td>\n",
              "      <td>0.009556</td>\n",
              "      <td>-0.175189</td>\n",
              "      <td>0.118727</td>\n",
              "      <td>0.047381</td>\n",
              "      <td>0.146719</td>\n",
              "      <td>0.004041</td>\n",
              "      <td>...</td>\n",
              "      <td>0.036397</td>\n",
              "      <td>0.120084</td>\n",
              "      <td>0.058233</td>\n",
              "      <td>-0.095840</td>\n",
              "      <td>0.066372</td>\n",
              "      <td>0.357378</td>\n",
              "      <td>0.107098</td>\n",
              "      <td>0.008878</td>\n",
              "      <td>-0.021500</td>\n",
              "      <td>0.233835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_3</th>\n",
              "      <td>0.071490</td>\n",
              "      <td>-0.027042</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.005692</td>\n",
              "      <td>0.187217</td>\n",
              "      <td>-0.184922</td>\n",
              "      <td>-0.071054</td>\n",
              "      <td>-0.217118</td>\n",
              "      <td>0.112494</td>\n",
              "      <td>-0.045269</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.054550</td>\n",
              "      <td>0.048824</td>\n",
              "      <td>-0.087434</td>\n",
              "      <td>0.183482</td>\n",
              "      <td>-0.184763</td>\n",
              "      <td>-0.133512</td>\n",
              "      <td>-0.018046</td>\n",
              "      <td>0.164799</td>\n",
              "      <td>-0.030219</td>\n",
              "      <td>0.204483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_4</th>\n",
              "      <td>0.414422</td>\n",
              "      <td>0.004284</td>\n",
              "      <td>0.005692</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.017515</td>\n",
              "      <td>0.295999</td>\n",
              "      <td>-0.119338</td>\n",
              "      <td>0.077402</td>\n",
              "      <td>0.123430</td>\n",
              "      <td>-0.147437</td>\n",
              "      <td>...</td>\n",
              "      <td>0.402941</td>\n",
              "      <td>-0.048514</td>\n",
              "      <td>0.175835</td>\n",
              "      <td>-0.130880</td>\n",
              "      <td>0.364475</td>\n",
              "      <td>0.317812</td>\n",
              "      <td>0.156064</td>\n",
              "      <td>-0.313222</td>\n",
              "      <td>0.200493</td>\n",
              "      <td>0.071073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_5</th>\n",
              "      <td>0.036982</td>\n",
              "      <td>0.009556</td>\n",
              "      <td>0.187217</td>\n",
              "      <td>-0.017515</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.139041</td>\n",
              "      <td>-0.020940</td>\n",
              "      <td>-0.116694</td>\n",
              "      <td>0.187147</td>\n",
              "      <td>-0.095713</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002091</td>\n",
              "      <td>0.094546</td>\n",
              "      <td>0.062270</td>\n",
              "      <td>0.143789</td>\n",
              "      <td>-0.263428</td>\n",
              "      <td>0.032675</td>\n",
              "      <td>-0.091599</td>\n",
              "      <td>0.159690</td>\n",
              "      <td>-0.051591</td>\n",
              "      <td>-0.072895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_764</th>\n",
              "      <td>0.443474</td>\n",
              "      <td>0.357378</td>\n",
              "      <td>-0.133512</td>\n",
              "      <td>0.317812</td>\n",
              "      <td>0.032675</td>\n",
              "      <td>0.202273</td>\n",
              "      <td>0.078858</td>\n",
              "      <td>0.117481</td>\n",
              "      <td>0.085433</td>\n",
              "      <td>-0.282476</td>\n",
              "      <td>...</td>\n",
              "      <td>0.192540</td>\n",
              "      <td>0.068779</td>\n",
              "      <td>0.145485</td>\n",
              "      <td>-0.230508</td>\n",
              "      <td>0.315251</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.204746</td>\n",
              "      <td>-0.159590</td>\n",
              "      <td>0.181170</td>\n",
              "      <td>0.216180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_765</th>\n",
              "      <td>0.216448</td>\n",
              "      <td>0.107098</td>\n",
              "      <td>-0.018046</td>\n",
              "      <td>0.156064</td>\n",
              "      <td>-0.091599</td>\n",
              "      <td>-0.113032</td>\n",
              "      <td>-0.079667</td>\n",
              "      <td>0.106025</td>\n",
              "      <td>0.118023</td>\n",
              "      <td>-0.205155</td>\n",
              "      <td>...</td>\n",
              "      <td>0.213167</td>\n",
              "      <td>0.136531</td>\n",
              "      <td>0.093549</td>\n",
              "      <td>-0.129885</td>\n",
              "      <td>0.327689</td>\n",
              "      <td>0.204746</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.117247</td>\n",
              "      <td>0.154951</td>\n",
              "      <td>0.388355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_766</th>\n",
              "      <td>-0.372152</td>\n",
              "      <td>0.008878</td>\n",
              "      <td>0.164799</td>\n",
              "      <td>-0.313222</td>\n",
              "      <td>0.159690</td>\n",
              "      <td>-0.411833</td>\n",
              "      <td>-0.139678</td>\n",
              "      <td>-0.374096</td>\n",
              "      <td>-0.342061</td>\n",
              "      <td>0.119664</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.559327</td>\n",
              "      <td>0.201898</td>\n",
              "      <td>-0.053654</td>\n",
              "      <td>0.334765</td>\n",
              "      <td>-0.503721</td>\n",
              "      <td>-0.159590</td>\n",
              "      <td>-0.117247</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.224632</td>\n",
              "      <td>0.129305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_767</th>\n",
              "      <td>0.081136</td>\n",
              "      <td>-0.021500</td>\n",
              "      <td>-0.030219</td>\n",
              "      <td>0.200493</td>\n",
              "      <td>-0.051591</td>\n",
              "      <td>0.173833</td>\n",
              "      <td>-0.109424</td>\n",
              "      <td>0.160097</td>\n",
              "      <td>0.017900</td>\n",
              "      <td>-0.064848</td>\n",
              "      <td>...</td>\n",
              "      <td>0.242810</td>\n",
              "      <td>-0.086578</td>\n",
              "      <td>-0.004117</td>\n",
              "      <td>-0.247390</td>\n",
              "      <td>0.280897</td>\n",
              "      <td>0.181170</td>\n",
              "      <td>0.154951</td>\n",
              "      <td>-0.224632</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.043913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_768</th>\n",
              "      <td>0.266223</td>\n",
              "      <td>0.233835</td>\n",
              "      <td>0.204483</td>\n",
              "      <td>0.071073</td>\n",
              "      <td>-0.072895</td>\n",
              "      <td>-0.208364</td>\n",
              "      <td>-0.122569</td>\n",
              "      <td>-0.007818</td>\n",
              "      <td>-0.078739</td>\n",
              "      <td>0.064398</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.049451</td>\n",
              "      <td>-0.056708</td>\n",
              "      <td>0.031914</td>\n",
              "      <td>0.022605</td>\n",
              "      <td>0.258167</td>\n",
              "      <td>0.216180</td>\n",
              "      <td>0.388355</td>\n",
              "      <td>0.129305</td>\n",
              "      <td>0.043913</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows × 768 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
              "feature_1     1.000000   0.267338   0.071490   0.414422   0.036982   0.207898   \n",
              "feature_2     0.267338   1.000000  -0.027042   0.004284   0.009556  -0.175189   \n",
              "feature_3     0.071490  -0.027042   1.000000   0.005692   0.187217  -0.184922   \n",
              "feature_4     0.414422   0.004284   0.005692   1.000000  -0.017515   0.295999   \n",
              "feature_5     0.036982   0.009556   0.187217  -0.017515   1.000000  -0.139041   \n",
              "...                ...        ...        ...        ...        ...        ...   \n",
              "feature_764   0.443474   0.357378  -0.133512   0.317812   0.032675   0.202273   \n",
              "feature_765   0.216448   0.107098  -0.018046   0.156064  -0.091599  -0.113032   \n",
              "feature_766  -0.372152   0.008878   0.164799  -0.313222   0.159690  -0.411833   \n",
              "feature_767   0.081136  -0.021500  -0.030219   0.200493  -0.051591   0.173833   \n",
              "feature_768   0.266223   0.233835   0.204483   0.071073  -0.072895  -0.208364   \n",
              "\n",
              "             feature_7  feature_8  feature_9  feature_10  ...  feature_759  \\\n",
              "feature_1     0.118319   0.147709   0.368570   -0.190114  ...     0.294503   \n",
              "feature_2     0.118727   0.047381   0.146719    0.004041  ...     0.036397   \n",
              "feature_3    -0.071054  -0.217118   0.112494   -0.045269  ...    -0.054550   \n",
              "feature_4    -0.119338   0.077402   0.123430   -0.147437  ...     0.402941   \n",
              "feature_5    -0.020940  -0.116694   0.187147   -0.095713  ...     0.002091   \n",
              "...                ...        ...        ...         ...  ...          ...   \n",
              "feature_764   0.078858   0.117481   0.085433   -0.282476  ...     0.192540   \n",
              "feature_765  -0.079667   0.106025   0.118023   -0.205155  ...     0.213167   \n",
              "feature_766  -0.139678  -0.374096  -0.342061    0.119664  ...    -0.559327   \n",
              "feature_767  -0.109424   0.160097   0.017900   -0.064848  ...     0.242810   \n",
              "feature_768  -0.122569  -0.007818  -0.078739    0.064398  ...    -0.049451   \n",
              "\n",
              "             feature_760  feature_761  feature_762  feature_763  feature_764  \\\n",
              "feature_1       0.016181     0.253096    -0.245060     0.423731     0.443474   \n",
              "feature_2       0.120084     0.058233    -0.095840     0.066372     0.357378   \n",
              "feature_3       0.048824    -0.087434     0.183482    -0.184763    -0.133512   \n",
              "feature_4      -0.048514     0.175835    -0.130880     0.364475     0.317812   \n",
              "feature_5       0.094546     0.062270     0.143789    -0.263428     0.032675   \n",
              "...                  ...          ...          ...          ...          ...   \n",
              "feature_764     0.068779     0.145485    -0.230508     0.315251     1.000000   \n",
              "feature_765     0.136531     0.093549    -0.129885     0.327689     0.204746   \n",
              "feature_766     0.201898    -0.053654     0.334765    -0.503721    -0.159590   \n",
              "feature_767    -0.086578    -0.004117    -0.247390     0.280897     0.181170   \n",
              "feature_768    -0.056708     0.031914     0.022605     0.258167     0.216180   \n",
              "\n",
              "             feature_765  feature_766  feature_767  feature_768  \n",
              "feature_1       0.216448    -0.372152     0.081136     0.266223  \n",
              "feature_2       0.107098     0.008878    -0.021500     0.233835  \n",
              "feature_3      -0.018046     0.164799    -0.030219     0.204483  \n",
              "feature_4       0.156064    -0.313222     0.200493     0.071073  \n",
              "feature_5      -0.091599     0.159690    -0.051591    -0.072895  \n",
              "...                  ...          ...          ...          ...  \n",
              "feature_764     0.204746    -0.159590     0.181170     0.216180  \n",
              "feature_765     1.000000    -0.117247     0.154951     0.388355  \n",
              "feature_766    -0.117247     1.000000    -0.224632     0.129305  \n",
              "feature_767     0.154951    -0.224632     1.000000     0.043913  \n",
              "feature_768     0.388355     0.129305     0.043913     1.000000  \n",
              "\n",
              "[768 rows x 768 columns]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corr_matrix_l4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_corr_features(corr_matrix, threshold):\n",
        "\n",
        "  correlated_features = []\n",
        "\n",
        "  for i in range(len(corr_matrix.columns)):\n",
        "    for j in range(i+1, len(corr_matrix.columns)):\n",
        "      if (abs(corr_matrix.iloc[i, j]) > threshold):\n",
        "        col_name = corr_matrix.columns[j]\n",
        "        if col_name not in correlated_features:\n",
        "          correlated_features.append(col_name)\n",
        "\n",
        "  return correlated_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27\n"
          ]
        }
      ],
      "source": [
        "correlated_features_l4 = get_corr_features(corr_matrix_l4, 0.7)\n",
        "print(len(correlated_features_l4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "x_test_l4 = x_test.copy()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train[L4] = pd.DataFrame(scaler.fit_transform(x_train[L4]), columns=FEATURES)\n",
        "x_valid[L4] = pd.DataFrame(scaler.transform(x_valid[L4]), columns=FEATURES)\n",
        "x_test_l4 = pd.DataFrame(scaler.transform(x_test_l4), columns=FEATURES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of features: 311\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "threshold = 0.96\n",
        "\n",
        "pca = PCA(n_components=threshold, svd_solver='full')\n",
        "x_train_l4_pca = pd.DataFrame(pca.fit_transform(x_train[L4]))\n",
        "x_valid_l4_pca = pd.DataFrame(pca.transform(x_valid[L4]))\n",
        "x_test_l4_pca = pd.DataFrame(pca.transform(x_test_l4))\n",
        "\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "\n",
        "print(f\"Number of features: {len(explained_variance)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy = 0.8946666666666667\n"
          ]
        }
      ],
      "source": [
        "accuracy_1 = weighted_svm_classifier(x_train_l4_pca, y_train[L4], x_valid_l4_pca, y_valid[L4])\n",
        "print(f\"Accuracy = {accuracy_1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Hyperparameter Tuning - Random Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "{'kernel': 'poly', 'gamma': 100.0, 'class_weight': 'balanced', 'C': 10.0}\n",
            "0.8137798036465638\n"
          ]
        }
      ],
      "source": [
        "param_dist = {\n",
        "    'C': np.logspace(-3, 3, 7),\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'gamma': np.logspace(-3, 3, 7),\n",
        "    'class_weight': ['balanced']\n",
        "}\n",
        "cv = 2\n",
        "n_iter = 5\n",
        "svm = SVC()\n",
        "\n",
        "random_search_l4 = random_grid_search(svm, param_dist, cv, n_iter, x_train_l4_pca, y_train[L4])\n",
        "best_model_l4 = random_search_l4.best_estimator_\n",
        "best_accuracy_l4 = random_search_l4.best_score_\n",
        "best_param = random_search_l4.best_params_\n",
        "\n",
        "print(best_param)\n",
        "print(best_accuracy_l4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy after: 0.972\n"
          ]
        }
      ],
      "source": [
        "y_pred_l4 = best_model_l4.predict(x_valid_l1_pca)\n",
        "accuracy = accuracy_score(y_valid[L4], y_pred_l4)\n",
        "print(f\"Accuracy after: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-Validation Scores: [0.94109397 0.93302945 0.94179523 0.95178822 0.92303647]\n",
            "Mean Score: 0.938148667601683\n",
            "Standard Deviation: 0.009618675498463689\n"
          ]
        }
      ],
      "source": [
        "model = SVC(kernel= best_param['kernel'], gamma= best_param['gamma'], class_weight= 'balanced', C= best_param['C'])\n",
        "\n",
        "k_fold_cross_validation(model, 5, x_train_l4_pca, y_train[L4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prediciton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Label 1\n",
        "pred_l1 = best_model_l1.predict(x_test_l1_pca)\n",
        "# Label 2\n",
        "pred_l2 = best_model_l2.predict(x_test_l2_pca)\n",
        "# Label 3\n",
        "pred_l3 = best_model_l3.predict(x_test_l3_pca)\n",
        "# Label 4\n",
        "pred_l4 = best_model_l4.predict(x_test_l4_pca)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "id_list = test_df['ID']\n",
        "\n",
        "result = {\n",
        "    'ID': id_list,\n",
        "    'label_1': pred_l1,\n",
        "    'label_2': pred_l2,\n",
        "    'label_3': pred_l3,\n",
        "    'label_4': pred_l4\n",
        "}\n",
        "\n",
        "result_df = pd.DataFrame(result)\n",
        "\n",
        "result_df.to_csv('layer_10.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
